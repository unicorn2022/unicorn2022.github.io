<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>多媒体技术 | 华风夏韵</title><meta name="author" content="华丰夏"><meta name="copyright" content="华丰夏"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="多媒体技术学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="多媒体技术">
<meta property="og:url" content="https://hzoi-unicorn.top/2023/03/01/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/index.html">
<meta property="og:site_name" content="华风夏韵">
<meta property="og:description" content="多媒体技术学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hzoi-unicorn.top/img/avatar.png">
<meta property="article:published_time" content="2023-03-01T00:00:00.000Z">
<meta property="article:modified_time" content="2023-07-22T11:41:22.475Z">
<meta property="article:author" content="华丰夏">
<meta property="article:tag" content="专业课">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hzoi-unicorn.top/img/avatar.png"><link rel="shortcut icon" href="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/favicon.png"><link rel="canonical" href="https://hzoi-unicorn.top/2023/03/01/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="codeva-PpLfvQYdq5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 华丰夏","link":"链接: ","source":"来源: 华风夏韵","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '多媒体技术',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-07-22 19:41:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/resources/"><i class="fa-fw fa fa-book"></i><span> 资源</span></a></div><div class="menus_item"><a class="site-page" href="/tools/"><i class="fa-fw fas fa-list"></i><span> 在线工具</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/default_top_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="华风夏韵"><span class="site-name">华风夏韵</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/resources/"><i class="fa-fw fa fa-book"></i><span> 资源</span></a></div><div class="menus_item"><a class="site-page" href="/tools/"><i class="fa-fw fas fa-list"></i><span> 在线工具</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">多媒体技术</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-01T00:00:00.000Z" title="发表于 2023-03-01 08:00:00">2023-03-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-22T11:41:22.475Z" title="更新于 2023-07-22 19:41:22">2023-07-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">专业课学习笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">11k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>37分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="多媒体技术"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



<h1 id="一、多媒体介绍"><a href="#一、多媒体介绍" class="headerlink" title="一、多媒体介绍"></a>一、多媒体介绍</h1><h2 id="1-1-什么是多媒体"><a href="#1-1-什么是多媒体" class="headerlink" title="1.1    什么是多媒体"></a>1.1    什么是多媒体</h2><ol>
<li>用于同时采集、处理、编辑、存储、表示两种及以上媒体类型的技术</li>
<li>一种能够创造、表示、处理、存储多种模态 信息的机器</li>
</ol>
<p>Perception Medium：感知媒介</p>
<ol>
<li>用于数据的采集和输入</li>
<li>如：麦克风、摄像头</li>
</ol>
<p>Representation Medium：表示媒介</p>
<ol>
<li>高效的将数据从一个地方传到另一个地方</li>
<li>如：网络、编码</li>
</ol>
<p>Presentation Medium：展示媒介</p>
<ol>
<li>将电信号转化为可以感知的信号</li>
<li>如：音响</li>
</ol>
<p>Storage Medium：存储媒介</p>
<ol>
<li>如：光盘、硬盘</li>
</ol>
<p>Transition Medium：传输媒介</p>
<h2 id="1-2-结构化数据"><a href="#1-2-结构化数据" class="headerlink" title="1.2    结构化数据"></a>1.2    结构化数据</h2><p>对于某个特定数据，计算机可以明确、快速的找到该数据的语义</p>
<ol>
<li>非结构化数据：视频、音频、文本</li>
<li>结构化数据：关系型数据库</li>
</ol>
<p>多媒体的任务：将非结构化的数据转化为结构化数据，让计算机能够处理</p>
<h1 id="二、图形和图像数据表示"><a href="#二、图形和图像数据表示" class="headerlink" title="二、图形和图像数据表示"></a>二、图形和图像数据表示</h1><h2 id="2-1-基础图像类型"><a href="#2-1-基础图像类型" class="headerlink" title="2.1    基础图像类型"></a>2.1    基础图像类型</h2><h3 id="2-1-1-1-bit-二值图像"><a href="#2-1-1-1-bit-二值图像" class="headerlink" title="2.1.1    1-bit 二值图像"></a>2.1.1    1-bit 二值图像</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303080712834.png" alt="image-20230303080712834" style="zoom:80%;" /></p>
<ol>
<li>包含多个像素</li>
<li>每个像素存储1-bit：0—black，1—white<ol>
<li>1表示有光照，因此是白的</li>
</ol>
</li>
<li>图像的大小：<ol>
<li>设分辨率为640×480，则大小为：640×480/8 = 38.4KB</li>
</ol>
</li>
<li>用途：<ol>
<li>存储简单图形、文本图像</li>
</ol>
</li>
</ol>
<h3 id="2-1-2-8-bit-灰度图像"><a href="#2-1-2-8-bit-灰度图像" class="headerlink" title="2.1.2    8-bit 灰度图像"></a>2.1.2    8-bit 灰度图像</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303081016469.png" alt="image-20230303081016469" style="zoom:80%;" /></p>
<ol>
<li>每个像素存储1-Byte = 0bit：有0~255共256个灰度等级<ol>
<li>256表示白色</li>
</ol>
</li>
<li>整个像素可以视为一个像素值的二维矩阵，被称为<strong>bitmap</strong><ol>
<li>8-bit灰度图像也可以视为8个1-bit图像的加权叠加</li>
</ol>
</li>
<li>图像的大小：<ol>
<li>设分辨率为640×480，则大小为：640×480 = 307,200 B</li>
</ol>
</li>
</ol>
<h3 id="2-1-3-将一个8-bit图像用一个1-bit打印机打印出来"><a href="#2-1-3-将一个8-bit图像用一个1-bit打印机打印出来" class="headerlink" title="2.1.3    将一个8-bit图像用一个1-bit打印机打印出来"></a>2.1.3    将一个8-bit图像用一个1-bit打印机打印出来</h3><ol>
<li><p><strong>DPI</strong>：Dot per inch</p>
<ol>
<li>DPI越高，代表打印机的质量越好</li>
</ol>
</li>
<li><p>1-bit打印机打印8-bit图像，本质上是用空间上的密度换取视觉上的感受</p>
<ol>
<li>抖动算法<strong>Dithering</strong>：用多个点替代原本的每一个像素</li>
<li>如果每个像素用<strong>N×N</strong>个点替代，则最多表示<strong>0~N^2^</strong>的灰度等级</li>
<li>打印机的驱动程序：将8-bit灰度图像，通过抖动算法，转换为一个更大的二值图像</li>
</ol>
</li>
<li><p>抖动矩阵：</p>
<ol>
<li>将当前像素点的灰度值与抖动矩阵比较，如果抖动矩阵当前位的值 &gt; 灰度值，则打印为黑色，否则打印为白色</li>
<li>不同硬件厂商，驱动中固化的抖动矩阵不同</li>
<li>对每一个像素，均通过抖动矩阵进行转化，从而可以得出一个更大的二值图像</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303082539666.png" alt="image-20230303082539666" style="zoom:80%;" /></p>
</li>
<li><p>示例：</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303082901189.png" alt="image-20230303082901189" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303083306296.png" alt="image-20230303083306296" style="zoom:67%;" /></p>
</li>
</ol>
<h3 id="2-1-4-24-Bit-真彩色图像"><a href="#2-1-4-24-Bit-真彩色图像" class="headerlink" title="2.1.4    24-Bit 真彩色图像"></a>2.1.4    24-Bit 真彩色图像</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303083457810.png" alt="image-20230303083457810" style="zoom:80%;" /></p>
<ol>
<li>每个像素分为三个通道RGB，每个通道取值范围为0~255<ol>
<li>颜色种类数：256×255×256</li>
</ol>
</li>
<li>32-Bit图像多了一个alpha通道，表示透明度，用于特效设计</li>
</ol>
<h3 id="2-1-5-8-Bit-彩色图像：256色彩色图像"><a href="#2-1-5-8-Bit-彩色图像：256色彩色图像" class="headerlink" title="2.1.5    8-Bit 彩色图像：256色彩色图像"></a>2.1.5    8-Bit 彩色图像：256色彩色图像</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303084302637.png" alt="image-20230303084302637" style="zoom:80%;" /></p>
<ol>
<li>将8-Bit彩色图像，显示到RGB显示器中：颜色查找表<strong>Color Lookup Table</strong><ol>
<li>每个像素存储的是颜色查找表中的索引</li>
<li>显示器显示该像素时，根据索引查找颜色查找表，然后显示表中对应项的RGB值</li>
</ol>
</li>
<li>将24-bit彩色图像转化为8-bit彩色图像，一定会失真<ol>
<li>不同算法，选出来的256种颜色不同</li>
</ol>
</li>
</ol>
<h3 id="2-1-6-颜色查找表-Color-Lookup-Table"><a href="#2-1-6-颜色查找表-Color-Lookup-Table" class="headerlink" title="2.1.6    颜色查找表 Color Lookup Table"></a>2.1.6    颜色查找表 Color Lookup Table</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303084509065.png" alt="image-20230303084509065" style="zoom:80%;" /></p>
<ol>
<li><p>优点：只需要将颜色查找表替换，就能更改显示风格</p>
</li>
<li><p>用途：医学图像</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303084623638.png" alt="image-20230303084623638" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="2-1-7-设计颜色查找表"><a href="#2-1-7-设计颜色查找表" class="headerlink" title="2.1.7    设计颜色查找表"></a>2.1.7    设计颜色查找表</h3><ol>
<li>本质上是做一个聚类Clustering<ol>
<li>将原本256×256×256个颜色，集合为256种颜色</li>
</ol>
</li>
</ol>
<h4 id="2-1-7-1-示例：3-bit-R，3-bit-G，2-bit-B"><a href="#2-1-7-1-示例：3-bit-R，3-bit-G，2-bit-B" class="headerlink" title="2.1.7.1    示例：3-bit R，3-bit G，2-bit B"></a>2.1.7.1    示例：3-bit R，3-bit G，2-bit B</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303085744468.png" alt="image-20230303085744468" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303085753499.png" alt="image-20230303085753499" style="zoom:80%;" /></p>
<h4 id="2-1-7-2-颜色直方图"><a href="#2-1-7-2-颜色直方图" class="headerlink" title="2.1.7.2    颜色直方图"></a>2.1.7.2    颜色直方图</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303085928266.png" alt="image-20230303085928266" style="zoom:80%;" /></p>
<ol>
<li>将一张图像，按照R、G、B通道分别统计每个值出现的频率</li>
<li>优化方法：让最后划分出来的256个桶中，像素个数基本相同</li>
</ol>
<h4 id="2-1-7-3-Median-cut：中值切分"><a href="#2-1-7-3-Median-cut：中值切分" class="headerlink" title="2.1.7.3    Median-cut：中值切分"></a>2.1.7.3    Median-cut：中值切分</h4><ol>
<li>每一次分割：将颜色直方图切分为两个部分，要求两个部分的离散积分(包含的像素点)相同</li>
<li>首先，根据图像的R值统计，然后进行分割</li>
<li>然后，根据上一次分割的情况，对每一个组，再次根据G值统计，然后进行分割</li>
<li>继续下去，按顺序总计进行了8次分割：RGBRGBRG</li>
<li>对每一个桶中的像素，取平均，即为颜色查找表中的颜色</li>
</ol>
<h2 id="2-2-场景图像文件格式"><a href="#2-2-场景图像文件格式" class="headerlink" title="2.2    场景图像文件格式"></a>2.2    场景图像文件格式</h2><ol>
<li>格式：图像的存储方式</li>
</ol>
<h3 id="2-2-1-GIF"><a href="#2-2-1-GIF" class="headerlink" title="2.2.1    GIF"></a>2.2.1    GIF</h3><ol>
<li>一般情况下，使用8-bit彩色图像</li>
<li>通常经过了压缩</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303091226783.png" alt="image-20230303091226783" style="zoom:80%;" /></p>
<h3 id="2-2-2-JPEG：Joint-Photographic-Experts-Group"><a href="#2-2-2-JPEG：Joint-Photographic-Experts-Group" class="headerlink" title="2.2.2    JPEG：Joint Photographic Experts Group"></a>2.2.2    JPEG：Joint Photographic Experts Group</h3><ol>
<li>JPEG一般均为压缩过的，在尽可能保存原有图像的质量下，最大化压缩比</li>
<li>也支持无损图像的存储</li>
</ol>
<h3 id="2-2-3-BMP：Windows的图像格式"><a href="#2-2-3-BMP：Windows的图像格式" class="headerlink" title="2.2.3    BMP：Windows的图像格式"></a>2.2.3    BMP：Windows的图像格式</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230303091504780.png" alt="image-20230303091504780" style="zoom:80%;" /></p>
<ol>
<li>Original data without compression, most popular</li>
<li>Run Length Encoding：Used for 8-bits image（256 colors）BI-RLE8</li>
<li>RLE：used for 4-bits image (16 colors) BI_RLE4</li>
</ol>
<h1 id="三、图像和视频中的颜色"><a href="#三、图像和视频中的颜色" class="headerlink" title="三、图像和视频中的颜色"></a>三、图像和视频中的颜色</h1><h2 id="3-1-颜色科学"><a href="#3-1-颜色科学" class="headerlink" title="3.1    颜色科学"></a>3.1    颜色科学</h2><h3 id="3-1-1-光与光谱-Light-and-Spectra"><a href="#3-1-1-光与光谱-Light-and-Spectra" class="headerlink" title="3.1.1    光与光谱 Light and Spectra"></a>3.1.1    光与光谱 Light and Spectra</h3><h4 id="3-1-1-1-光是一种电磁波，其颜色以波长为特征"><a href="#3-1-1-1-光是一种电磁波，其颜色以波长为特征" class="headerlink" title="3.1.1.1    光是一种电磁波，其颜色以波长为特征"></a>3.1.1.1    光是一种电磁波，其颜色以波长为特征</h4><ol>
<li>激光：单一波长</li>
<li>大多数光源：许多波长</li>
<li>短波–蓝色，长波–红色</li>
<li>可见光范围：400-700nm</li>
</ol>
<h4 id="3-1-1-2-不同波长的光，携带的能量不同：E-λ"><a href="#3-1-1-2-不同波长的光，携带的能量不同：E-λ" class="headerlink" title="3.1.1.2    不同波长的光，携带的能量不同：E(λ)"></a>3.1.1.2    不同波长的光，携带的能量不同：E(λ)</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308080613596.png" alt="image-20230308080613596" style="zoom:80%;" /></p>
<h4 id="3-1-1-3-人的视觉"><a href="#3-1-1-3-人的视觉" class="headerlink" title="3.1.1.3    人的视觉"></a>3.1.1.3    人的视觉</h4><ol>
<li><p>柱状细胞：只对明暗产生响应</p>
</li>
<li><p>锥体细胞：只对RGB三种颜色中的一种产生响应，对三种颜色的感知细胞数量不同</p>
<ol>
<li>R : G : B = 40 : 20 : 1</li>
</ol>
</li>
<li><p>对不同波长的光，人眼的敏感度不同：<strong>Luminous-efficiency function</strong></p>
<ol>
<li>$q(λ)=(q_R(λ),q_G(λ),q_B(λ))^T$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308081206201.png" alt="image-20230308081206201" style="zoom:80%;" /></p>
</li>
<li><p>$C(λ)=E(λ)S(λ)$：颜色信号</p>
<ol>
<li>$E(λ)$：光源强度</li>
<li>$S(λ)$：反射率</li>
</ol>
</li>
<li><p>颜色模型函数：</p>
<ol>
<li>$R=\int E(λ)S(λ)q_R(λ)\ dλ$</li>
<li>$G=\int E(λ)S(λ)q_G(λ)\ dλ$</li>
<li>$B=\int E(λ)S(λ)q_B(λ)\ dλ$</li>
</ol>
</li>
</ol>
<h3 id="3-1-2-Gamma矫正"><a href="#3-1-2-Gamma矫正" class="headerlink" title="3.1.2    Gamma矫正"></a>3.1.2    Gamma矫正</h3><h4 id="3-1-2-1-CRT显示原理"><a href="#3-1-2-1-CRT显示原理" class="headerlink" title="3.1.2.1    CRT显示原理"></a>3.1.2.1    CRT显示原理</h4><ol>
<li><p>将RGB的数值转化为电压，通过电子轰击荧光涂层屏幕，使屏幕发光</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308081907023.png" alt="image-20230308081907023" style="zoom:80%;" /></p>
</li>
<li><p>CRT发出的光，与输入的电压值，并不是线性关系的</p>
<ol>
<li>CRT发出的光的强度与升高的电压成比例：$R=&gt;R^γ$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308082014004.png" alt="image-20230308082014004" style="zoom:80%;" /></p>
</li>
<li><p>Gamma矫正：将期望的信号，首先进行一次放大，然后再输入给硬件</p>
<ol>
<li>$R=&gt;(R’=R^\frac{1}{γ})=&gt;(R’)^γ=&gt;R$</li>
<li>$\frac{1}{γ}$通常为$2.2$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308082520790.png" alt="image-20230308082520790" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="3-1-3-颜色匹配函数"><a href="#3-1-3-颜色匹配函数" class="headerlink" title="3.1.3    颜色匹配函数"></a>3.1.3    颜色匹配函数</h3><ol>
<li><p>测量出的颜色匹配函数：</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308083332082.png" alt="image-20230308083332082" style="zoom:80%;" /></p>
</li>
<li><p>通过线性变换，将所有值映射为正数</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308083515574.png" alt="image-20230308083515574" style="zoom:80%;" /></p>
</li>
<li><p>XYZ =&gt; RGB</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308083544437.png" alt="image-20230308083544437" style="zoom:80%;" /></p>
</li>
<li><p>亮度敏感度：</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308083700425.png" alt="image-20230308083700425" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="3-1-4-L-a-b-CIELAB-颜色模型"><a href="#3-1-4-L-a-b-CIELAB-颜色模型" class="headerlink" title="3.1.4    L  a  b * (CIELAB) 颜色模型"></a>3.1.4    L <em> a </em> b * (CIELAB) 颜色模型</h3><h4 id="3-1-4-1-韦伯定律"><a href="#3-1-4-1-韦伯定律" class="headerlink" title="3.1.4.1    韦伯定律"></a>3.1.4.1    韦伯定律</h4><ol>
<li>人感受到的变化，是变化率，而不是绝对值</li>
<li><strong>人的视觉系统，对于明暗变化的敏感度，远大于对于颜色变化的敏感度</strong></li>
</ol>
<h4 id="3-1-4-2-L-a-b-颜色模型：保证值的变化与人感知的变化相同"><a href="#3-1-4-2-L-a-b-颜色模型：保证值的变化与人感知的变化相同" class="headerlink" title="3.1.4.2    L  a  b * 颜色模型：保证值的变化与人感知的变化相同"></a>3.1.4.2    L <em> a </em> b * 颜色模型：保证值的变化与人感知的变化相同</h4><blockquote>
<p>相当于进行了一次线性变换</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308084130017.png" alt="image-20230308084130017" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308084422156.png" alt="image-20230308084422156" style="zoom:80%;" /></p>
<h4 id="3-1-4-3-其他颜色模型：人脑—LHS"><a href="#3-1-4-3-其他颜色模型：人脑—LHS" class="headerlink" title="3.1.4.3    其他颜色模型：人脑—LHS"></a>3.1.4.3    其他颜色模型：人脑—LHS</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308084336111.png" alt="image-20230308084336111" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308084320125.png" alt="image-20230308084320125" style="zoom:80%;" /></p>
<h2 id="3-2-图像中的颜色模型"><a href="#3-2-图像中的颜色模型" class="headerlink" title="3.2    图像中的颜色模型"></a>3.2    图像中的颜色模型</h2><h3 id="3-2-1-CRT显示：RGB"><a href="#3-2-1-CRT显示：RGB" class="headerlink" title="3.2.1    CRT显示：RGB"></a>3.2.1    CRT显示：RGB</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085211240.png" alt="image-20230308085211240" style="zoom:80%;" /></p>
<h3 id="3-2-2-打印机：CMY-K"><a href="#3-2-2-打印机：CMY-K" class="headerlink" title="3.2.2    打印机：CMY(K)"></a>3.2.2    打印机：CMY(K)</h3><ol>
<li>打印机会使用四个墨盒</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085252560.png" alt="image-20230308085252560" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085452322.png" alt="image-20230308085452322" style="zoom:80%;" /></p>
<h3 id="3-2-3-RGB-lt-gt-CMY"><a href="#3-2-3-RGB-lt-gt-CMY" class="headerlink" title="3.2.3    RGB &lt;=&gt; CMY"></a>3.2.3    RGB &lt;=&gt; CMY</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085403909.png" alt="image-20230308085403909" style="zoom:80%;" /></p>
<h2 id="3-3-视频中的颜色模型"><a href="#3-3-视频中的颜色模型" class="headerlink" title="3.3    视频中的颜色模型"></a>3.3    视频中的颜色模型</h2><p>YUV、YIQ、YCbCr模型</p>
<ol>
<li>Y：灰度</li>
<li>另外两层是对颜色的划分</li>
<li>由于人眼对明暗的敏感性远大于色彩，因此在压缩过程中，灰度是不会改变的</li>
</ol>
<h3 id="3-3-1-YUV颜色模型"><a href="#3-3-1-YUV颜色模型" class="headerlink" title="3.3.1    YUV颜色模型"></a>3.3.1    YUV颜色模型</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085810546.png" alt="image-20230308085810546" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308085938222.png" alt="image-20230308085938222" style="zoom:80%;" /></p>
<h3 id="3-3-2-YIQ颜色模型"><a href="#3-3-2-YIQ颜色模型" class="headerlink" title="3.3.2    YIQ颜色模型"></a>3.3.2    YIQ颜色模型</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308090901371.png" alt="image-20230308090901371" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308090049754.png" alt="image-20230308090049754" style="zoom:80%;" /></p>
<h3 id="3-3-3-YCbCr颜色模型"><a href="#3-3-3-YCbCr颜色模型" class="headerlink" title="3.3.3    YCbCr颜色模型"></a>3.3.3    YCbCr颜色模型</h3><blockquote>
<p>JPEG图像，MPEG视频</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230308090827897.png" alt="image-20230308090827897" style="zoom:80%;" /></p>
<h1 id="四、视频基础概念"><a href="#四、视频基础概念" class="headerlink" title="四、视频基础概念"></a>四、视频基础概念</h1><h2 id="4-1-视频信号类别"><a href="#4-1-视频信号类别" class="headerlink" title="4.1    视频信号类别"></a>4.1    视频信号类别</h2><ol>
<li>Component Video：分量视频</li>
<li>Composite Video：复合视频</li>
<li>S-Video：介于两者之间</li>
</ol>
<h3 id="4-1-1-分量视频"><a href="#4-1-1-分量视频" class="headerlink" title="4.1.1    分量视频"></a>4.1.1    分量视频</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310081325975.png" alt="image-20230310081325975" style="zoom:80%;" /></p>
<ol>
<li>三根线，每根线负责传输RGB其中一个通道的视频信号</li>
<li>优点：RGB三个通道互不干扰，传输信号质量高、带宽大<ol>
<li>干扰：crosstalk</li>
</ol>
</li>
<li>也可以传输YIQ、YUV等其他模型的信号<ol>
<li>Luminance-chrominance transformation from RGB：RGB亮度色度变换</li>
</ol>
</li>
<li>只能由彩色电视使用</li>
</ol>
<h3 id="4-1-2-复合视频"><a href="#4-1-2-复合视频" class="headerlink" title="4.1.2    复合视频"></a>4.1.2    复合视频</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310081343053.png" alt="image-20230310081343053" style="zoom:80%;" /></p>
<ol>
<li>机顶盒：对数据进行解压，然后将数据送往电视机</li>
<li>将所有的信号，调制到一根电缆上传输<ol>
<li>更多使用YIQ、YUV等模型</li>
<li>要进行数据的压缩</li>
<li>Y用低频信号调制，UV/IQ用高频信号调制，然后再调制到一个通道上</li>
</ol>
</li>
<li>天然与黑白电视兼容<ol>
<li>可以在解码时只取Y通道</li>
</ol>
</li>
<li>缺点：三个信号之间会存在一定的干扰</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310081901918.png" alt="image-20230310081901918" style="zoom:80%;" /></p>
<h3 id="4-1-3-S-Video"><a href="#4-1-3-S-Video" class="headerlink" title="4.1.3    S-Video"></a>4.1.3    S-Video</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310081753068.png" alt="image-20230310081753068" style="zoom:80%;" /></p>
<ol>
<li>4个引脚<ol>
<li>1~2：接地</li>
<li>3：传输Y信号</li>
<li>4：传输颜色信号</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310081912967.png" alt="image-20230310081912967" style="zoom:80%;" /></p>
<h2 id="4-2-模拟视频制式-与硬件有关"><a href="#4-2-模拟视频制式-与硬件有关" class="headerlink" title="4.2    模拟视频制式(与硬件有关)"></a>4.2    模拟视频制式(与硬件有关)</h2><h3 id="4-2-1-相关概念"><a href="#4-2-1-相关概念" class="headerlink" title="4.2.1    相关概念"></a>4.2.1    相关概念</h3><ol>
<li><p>模拟信号是连续的，数字信号是离散的</p>
<ol>
<li>连续：在任何时间，均有对应取值</li>
<li>离散：只有在采样点处，才有对应取值</li>
</ol>
</li>
<li><p>模拟信号 Analog signal：f(t)，随时间变化的图像</p>
</li>
<li><p>CRT显示器(至少85Hz，每秒至少扫85帧)</p>
<ol>
<li>逐行扫描：从第一行开始，一行一行扫描</li>
<li>隔行扫描：从第一行开始，先扫1357…，再扫2468….<ol>
<li>奇数线扫描出的是奇数场图像，偶数线扫描出的是偶数场图像</li>
</ol>
</li>
<li>扫描线是斜线，但斜度较小<ol>
<li>field：场</li>
<li>水平回溯时间：上一条扫描线Q=&gt;下一条扫描线R</li>
<li>垂直回溯时间：上一次扫描U=&gt;下一次扫描V</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310082732135.png" alt="image-20230310082732135" style="zoom:80%;" /></p>
</li>
<li><p>电视机=&gt;隔行扫描，显示器=&gt;逐行扫描</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310083025314.png" alt="image-20230310083025314" style="zoom:80%;" /></p>
</li>
<li><p>示例：</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310083146608.png" alt="image-20230310083146608" style="zoom:80%;" /></p>
</li>
<li><p>模拟电视的电视信号制式：</p>
<ol>
<li>NTSC：正交平衡调幅<ol>
<li>USA, Canada, Japan and Korea，1953 by USA</li>
</ol>
</li>
<li>PAL：逐行倒相正交平衡调幅<ol>
<li>Germany, England and China, 1962 by Germany</li>
</ol>
</li>
<li>SECAM：顺序传送彩色与存储<ol>
<li>France, Russia，1966 by France</li>
</ol>
</li>
</ol>
</li>
<li><p>均可以同时兼容黑白、彩色，明暗度也会单独传输</p>
</li>
</ol>
<h3 id="4-2-2-NTSC信号"><a href="#4-2-2-NTSC信号" class="headerlink" title="4.2.2    NTSC信号"></a>4.2.2    NTSC信号</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310085636444.png" alt="image-20230310085636444" style="zoom:80%;" /></p>
<ol>
<li><p><strong>NTSC</strong>：National Television Standards Committee，正交平衡调幅</p>
<ol>
<li>长宽比：4:3</li>
<li>每一帧：525行</li>
<li>每一秒：30帧</li>
<li>颜色模型：YIQ</li>
</ol>
</li>
<li><p>详细参数：</p>
<ol>
<li>FPS：29.97，33.37ms每帧</li>
<li>隔行扫描，每个场262.5行</li>
<li>水平扫描频率：525×29.97 = 15734行</li>
<li>每一行时间：1/15734 = 63.6 μsec<ol>
<li>水平回溯：10.9</li>
<li>扫描：52.7</li>
</ol>
</li>
<li>垂直回溯：每个场20行的时间，因此每一帧只有485行的时间</li>
<li>水平扫描：保留光栅的1/6</li>
<li>水平分辨率：每行样本数</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310084119186.png" alt="image-20230310084119186" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310084128971.png" alt="image-20230310084128971" style="zoom:80%;" /></p>
</li>
<li><p>调制方式：$Y+I\cos(F<em>{sc}t)+Q\sin(F</em>{sc}t)$</p>
<ol>
<li>$YIQ$：为原始信号</li>
<li>$F_{sc}$：为一个高频信号</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310084420486.png" alt="image-20230310084420486" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310084434188.png" alt="image-20230310084434188" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310084443752.png" alt="image-20230310084443752" style="zoom:80%;" /></p>
</li>
<li><p>解调方式</p>
<ol>
<li>通过一个低通滤波器，将$Y$、$C=I\cos(F<em>{sc}t)+Q\sin(F</em>{sc}t)$分离</li>
<li>将$C*2cos(F<em>{sc}t)$，可得$I+I\cos(2F</em>{sc}t)+2Q\sin(2F_{sc}t)$</li>
<li>然后使用低通滤波器，将$I$分离出来</li>
</ol>
</li>
</ol>
<h3 id="4-2-3-PAL信号"><a href="#4-2-3-PAL信号" class="headerlink" title="4.2.3    PAL信号"></a>4.2.3    PAL信号</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310085507449.png" alt="image-20230310085507449" style="zoom:80%;" /></p>
<ol>
<li><p><strong>PAL</strong>：Phase Alteration Line，逐行倒相正交平衡调幅</p>
<ol>
<li>颜色模型：YUV</li>
</ol>
</li>
</ol>
<h3 id="4-2-4-SECAM信号"><a href="#4-2-4-SECAM信号" class="headerlink" title="4.2.4    SECAM信号"></a>4.2.4    SECAM信号</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310085617972.png" alt="image-20230310085617972" style="zoom:80%;" /></p>
<ol>
<li><strong>SECAM</strong>：顺序传送彩色与存储</li>
</ol>
<h3 id="4-2-5-三种信号对比"><a href="#4-2-5-三种信号对比" class="headerlink" title="4.2.5    三种信号对比"></a>4.2.5    三种信号对比</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310085726784.png" alt="image-20230310085726784" style="zoom:80%;" /></p>
<h2 id="4-3-数字视频"><a href="#4-3-数字视频" class="headerlink" title="4.3    数字视频"></a>4.3    数字视频</h2><h3 id="4-3-1-数字视频的优点"><a href="#4-3-1-数字视频的优点" class="headerlink" title="4.3.1    数字视频的优点"></a>4.3.1    数字视频的优点</h3><ol>
<li>将视频存储在数字设备或存储器中</li>
<li>可随时处理并集成到各种多媒体应用程序中</li>
<li>直接访问：非线性视频编辑</li>
<li>重复记录而不降低图像质量</li>
<li>易于加密，更好地容忍信道噪声</li>
</ol>
<h3 id="4-3-2-色度下采样-Chroma-subsampling"><a href="#4-3-2-色度下采样-Chroma-subsampling" class="headerlink" title="4.3.2    色度下采样 Chroma subsampling"></a>4.3.2    色度下采样 Chroma subsampling</h3><blockquote>
<p><strong>色彩模型的转换，不会产生数据损失</strong></p>
</blockquote>
<ol>
<li>人类视觉：对明暗变化的敏感度，远大于对于颜色变化的敏感度</li>
<li>每四个原始像素，实际发送的像素值是多少？<ol>
<li>4:4:4：表示无二次采样</li>
<li>4:2:2：表示Cb和Cr的水平二次采样，系数为2<ol>
<li>水平的两个像素，用一个像素值表示</li>
</ol>
</li>
<li>4:1:1：表示Cb和Cr的水平二次采样，系数为4<ol>
<li>水平的四个像素，用一个像素值表示</li>
</ol>
</li>
<li>4:2:0：分别表示Cb和Cr的水平和垂直二次采样，系数为2<ol>
<li>水平&amp;垂直的2×2共4个像素，用一个像素值表示</li>
</ol>
</li>
</ol>
</li>
<li>JPEG和MPEG中通常使用的4:2:0方案</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310090543092.png" alt="image-20230310090543092" style="zoom:80%;" /></p>
<h3 id="4-3-3-CCIR标准"><a href="#4-3-3-CCIR标准" class="headerlink" title="4.3.3    CCIR标准"></a>4.3.3    CCIR标准</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091159598.png" alt="image-20230310091159598" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091208390.png" alt="image-20230310091208390" style="zoom:80%;" /></p>
<h3 id="4-3-4-CIF标准"><a href="#4-3-4-CIF标准" class="headerlink" title="4.3.4    CIF标准"></a>4.3.4    CIF标准</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091227244.png" alt="image-20230310091227244" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091241022.png" alt="image-20230310091241022" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091258675.png" alt="image-20230310091258675" style="zoom:80%;" /></p>
<h3 id="4-3-5-HDTV：High-Definition-TV"><a href="#4-3-5-HDTV：High-Definition-TV" class="headerlink" title="4.3.5    HDTV：High Definition TV"></a>4.3.5    HDTV：High Definition TV</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091341936.png" alt="image-20230310091341936" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091349518.png" alt="image-20230310091349518" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091404438.png" alt="image-20230310091404438" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230310091420604.png" alt="image-20230310091420604" style="zoom:80%;" /></p>
<h1 id="五、数字音频基础"><a href="#五、数字音频基础" class="headerlink" title="五、数字音频基础"></a>五、数字音频基础</h1><h2 id="5-1-声音的数字化"><a href="#5-1-声音的数字化" class="headerlink" title="5.1    声音的数字化"></a>5.1    声音的数字化</h2><h3 id="5-1-1-什么是声音"><a href="#5-1-1-什么是声音" class="headerlink" title="5.1.1    什么是声音"></a>5.1.1    什么是声音</h3><ol>
<li>声音是像光一样的波动现象<ol>
<li>没有空气–没有声音</li>
<li>声音是一种压力波，具有连续值</li>
</ol>
</li>
<li>声音具有波的特性和行为<ol>
<li>反射</li>
<li>折射</li>
<li>衍射</li>
</ol>
</li>
<li>声音可以通过将压力转换为电压水平来测量</li>
</ol>
<h3 id="5-1-2-数字化"><a href="#5-1-2-数字化" class="headerlink" title="5.1.2    数字化"></a>5.1.2    数字化</h3><ol>
<li>振幅Amplitude：连续值和随时间变化<ol>
<li>在时间维度和振幅维度采样</li>
</ol>
</li>
<li>时间维度：以均匀间隔采样<ol>
<li>典型范围：8kHz至48kHz</li>
<li>人类可以听到20Hz到20kHz的声音</li>
</ol>
</li>
<li>量化：振幅维度的采样<ol>
<li>均匀采样 Uniform Sampling：等距采样</li>
<li>非均匀采样 Nonuniform Sampling：如u-law规则</li>
<li>典型的均匀量化率：<ol>
<li>8位，256级</li>
<li>16位，65536级</li>
</ol>
</li>
</ol>
</li>
<li>三个关键问题<ol>
<li>采样频率是多少？</li>
<li>采样到的数据如何量化？分成多少级？</li>
<li>音频数据如何存储？文件格式是什么？</li>
</ol>
</li>
</ol>
<blockquote>
<p>在时间维度和振幅维度采样，需要将两个轴均离散化</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315081333664.png" alt="image-20230315081333664" style="zoom:80%;" /></p>
<h3 id="5-1-3-奈奎斯特定理"><a href="#5-1-3-奈奎斯特定理" class="headerlink" title="5.1.3    奈奎斯特定理"></a>5.1.3    奈奎斯特定理</h3><ol>
<li>奈奎斯特速率 Nyquist Rate：<ol>
<li>采样频率必须是原始信号最大频率的2倍</li>
</ol>
</li>
<li>奈奎斯特定理 Nyquist Theorem：<ol>
<li>如果原始信号的最大频率为<strong>f1</strong>，最低频率为<strong>f2</strong>，带宽为<strong>f1-f2</strong>，则采样频率至少为<strong>2(f1-f2)</strong></li>
</ol>
</li>
<li>奈奎斯特频率 Nyquist Frequency：<ol>
<li>如果数字信号的频率为<strong>F</strong>，则能够还原的无失真信号的最大频率为<strong>F/2</strong></li>
</ol>
</li>
</ol>
<h3 id="5-1-4-信噪比SNR"><a href="#5-1-4-信噪比SNR" class="headerlink" title="5.1.4    信噪比SNR"></a>5.1.4    信噪比SNR</h3><p>$SNR = 10\log<em>10 \frac{V</em>{signal}^2}{V<em>{noise}^2}=10\log_10 \frac{V</em>{signal}}{V_{noise}}$</p>
<ol>
<li>SNR：信号与噪声的功率之比称为信噪比，这是信号质量的度量。</li>
<li>单位：分贝dB，其中1dB为十分之一贝尔</li>
<li>信号的功率与电压的平方成正比<ol>
<li>例如，如果信号电压Vsignal是噪声的10倍，则SNR为20log10（10）＝20dB。</li>
</ol>
</li>
<li>在功率方面，如果十把小提琴的功率是一把小提琴的十倍，则功率比为10dB或1B</li>
</ol>
<h3 id="5-1-5-SQNR"><a href="#5-1-5-SQNR" class="headerlink" title="5.1.5    SQNR"></a>5.1.5    SQNR</h3><p>$SQNR=20\log<em>{10}\frac{V</em>{signal}}{V<em>{quan_noise}}=20\log</em>{10}\frac{2^{N-1}}{0.5}=20<em>N</em>\log_2=6.02N(dB)$</p>
<ol>
<li>在量化时，会人为引入误差，也被称为人为引入噪音</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315083401485.png" alt="image-20230315083401485" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315083412440.png" alt="image-20230315083412440" style="zoom:80%;" /></p>
<h3 id="5-1-6-非线性采样"><a href="#5-1-6-非线性采样" class="headerlink" title="5.1.6    非线性采样"></a>5.1.6    非线性采样</h3><ol>
<li>对于声音的采样来说，高频部分采样稀疏，低频部分采样密集</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315083327169.png" alt="image-20230315083327169" style="zoom:80%;" /></p>
<h3 id="5-1-7-声音过滤"><a href="#5-1-7-声音过滤" class="headerlink" title="5.1.7    声音过滤"></a>5.1.7    声音过滤</h3><ol>
<li>在采样和AD转换之前，通过过滤音频信号来去除不需要的频率</li>
<li>保留的频率取决于具体应用：<ol>
<li>人的语音：50Hz至10kHz</li>
<li>音频音乐信号：20Hz至20kHz</li>
</ol>
</li>
<li>其他频率被带通滤波器（也称为限带滤波）过滤掉了<ol>
<li>band-pass filter，band-limiting filter</li>
</ol>
</li>
</ol>
<h3 id="5-1-8-音频质量与数据速率"><a href="#5-1-8-音频质量与数据速率" class="headerlink" title="5.1.8    音频质量与数据速率"></a>5.1.8    音频质量与数据速率</h3><ol>
<li>未压缩的数据速率随着用于量化的比特数的增加而增加</li>
<li>音频质量：数据速率和带宽<ol>
<li>模拟设备，带宽以频率单位表示，赫兹</li>
<li>数字设备，比特每秒，bps</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315083645880.png" alt="image-20230315083645880" style="zoom:80%;" /></p>
<h3 id="5-1-9-合成声音"><a href="#5-1-9-合成声音" class="headerlink" title="5.1.9    合成声音"></a>5.1.9    合成声音</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315083956623.png" alt="image-20230315083956623" style="zoom: 80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315084009750.png" alt="image-20230315084009750" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315084025378.png" alt="image-20230315084025378" style="zoom:80%;" /></p>
<h2 id="5-2-乐器数字接口"><a href="#5-2-乐器数字接口" class="headerlink" title="5.2    乐器数字接口"></a>5.2    乐器数字接口</h2><h3 id="5-2-1-MIDI"><a href="#5-2-1-MIDI" class="headerlink" title="5.2.1    MIDI"></a>5.2.1    MIDI</h3><ol>
<li>MIDI存储的是合成声音的指令，而不是原始信号</li>
<li>机器根据MIDI的指令，合成固化在硬件中的波形</li>
</ol>
<h2 id="5-3-音频的量化和传输"><a href="#5-3-音频的量化和传输" class="headerlink" title="5.3    音频的量化和传输"></a>5.3    音频的量化和传输</h2><p>每个压缩模式包含三个阶段：</p>
<ol>
<li>对输入数据进行<strong>变换</strong>：不会产生信息差异</li>
<li><strong>量化</strong>：会导致信息丢失</li>
<li><strong>编码</strong></li>
</ol>
<h3 id="5-3-1-声音的编码"><a href="#5-3-1-声音的编码" class="headerlink" title="5.3.1    声音的编码"></a>5.3.1    声音的编码</h3><ol>
<li>编码Coding：数据的量化与传输</li>
<li>时间上的冗余性：声音信号是连续的，即相邻的两个点的值差别不大<ol>
<li>因此可以减少存储的数据量</li>
</ol>
</li>
<li>编码调制<ol>
<li>PCM：脉冲编码调制</li>
<li>DPCM：脉冲编码调制的差分版本</li>
<li>ADPCM：Adaptive DPCM</li>
</ol>
</li>
</ol>
<h3 id="5-3-2-PCM：Pulse-Code-Modulation"><a href="#5-3-2-PCM：Pulse-Code-Modulation" class="headerlink" title="5.3.2    PCM：Pulse Code Modulation"></a>5.3.2    PCM：Pulse Code Modulation</h3><ol>
<li><p>PCM的过程：确定采样点、求交、取整</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315085142376.png" alt="image-20230315085142376" style="zoom:80%;" /></p>
</li>
<li><p>均匀量化：对采样到的值均匀的分为多个等级</p>
</li>
<li><p>非均匀量化：在某些部分分的等级多，某些部分分的等级少</p>
</li>
</ol>
<blockquote>
<p>在数转模的过程中，会引入高频噪声，因此需要一个低通滤波器</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315085734942.png" alt="image-20230315085734942" style="zoom:80%;" /></p>
<h3 id="5-3-3-音频的差分编码-Difference-coding-of-audio"><a href="#5-3-3-音频的差分编码-Difference-coding-of-audio" class="headerlink" title="5.3.3    音频的差分编码 Difference coding of audio"></a>5.3.3    音频的差分编码 Difference coding of audio</h3><ol>
<li>存储当前采样点的值，与上一采样点的值的差值<ol>
<li>信号分布的范围越广，压缩的可能性越低</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315090256082.png" alt="image-20230315090256082" style="zoom:80%;" /></p>
<h3 id="5-3-4-无损预测编码-Lossless-Predictive-Coding"><a href="#5-3-4-无损预测编码-Lossless-Predictive-Coding" class="headerlink" title="5.3.4    无损预测编码 Lossless Predictive Coding"></a>5.3.4    无损预测编码 Lossless Predictive Coding</h3><p>预测编码：</p>
<ol>
<li>预测当前时刻值，为上一时刻的值$\hat f<em>n = f</em>{n-1}$</li>
<li>但是肯定会有误差，存储的数据即为误差本身$e_n=f_n-\hat f_n$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315090739975.png" alt="image-20230315090739975" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315090759711.png" alt="image-20230315090759711" style="zoom:80%;" /></p>
<p>无损预测编码：解码器产生与原始信号相同的信号</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315091336063.png" alt="image-20230315091336063" style="zoom:80%;" /></p>
<blockquote>
<p>示例：$\hat f<em>n =\lfloor \frac{1}{2} (f</em>{n-1} + f_{n-2}) \rfloor$，$e_n=f_n-\hat f_n$</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315091407545.png" alt="image-20230315091407545" style="zoom:80%;" /></p>
</blockquote>
<h3 id="5-3-5-DPCM"><a href="#5-3-5-DPCM" class="headerlink" title="5.3.5    DPCM"></a>5.3.5    DPCM</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315091540051.png" alt="image-20230315091540051" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315091823659.png" alt="image-20230315091823659" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230315092320033.png" alt="image-20230315092320033" style="zoom:80%;" /></p>
<h1 id="六、无损压缩算法"><a href="#六、无损压缩算法" class="headerlink" title="六、无损压缩算法"></a>六、无损压缩算法</h1><h2 id="6-1-信息论基础"><a href="#6-1-信息论基础" class="headerlink" title="6.1    信息论基础"></a>6.1    信息论基础</h2><h3 id="6-1-1-背景"><a href="#6-1-1-背景" class="headerlink" title="6.1.1    背景"></a>6.1.1    背景</h3><ol>
<li>压缩的目的：<ol>
<li>节约存储空间、提高传输速率</li>
</ol>
</li>
<li>不同的数据，出现的频率不同：<ol>
<li>出现频率越高的数据，给越短的编码</li>
</ol>
</li>
</ol>
<h3 id="6-1-2-数据压缩范式"><a href="#6-1-2-数据压缩范式" class="headerlink" title="6.1.2    数据压缩范式"></a>6.1.2    数据压缩范式</h3><ol>
<li>压缩率：<strong>B0/B1</strong><ol>
<li>B0：为压缩前的数据的bit数</li>
<li>B1：为压缩后的数据的bit数</li>
<li>压缩算法用到某些数据上后，可能会导致数据bit数变大</li>
</ol>
</li>
<li>压缩率越大，压缩算法越好</li>
<li>无损压缩：解码出的数据 == 压缩前的数据</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317081013933.png" alt="image-20230317081013933" style="zoom:80%;" /></p>
<h3 id="6-1-3-信息论基础"><a href="#6-1-3-信息论基础" class="headerlink" title="6.1.3    信息论基础"></a>6.1.3    信息论基础</h3><ol>
<li><p><strong>熵 entropy</strong>：表征信源的信息量大小</p>
<ol>
<li>如果要压缩一个文本文档，那么文本文档本身是<strong>信源</strong>，ASCII码表是信源的<strong>码表</strong></li>
<li>熵越大，表示该系统更无序，压缩后的产物越大</li>
<li>压缩算法实际上就是降低信源的熵</li>
</ol>
</li>
<li><p>计算方法：设码表为$S={s1,s2…,sn}$</p>
<ol>
<li>则熵为：$\eta=H(S)=\sum<em>{i=1}^{n}p_i\log_2\frac{1}{p_i}=-\sum</em>{i=1}^{n}p_i\log_2p_i$</li>
<li>$p_i$：表示$s_i$在信源中出现的概率，$p_i=\frac{s1出现的次数}{信源包含的字符数}$</li>
<li>$\log_2\frac{1}{p_i}$：表示信号$s_i$的熵 amount of information contained in characters</li>
</ol>
<blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317082205213.png" alt="image-20230317082205213" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317082522398.png" alt="image-20230317082522398" style="zoom:80%;" /></p>
</blockquote>
</li>
<li><p><strong>熵编码</strong>：高频出现的符号，码长更短</p>
</li>
<li><p>如果某个符号的熵为<strong>k</strong>，则使用<strong>熵编码</strong>后，其二进制位数至少为<strong>k bits</strong></p>
</li>
</ol>
<h2 id="6-2-无损编码算法"><a href="#6-2-无损编码算法" class="headerlink" title="6.2    无损编码算法"></a>6.2    无损编码算法</h2><h3 id="6-2-1-Run-Length-Coding-游程编码"><a href="#6-2-1-Run-Length-Coding-游程编码" class="headerlink" title="6.2.1    Run-Length Coding 游程编码"></a>6.2.1    Run-Length Coding 游程编码</h3><p>思想：将连续出现多次的字符，转换为<strong>(字符, 出现次数)</strong></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317083422974.png" alt="image-20230317083422974" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317083623892.png" alt="image-20230317083623892" style="zoom:80%;" /></p>
<h3 id="6-2-2-Variable-Length-Coding-可变长编码"><a href="#6-2-2-Variable-Length-Coding-可变长编码" class="headerlink" title="6.2.2    Variable-Length Coding 可变长编码"></a>6.2.2    Variable-Length Coding 可变长编码</h3><p>思想：计算出所有符号的熵后，根据熵的大小，赋予编码值</p>
<ol>
<li><p>Shannon-Fano算法</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317083801102.png" alt="image-20230317083801102" style="zoom:80%;" /></p>
</li>
<li><p>Huffman编码</p>
<ol>
<li>先统计出现的概率，然后根据概率建树，最后对树进行编码</li>
<li>扩展Huffman编码：对于某些连续出现的字符，如abc，可以把它们作为整体定义为一个新的字符</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317083924140.png" alt="image-20230317083924140" style="zoom:80%;" /></p>
</li>
<li><p>自适应Huffman编码</p>
<ol>
<li>由于信源在不断发出信号，因此我们只能统计到当前位置，某个字符出现的概率</li>
<li>在编码器和解码器中，同时维护两棵树，根据发出的字符，动态调整树的结构</li>
</ol>
</li>
</ol>
<h3 id="6-2-3-Dictionary-Based-Coding-字典编码"><a href="#6-2-3-Dictionary-Based-Coding-字典编码" class="headerlink" title="6.2.3    Dictionary-Based Coding 字典编码"></a>6.2.3    Dictionary-Based Coding 字典编码</h3><p>思想：对出现的不同字符串，赋予一个编码，传输时同时传输码表</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085238101.png" alt="image-20230317085238101" style="zoom:80%;" /></p>
<blockquote>
<ol>
<li>首先，将ABC分别赋予1、2、3</li>
<li>对于输入<code>ABABBABCABABBA</code></li>
<li>将<code>A</code>入栈，发现<code>A</code>在码表中，输出1，然后</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085337366.png" alt="image-20230317085337366" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085600752.png" alt="image-20230317085600752" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085616473.png" alt="image-20230317085616473" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085622861.png" alt="image-20230317085622861" style="zoom:80%;" /></p>
<h3 id="6-2-4-Arithmetic-Coding-算术编码"><a href="#6-2-4-Arithmetic-Coding-算术编码" class="headerlink" title="6.2.4    Arithmetic Coding 算术编码"></a>6.2.4    Arithmetic Coding 算术编码</h3><blockquote>
<ol>
<li>将每个字符，按出现的频率，划分<code>[0~1)</code>的地盘</li>
<li>第一个字符为<code>C</code>，则将<code>[0.3,0.5)</code>的地盘再次根据频率划分地盘</li>
<li>第二个字符为<code>A</code>，则将<code>[0.3,0.34)</code>的地盘再次根据频率划分地盘</li>
<li>重复以上过程，直到所有的字符均读入过</li>
<li>在最后得到的区间范围内，随机选取一个小数，作为编码结果</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085851234.png" alt="image-20230317085851234"></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317085900934.png" alt="image-20230317085900934" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090106383.png" alt="image-20230317090106383" style="zoom:80%;" /></p>
<blockquote>
<ol>
<li>接收到的小数为<code>0.33203125</code>，在<code>[0.3,0.5)</code>之间，则第一个字符为<code>C</code></li>
<li>第二个小数为<code>(0.33203125-0.3)/0.2=0.16015625</code>，在<code>[0.0,0.2)</code>之间，则第二个字符为<code>A</code></li>
<li>第三个小数为<code>(0.16015625-0.0)/0.2=0.80078125</code>，在<code>[0.55,0.85)</code>之间，则第三个字符为<code>E</code></li>
<li>重复上述操作，直到读到文档结束符号<code>$</code></li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090019427.png" alt="image-20230317090019427" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090542579.png" alt="image-20230317090542579" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090117733.png" alt="image-20230317090117733" style="zoom:80%;" /></p>
<h2 id="6-3-无损图像压缩"><a href="#6-3-无损图像压缩" class="headerlink" title="6.3    无损图像压缩"></a>6.3    无损图像压缩</h2><h3 id="6-3-1-图像差分编码：降低数据的熵"><a href="#6-3-1-图像差分编码：降低数据的熵" class="headerlink" title="6.3.1    图像差分编码：降低数据的熵"></a>6.3.1    图像差分编码：降低数据的熵</h3><ol>
<li>简单差分算子：$d(x,y)=I(x,y)-I(x-1,y)$</li>
<li>离散二维拉普拉斯算子：$d(x,y)=4I(x,y)-I(x,y-1)-I(x,y+1)-I(x+1,y)-I(x-1,y)$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090726189.png" alt="image-20230317090726189" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317090750890.png" alt="image-20230317090750890" style="zoom:80%;" /></p>
<h3 id="6-3-2-无损JPEG"><a href="#6-3-2-无损JPEG" class="headerlink" title="6.3.2    无损JPEG"></a>6.3.2    无损JPEG</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317091521842.png" alt="image-20230317091521842" style="zoom:80%;" /></p>
<ol>
<li><p>JPEG中由很多种预测算法，目的是让预测尽可能的准确，从而让差分值接近0</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230317091313056.png" alt="image-20230317091313056" style="zoom:80%;" /></p>
</li>
</ol>
<h1 id="七、有损压缩算法"><a href="#七、有损压缩算法" class="headerlink" title="七、有损压缩算法"></a>七、有损压缩算法</h1><h2 id="7-2-损失测量-Distortion-Measures"><a href="#7-2-损失测量-Distortion-Measures" class="headerlink" title="7.2    损失测量 Distortion Measures"></a>7.2    损失测量 Distortion Measures</h2><h3 id="7-2-2-Distortion的数学测量"><a href="#7-2-2-Distortion的数学测量" class="headerlink" title="7.2.2    Distortion的数学测量"></a>7.2.2    Distortion的数学测量</h3><ol>
<li><p>MSE：Mean Square Error，越大损失越多</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322080849919.png" alt="image-20230322080849919" style="zoom:80%;" /></p>
</li>
<li><p>SNR：Signal-to-noise Ratio，越大损失越少</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322080926021.png" alt="image-20230322080926021" style="zoom:80%;" /></p>
</li>
<li><p>PSNR：Peak-signal-to-noise Ratio，越大损失越少</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322080935703.png" alt="image-20230322080935703" style="zoom:80%;" /></p>
</li>
</ol>
<h2 id="7-3-失真率"><a href="#7-3-失真率" class="headerlink" title="7.3    失真率"></a>7.3    失真率</h2><h3 id="7-3-2-R-D函数"><a href="#7-3-2-R-D函数" class="headerlink" title="7.3.2    R-D函数"></a>7.3.2    R-D函数</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322081052871.png" alt="image-20230322081052871" style="zoom:80%;" /></p>
<h2 id="7-4-量化-Quantization—产生损失"><a href="#7-4-量化-Quantization—产生损失" class="headerlink" title="7.4    量化 Quantization—产生损失"></a>7.4    量化 Quantization—产生损失</h2><h3 id="7-4-2-Uniform-Scalar-Quantization"><a href="#7-4-2-Uniform-Scalar-Quantization" class="headerlink" title="7.4.2    Uniform Scalar Quantization"></a>7.4.2    Uniform Scalar Quantization</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322081338775.png" alt="image-20230322081338775" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322081526737.png" alt="image-20230322081526737" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322081539088.png" alt="image-20230322081539088" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322081550567.png" alt="image-20230322081550567" style="zoom:80%;" /></p>
<h2 id="7-5-Transform-Coding"><a href="#7-5-Transform-Coding" class="headerlink" title="7.5    Transform Coding"></a>7.5    Transform Coding</h2><h3 id="7-5-1-基础思想"><a href="#7-5-1-基础思想" class="headerlink" title="7.5.1    基础思想"></a>7.5.1    基础思想</h3><ol>
<li>对于单个标量编码的效率，不如直接对整个向量编码<ol>
<li>因为压缩成向量之后，相邻数据的相关性更低</li>
</ol>
</li>
<li>如果存在一个线性变换<code>T</code>，将向量<code>X</code>变换为<code>Y</code>，且<code>Y</code>的相关性小于<code>X</code>，则对<code>Y</code>编码的效率更高<ol>
<li><code>T</code>不会导致信息的损失</li>
</ol>
</li>
<li><strong>DCT</strong>：离散余弦变换<ol>
<li>定义了一个长度为8的DCT</li>
<li>输入是长度为8的向量<strong>f(i)</strong>，输出为长度为8的向量<strong>F(u)</strong></li>
<li><strong>C(u)</strong>为一个常数</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322082330702.png" alt="image-20230322082330702" style="zoom:80%;" /></p>
<blockquote>
<p><strong>使用DCT压缩数据</strong></p>
</blockquote>
<ol>
<li>输入为：<code>X</code></li>
<li>做一次DCT变换：<code>Y = dct(X)</code></li>
<li>量化：<code>Z = Y(0:7)</code>，此处产生了<strong>信息损失</strong></li>
<li>编码：将<code>Z</code>使用无损编码，进行保存&amp;传输</li>
<li>解码：<code>X&#39; = idct(Z)</code></li>
</ol>
<p>目标：让<code>X&#39;</code>与<code>X</code>尽可能接近</p>
<h3 id="7-5-2-DCT：离散余弦变换-Discrete-Cosine-Transform"><a href="#7-5-2-DCT：离散余弦变换-Discrete-Cosine-Transform" class="headerlink" title="7.5.2    DCT：离散余弦变换 Discrete Cosine Transform"></a>7.5.2    DCT：离散余弦变换 Discrete Cosine Transform</h3><h4 id="7-5-2-1-一维DCT变换"><a href="#7-5-2-1-一维DCT变换" class="headerlink" title="7.5.2.1    一维DCT变换"></a>7.5.2.1    一维DCT变换</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322083459534.png" alt="image-20230322083459534" style="zoom:80%;" /></p>
<blockquote>
<p>将<strong>F(u)</strong>展开，<strong>f(i)</strong>前面的系数，相当于定义了一个线性变换的矩阵，并且只要<strong>u</strong>和<strong>N</strong>确定，矩阵就是一个常量</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322083654438.png" alt="image-20230322083654438" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322084012844.png" alt="image-20230322084012844" style="zoom:80%;" /></p>
<h4 id="7-5-2-2-在三维空间的DCT变换示例"><a href="#7-5-2-2-在三维空间的DCT变换示例" class="headerlink" title="7.5.2.2    在三维空间的DCT变换示例"></a>7.5.2.2    在三维空间的DCT变换示例</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322084258908.png" alt="image-20230322084258908" style="zoom:80%;" /></p>
<h4 id="7-5-2-3-DCT是正交线性变换，即不同行向量的内积为0"><a href="#7-5-2-3-DCT是正交线性变换，即不同行向量的内积为0" class="headerlink" title="7.5.2.3    DCT是正交线性变换，即不同行向量的内积为0"></a>7.5.2.3    DCT是正交线性变换，即不同行向量的内积为0</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322084525428.png" alt="image-20230322084525428" style="zoom:80%;" /></p>
<h4 id="7-5-2-4-DCT是线性变换，满足加法性质：-T-alpha-p-beta-q-alpha-p-beta-q"><a href="#7-5-2-4-DCT是线性变换，满足加法性质：-T-alpha-p-beta-q-alpha-p-beta-q" class="headerlink" title="7.5.2.4    DCT是线性变换，满足加法性质：$T(\alpha p+ \beta q) = \alpha p + \beta q$"></a>7.5.2.4    DCT是线性变换，满足加法性质：$T(\alpha p+ \beta q) = \alpha p + \beta q$</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322085340281.png" alt="image-20230322085340281" style="zoom:80%;" /></p>
<h4 id="7-5-2-5-DCT的物理含义：给定任意一个输入信号，告诉该信号是如何有基信号组合而成的"><a href="#7-5-2-5-DCT的物理含义：给定任意一个输入信号，告诉该信号是如何有基信号组合而成的" class="headerlink" title="7.5.2.5    DCT的物理含义：给定任意一个输入信号，告诉该信号是如何有基信号组合而成的"></a>7.5.2.5    DCT的物理含义：给定任意一个输入信号，告诉该信号是如何有基信号组合而成的</h4><blockquote>
<ol>
<li>原始信号 = 基向量的线性组合</li>
<li>F[0]为DC系数，表示原始信号的直流系数；其他信号为AC系数，表示原始信号的交流系数<ol>
<li>DC = 0，表示原始信号没有直流分量</li>
<li>只有DC不为0，表示原始信号为直流信号</li>
<li>如果DC为负数，则说明输入信号的平均值 &lt; 0</li>
<li>如果AC为负数，说明输入信号与基信号的相位，相差半个周期</li>
</ol>
</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322085639314.png" alt="image-20230322085639314" style="zoom:80%;" /></p>
<h4 id="7-5-2-6-2维DCT变换：定义了一组基矩阵"><a href="#7-5-2-6-2维DCT变换：定义了一组基矩阵" class="headerlink" title="7.5.2.6    2维DCT变换：定义了一组基矩阵"></a>7.5.2.6    2维DCT变换：定义了一组基矩阵</h4><ol>
<li>计算方法：将输入信号，与每一个基矩阵做卷积(对应元素相乘求和)，然后将值写入对应位置<ol>
<li>正向变换：信号分解</li>
<li>逆向变换：信号组合</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322090401375.png" alt="image-20230322090401375" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322090541374.png" alt="image-20230322090541374" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322090716705.png" alt="image-20230322090716705" style="zoom: 80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322090839297.png" alt="image-20230322090839297" style="zoom:80%;" /></p>
<h3 id="7-5-2-6-DFT：离散傅里叶变换"><a href="#7-5-2-6-DFT：离散傅里叶变换" class="headerlink" title="7.5.2.6    DFT：离散傅里叶变换"></a>7.5.2.6    DFT：离散傅里叶变换</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322091029900.png" alt="image-20230322091029900" style="zoom:80%;" /></p>
<h2 id="7-6-Wavelet-Based-Coding-小波变换"><a href="#7-6-Wavelet-Based-Coding-小波变换" class="headerlink" title="7.6    Wavelet-Based Coding 小波变换"></a>7.6    Wavelet-Based Coding 小波变换</h2><h3 id="7-6-2-小波变换示例"><a href="#7-6-2-小波变换示例" class="headerlink" title="7.6.2    小波变换示例"></a>7.6.2    小波变换示例</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322091338669.png" alt="image-20230322091338669" style="zoom:80%;" /></p>
<h3 id="7-6-3-一维Harr变换"><a href="#7-6-3-一维Harr变换" class="headerlink" title="7.6.3    一维Harr变换"></a>7.6.3    一维Harr变换</h3><ol>
<li>设原始信号为：<code>&#123;a1,a2,a3,a4,a5,a6,a7,a8&#125;</code></li>
<li>做1次变换：<code>&#123;a12,a34,a56,a78,d12,d34,d56,d78&#125;</code></li>
<li>做2次变换：<code>&#123;a12,a34,a56,a78,d12,d34,d56,d78&#125;</code></li>
</ol>
<h3 id="7-6-4-二维Harr变换"><a href="#7-6-4-二维Harr变换" class="headerlink" title="7.6.4    二维Harr变换"></a>7.6.4    二维Harr变换</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322091903391.png" alt="image-20230322091903391" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230322091929269.png" alt="image-20230322091929269" style="zoom:80%;" /></p>
<h1 id="八、图像压缩标准"><a href="#八、图像压缩标准" class="headerlink" title="八、图像压缩标准"></a>八、图像压缩标准</h1><h2 id="8-1-JPEG标准"><a href="#8-1-JPEG标准" class="headerlink" title="8.1    JPEG标准"></a>8.1    JPEG标准</h2><blockquote>
<p>Joint Photographic Experts Group</p>
</blockquote>
<ol>
<li>标准名：ISO 10918-1</li>
<li>JEPG定义了图像的有损 &amp; 无损压缩的流程及方法</li>
<li>图像：是一个二位函数</li>
<li>图像的有损压缩，即对图像做2D DCT变换</li>
<li>观测到的三个事实<ol>
<li>图像具有空间冗余性，在某个较小的区域内，像素的颜色值变化不会很大</li>
<li>心理学实验告诉我们，人的视觉系统对于低频部分变化的感知能力，大于对于高频部分变化的感知能力：即对于<strong>低频信号</strong>敏感，高频信号不敏感</li>
<li>人的视觉系统，对于<strong>明暗</strong>变化的敏感度，大于对于色彩的敏感度</li>
</ol>
</li>
</ol>
<h3 id="8-1-1-JEPG压缩步骤"><a href="#8-1-1-JEPG压缩步骤" class="headerlink" title="8.1.1    JEPG压缩步骤"></a>8.1.1    JEPG压缩步骤</h3><ol>
<li>将RGB转换为YIQ/YUV，然后对颜色进行<strong>下采样</strong>：出现损失<ol>
<li>会有三个矩阵：一个较大的Y矩阵，两个较小的IQ/UV矩阵</li>
</ol>
</li>
<li>对图像矩阵进行DCT变换</li>
<li>进行<strong>量化</strong>：出现损失</li>
<li>Zigzag排序</li>
<li>对DC信号进行DPCM编码</li>
<li>对AC信号进行RLE编码</li>
<li>最后，进行熵编码</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324081842470.png" alt="image-20230324081842470" style="zoom:80%;" /></p>
<h4 id="8-1-1-1-DCT"><a href="#8-1-1-1-DCT" class="headerlink" title="8.1.1.1    DCT"></a>8.1.1.1    DCT</h4><ol>
<li>对图像切分为8×8的块，然后进行2D DCT变换<ol>
<li>8×8是对准确率和计算效率的折中</li>
<li>块很大时，会出现马赛克效应</li>
</ol>
</li>
</ol>
<h4 id="8-1-1-2-量化"><a href="#8-1-1-2-量化" class="headerlink" title="8.1.1.2    量化"></a>8.1.1.2    量化</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324082307174.png" alt="image-20230324082307174" style="zoom:80%;" /></p>
<ol>
<li>量化时，不同层使用的量化矩阵不同<ol>
<li>量化矩阵是通过心理学实验测出来的</li>
<li>灰度层的量化表更细，颜色层的量化表更粗</li>
</ol>
</li>
<li>将图像矩阵<code>F(u,v)</code>与量化矩阵<code>Q(u,v)</code>对应元素相除，然后取整</li>
</ol>
<h4 id="8-1-1-3-Zigzag展开"><a href="#8-1-1-3-Zigzag展开" class="headerlink" title="8.1.1.3    Zigzag展开"></a>8.1.1.3    Zigzag展开</h4><ol>
<li>将8×8的矩阵，展开为长度64的向量</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324083857493.png" alt="image-20230324083857493" style="zoom:80%;" /></p>
<h4 id="8-1-1-4-对AC信号做RLE编码"><a href="#8-1-1-4-对AC信号做RLE编码" class="headerlink" title="8.1.1.4    对AC信号做RLE编码"></a>8.1.1.4    对AC信号做RLE编码</h4><ol>
<li>RLE：游程编码</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324083951302.png" alt="image-20230324083951302" style="zoom:80%;" /></p>
<h4 id="8-1-1-5-对DC信号做DPCM编码"><a href="#8-1-1-5-对DC信号做DPCM编码" class="headerlink" title="8.1.1.5    对DC信号做DPCM编码"></a>8.1.1.5    对DC信号做DPCM编码</h4><ol>
<li>将整张图的所有DC信号取出来，再做DPCM差分预测编码</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324084211225.png" alt="image-20230324084211225" style="zoom:80%;" /></p>
<h4 id="8-1-1-6-对结果做熵编码"><a href="#8-1-1-6-对结果做熵编码" class="headerlink" title="8.1.1.6    对结果做熵编码"></a>8.1.1.6    对结果做熵编码</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230324084312061.png" alt="image-20230324084312061" style="zoom:80%;" /></p>
<h3 id="8-1-2-JPEG模式"><a href="#8-1-2-JPEG模式" class="headerlink" title="8.1.2    JPEG模式"></a>8.1.2    JPEG模式</h3><h4 id="8-1-2-1-顺序模式-Sequential"><a href="#8-1-2-1-顺序模式-Sequential" class="headerlink" title="8.1.2.1    顺序模式 Sequential"></a>8.1.2.1    顺序模式 Sequential</h4><p>JPEG的默认模式</p>
<ol>
<li>对图像进行编码时，使用从左到右，从上到下扫描方式</li>
<li>图像会从上到下依次显示</li>
</ol>
<h4 id="8-1-2-2-渐进模式-Progressive"><a href="#8-1-2-2-渐进模式-Progressive" class="headerlink" title="8.1.2.2    渐进模式 Progressive"></a>8.1.2.2    渐进模式 Progressive</h4><ol>
<li>方法一：先传输每一块的低频部分，然后传输每一块的高频部分<ol>
<li>解码时，先解码低频信号，然后解码高频信号，将后面的解码结果叠加到原来的图像上</li>
</ol>
</li>
<li>方法二：由于已经编码为二进制数，因此可以按每一个系数的位，依次传递<ol>
<li>比如，可以先传输二进制数的最高位，然后依次传输后面的位</li>
</ol>
</li>
<li>图像会由模糊变得清晰</li>
</ol>
<h4 id="8-1-2-3-层次模式-Hierarchical"><a href="#8-1-2-3-层次模式-Hierarchical" class="headerlink" title="8.1.2.3    层次模式 Hierarchical"></a>8.1.2.3    层次模式 Hierarchical</h4><ol>
<li>将图像做多次下采样</li>
<li>传输时，按层次传输，每一次传输与上一层的差值</li>
</ol>
<h4 id="8-1-2-4-无损模式-Lossless"><a href="#8-1-2-4-无损模式-Lossless" class="headerlink" title="8.1.2.4    无损模式 Lossless"></a>8.1.2.4    无损模式 Lossless</h4><ol>
<li>使用差分预测编码，而不是DCT编码</li>
</ol>
<h2 id="8-2-JEPG2000标准"><a href="#8-2-JEPG2000标准" class="headerlink" title="8.2    JEPG2000标准"></a>8.2    JEPG2000标准</h2><ol>
<li>同时提供了有损、无损两种形式</li>
<li>可以进行分区域编码：<strong>ROI</strong>(Region of insterest)，不同区域使用不同的压缩矩阵</li>
</ol>
<h1 id="九、基础视频压缩算法"><a href="#九、基础视频压缩算法" class="headerlink" title="九、基础视频压缩算法"></a>九、基础视频压缩算法</h1><h2 id="9-1-Introduction"><a href="#9-1-Introduction" class="headerlink" title="9.1    Introduction"></a>9.1    Introduction</h2><p>三个可以压缩的方向：</p>
<ol>
<li><p>空间信息冗余性：冗余度较小</p>
</li>
<li><p>颜色信息：将RGB转成YUV，然后再进行下采样</p>
</li>
<li><p>时间信息冗余性</p>
<ol>
<li><p>预测编码：假设第二帧和第一帧一样，传输差值，但是可能相邻两帧相差很大</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329081906495.png" alt="image-20230329081906495" style="zoom:80%;" /></p>
</li>
<li><p>因此不能直接对整张图像做差分，而是先将<strong>当前帧</strong>划分为16×16的<strong>宏块</strong>(Macro Block)，到前一帧找到与它类似的宏块，然后再进行差分计算</p>
<ol>
<li>传输时，既要传输残差，也要传输每个宏块对应的上一帧的部分，与当前宏块的位移差</li>
<li>位移称为<strong>运动向量</strong></li>
<li>如果找不到，则直接传输当前宏块</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329082954544.png" alt="image-20230329082954544" style="zoom:80%;" /></p>
</li>
</ol>
</li>
</ol>
<h2 id="9-2-基于运动补偿的视频压缩"><a href="#9-2-基于运动补偿的视频压缩" class="headerlink" title="9.2    基于运动补偿的视频压缩"></a>9.2    基于运动补偿的视频压缩</h2><h3 id="9-2-1-时间冗余性"><a href="#9-2-1-时间冗余性" class="headerlink" title="9.2.1    时间冗余性"></a>9.2.1    时间冗余性</h3><ol>
<li>相邻的帧，通常很相似，因此需要通过差分信息进行编码</li>
<li>相邻两帧的差异，通常由于摄像机/物体的运动</li>
<li>基础思想：检测相邻两帧对应位置的差异<ol>
<li>运动估计：判断哪两个宏块为对应位置</li>
<li>运动补偿：计算对应宏块的差异</li>
</ol>
</li>
<li>两种帧：<ol>
<li>Intra-Frame I帧：独立编码，不做运动估计&amp;补偿</li>
<li>Inter-Frame：使用运动估计&amp;补偿进行压缩<ol>
<li>P帧：参考帧在前面</li>
<li>B帧：参考帧同时在前面&amp;后面</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="9-2-2-运动补偿-Motion-Compensation"><a href="#9-2-2-运动补偿-Motion-Compensation" class="headerlink" title="9.2.2    运动补偿 Motion Compensation"></a>9.2.2    运动补偿 Motion Compensation</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329083808182.png" alt="image-20230329083808182" style="zoom:80%;" /></p>
<p>运动估计：</p>
<ol>
<li>以当前<strong>宏块 macroblocks</strong>所在位置为中心，划定一个<strong>区域</strong> (如 2p+1 × 2p+1)，在该区域内进行搜索</li>
<li>如果能找到<strong>中心点</strong>在该区域，且与当前宏块类似，则停止该过程</li>
<li>计算当前宏块与对应位置的位移，称为<strong>运动向量</strong></li>
</ol>
<p>运动补偿：</p>
<ol>
<li>运动向量搜索</li>
<li>基于运动补偿的预测</li>
<li>对残差进行编码</li>
</ol>
<h2 id="9-3-搜索运动向量"><a href="#9-3-搜索运动向量" class="headerlink" title="9.3    搜索运动向量"></a>9.3    搜索运动向量</h2><h3 id="9-3-1-判断是否匹配"><a href="#9-3-1-判断是否匹配" class="headerlink" title="9.3.1    判断是否匹配"></a>9.3.1    判断是否匹配</h3><ol>
<li>C：当前帧</li>
<li>R：参考帧</li>
<li>判断是否相同：对应位置求差，然后将绝对值加和</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329085311384.png" alt="image-20230329085311384" style="zoom:80%;" /></p>
<h3 id="9-3-2-顺序搜索-Sequential-Search"><a href="#9-3-2-顺序搜索-Sequential-Search" class="headerlink" title="9.3.2    顺序搜索 Sequential Search"></a>9.3.2    顺序搜索 Sequential Search</h3><ol>
<li>每次移动<strong>中心像素</strong>，每次移动一个像素</li>
<li>优点：可以在搜索区域内找到最优解</li>
<li>缺点：时间太长</li>
</ol>
<h3 id="9-3-3-2维对数搜索-2D-Logarithmic-search"><a href="#9-3-3-2维对数搜索-2D-Logarithmic-search" class="headerlink" title="9.3.3    2维对数搜索 2D-Logarithmic-search"></a>9.3.3    2维对数搜索 2D-Logarithmic-search</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329085943406.png" alt="image-20230329085943406" style="zoom:80%;" /></p>
<ol>
<li>以对应位置为中心，划定搜索范围，在整个范围内，均匀采样9个块</li>
<li>以最小的块为中心，搜索范围减半，均匀采样9个块，计算差值</li>
<li>重复第2步，直到搜索几次之后停止</li>
<li>优点：快</li>
<li>缺点：不一定能找到最优解</li>
</ol>
<h3 id="9-3-4-层次搜索-Hierarchical-Search"><a href="#9-3-4-层次搜索-Hierarchical-Search" class="headerlink" title="9.3.4    层次搜索 Hierarchical Search"></a>9.3.4    层次搜索 Hierarchical Search</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329090155354.png" alt="image-20230329090155354" style="zoom:80%;" /></p>
<ol>
<li>先进行下采样，在低层次中使用较小的块，找到与之相似的块，返回到上一层求精</li>
</ol>
<h2 id="9-4-H-261"><a href="#9-4-H-261" class="headerlink" title="9.4    H.261"></a>9.4    H.261</h2><h3 id="9-4-1-总览"><a href="#9-4-1-总览" class="headerlink" title="9.4.1    总览"></a>9.4.1    总览</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329090717872.png" alt="image-20230329090717872" style="zoom:80%;" /></p>
<ol>
<li>箭头：从箭头的尾帧推出箭头的指向帧</li>
<li><strong>I帧</strong>：独立帧，只去除空间冗余性</li>
<li><strong>P帧</strong>：根据前一帧进行预测<ol>
<li>运动向量搜索只在Y层上做</li>
<li>差分在Y、U、V上均要做</li>
<li>对<strong>运动向量</strong>也要做差分预测编码</li>
</ol>
</li>
</ol>
<h3 id="9-4-2-Intra-Frame-Coding"><a href="#9-4-2-Intra-Frame-Coding" class="headerlink" title="9.4.2    Intra-Frame Coding"></a>9.4.2    Intra-Frame Coding</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091224103.png" alt="image-20230329091224103" style="zoom:80%;" /></p>
<h3 id="9-4-3-Inter-Frame-predictive-Coding"><a href="#9-4-3-Inter-Frame-predictive-Coding" class="headerlink" title="9.4.3    Inter-Frame predictive Coding"></a>9.4.3    Inter-Frame predictive Coding</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091353730.png" alt="image-20230329091353730" style="zoom:80%;" /></p>
<h3 id="9-4-4-量化"><a href="#9-4-4-量化" class="headerlink" title="9.4.4    量化"></a>9.4.4    量化</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091801118.png" alt="image-20230329091801118" style="zoom:80%;" /></p>
<h3 id="9-4-5-整个过程"><a href="#9-4-5-整个过程" class="headerlink" title="9.4.5    整个过程"></a>9.4.5    整个过程</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091826070.png" alt="image-20230329091826070" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091834234.png" alt="image-20230329091834234" style="zoom:80%;" /></p>
<h3 id="9-4-6-H-261-视频Bit流"><a href="#9-4-6-H-261-视频Bit流" class="headerlink" title="9.4.6    H.261 视频Bit流"></a>9.4.6    H.261 视频Bit流</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329091959599.png" alt="image-20230329091959599" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230329092011224.png" alt="image-20230329092011224" style="zoom:80%;" /></p>
<h2 id="9-5-H-263"><a href="#9-5-H-263" class="headerlink" title="9.5    H.263"></a>9.5    H.263</h2><ol>
<li>在宏块划分的基础上，允许对MV进行预测编码<ol>
<li>MV一定是无损压缩，仅仅是降低信息的熵</li>
</ol>
</li>
<li>在运动预测时，允许每次移动半个像素查找<ol>
<li>原本是每次只能移动一个像素，然后对应位判断差值</li>
<li>移动半个像素后，需要对像素进行差值</li>
<li>类似于提高了图像的分辨率</li>
</ol>
</li>
<li>可以将参考帧的边缘进行延展，从而实现不受限的匹配<ol>
<li>将边界进行复制</li>
</ol>
</li>
<li>使用算数编码</li>
<li>宏块的大小更加灵活</li>
<li>可以进行双向预测<ol>
<li>在前面的帧、后面的帧中均可找到一个相似的宏块</li>
<li>视频编解码可以有一定的延迟，因此可以等后面的帧出现了再进行预测</li>
<li>做残差时，与前后两个参考帧做残差，然后再做平均</li>
</ol>
</li>
</ol>
<h1 id="十、MPEG视频编码"><a href="#十、MPEG视频编码" class="headerlink" title="十、MPEG视频编码"></a>十、MPEG视频编码</h1><h2 id="10-1-MPEG-1"><a href="#10-1-MPEG-1" class="headerlink" title="10.1    MPEG-1"></a>10.1    MPEG-1</h2><ol>
<li>只支持逐行扫描</li>
<li>4:2:0的色彩下采样</li>
</ol>
<h3 id="10-1-1-运动补偿"><a href="#10-1-1-运动补偿" class="headerlink" title="10.1.1    运动补偿"></a>10.1.1    运动补偿</h3><ol>
<li>从前向的的I帧/P帧进行预测，可以跳帧匹配，从而找到更优匹配</li>
<li>也可以做双向预测，会乱序传递帧，但是可以通过帧编号确定顺序<ol>
<li>前后参考帧先求平均，然后再与预测帧做残差</li>
<li>如果找不到，可以直接舍弃该参考帧</li>
</ol>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230331083354656.png" alt="image-20230331083354656" style="zoom:80%;" /></p>
<h3 id="10-1-2-MPEG-1与H-261区别"><a href="#10-1-2-MPEG-1与H-261区别" class="headerlink" title="10.1.2    MPEG-1与H.261区别"></a>10.1.2    MPEG-1与H.261区别</h3><p>支持的视频格式不同：</p>
<ol>
<li>H.261支持CIF、QCIF</li>
<li>MPEG-1支持SIF</li>
</ol>
<p>数据格式不同</p>
<ol>
<li>H.261将图像序列划分为了GOB</li>
<li>MPEG-1将图像序列划分为了slices<ol>
<li>不同slices之间相互独立，一个slice坏了，不影响其他区域的显示</li>
</ol>
</li>
</ol>
<p>量化不同</p>
<ol>
<li>H.261使用了很大的系数，直接进行压缩</li>
<li>MPEG-1使用了量化表，并且添加了缩放系数，可以压缩的更狠一点</li>
</ol>
<p>搜索范围不同</p>
<ol>
<li>H.261是[-15, 15]像素</li>
<li>MPEG-1是[-512, 511.5]像素，并且可以进行半像素搜索</li>
</ol>
<p>MPEG-1可以随机访问，因为有GOP(Group Of Picture)</p>
<ol>
<li>将一段时间的视频帧打包到一起</li>
</ol>
<h3 id="10-1-3-MPEG-1视频比特流"><a href="#10-1-3-MPEG-1视频比特流" class="headerlink" title="10.1.3    MPEG-1视频比特流"></a>10.1.3    MPEG-1视频比特流</h3><p>GOP层 =&gt; 帧 =&gt; Slice(Block的组合) =&gt; Macroblock =&gt; Block</p>
<h2 id="10-2-MPEG-2"><a href="#10-2-MPEG-2" class="headerlink" title="10.2    MPEG-2"></a>10.2    MPEG-2</h2><h3 id="10-2-1-总览"><a href="#10-2-1-总览" class="headerlink" title="10.2.1    总览"></a>10.2.1    总览</h3><ol>
<li>定义了7种profiles，针对不同的应用，每个profile定义了最多4个画质等级</li>
</ol>
<h3 id="10-2-2-支持隔行扫描"><a href="#10-2-2-支持隔行扫描" class="headerlink" title="10.2.2    支持隔行扫描"></a>10.2.2    支持隔行扫描</h3><ol>
<li>Frame-picture：完整的一帧<ol>
<li>Top-field：奇数场图像</li>
<li>bottom-field：偶数场图像</li>
<li>称为Field-picture</li>
</ol>
</li>
<li>奇数场的参考帧，可能是奇数场，也可能是偶数场</li>
<li>偶数场也一样</li>
</ol>
<p>5种预测模式</p>
<ol>
<li>Frame prediction for frame-pictures：<ol>
<li>对完整帧进行预测</li>
</ol>
</li>
<li>Field prediction for field-pictures：<ol>
<li>可以跨场预测</li>
</ol>
</li>
<li>Field prediction for frame-pictures：<ol>
<li>将奇数场和偶数场完全分离</li>
</ol>
</li>
<li>16 × 8场图像预测<ol>
<li>宏块大小为16×8</li>
</ol>
</li>
<li>Dual-prime for P-pictures</li>
</ol>
<p>Zigzag展开的方式也不太一样</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230331090541377.png" alt="image-20230331090541377" style="zoom:80%;" /></p>
<h3 id="10-2-3-MPEG-2-Scalabilities-可伸缩性"><a href="#10-2-3-MPEG-2-Scalabilities-可伸缩性" class="headerlink" title="10.2.3    MPEG-2 Scalabilities 可伸缩性"></a>10.2.3    MPEG-2 Scalabilities 可伸缩性</h3><h4 id="10-2-3-1-可伸缩编码-Scalable-Coding"><a href="#10-2-3-1-可伸缩编码-Scalable-Coding" class="headerlink" title="10.2.3.1    可伸缩编码 Scalable Coding"></a>10.2.3.1    可伸缩编码 Scalable Coding</h4><p>基本思想：</p>
<ol>
<li>将图像划分为Base Layer 和 Enhancement Layer<ol>
<li>将原有视频降低分辨率，得到Base Layer</li>
<li>再将Base Layer放大回去，与原视频做差，得到Enhancement Layer</li>
<li>Base Layer只有一个，但是Enhancement Layer可以有多个</li>
</ol>
</li>
<li>将这两层作为两个视频序列进行传输</li>
<li>接收端可以选择只接收Base Layer，或者两个都接受</li>
<li>两个都接受时，将Enhancement Layer叠加到Base Layer上即可</li>
</ol>
<h4 id="10-2-3-2-SNR可伸缩"><a href="#10-2-3-2-SNR可伸缩" class="headerlink" title="10.2.3.2    SNR可伸缩"></a>10.2.3.2    SNR可伸缩</h4><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230331091643001.png" alt="image-20230331091643001" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230331091732289.png" alt="image-20230331091732289" style="zoom:80%;" /></p>
<h4 id="10-2-3-3-空间可伸缩"><a href="#10-2-3-3-空间可伸缩" class="headerlink" title="10.2.3.3    空间可伸缩"></a>10.2.3.3    空间可伸缩</h4><ol>
<li>先进行下采样，得到基础层</li>
<li>然后再进行上采样，再与原有图像做差，得到增强层</li>
</ol>
<h4 id="10-2-3-4-时间可伸缩"><a href="#10-2-3-4-时间可伸缩" class="headerlink" title="10.2.3.4    时间可伸缩"></a>10.2.3.4    时间可伸缩</h4><ol>
<li>直接按照时间顺序，将一部分帧作为基础层，一部分帧作为增强层</li>
</ol>
<h4 id="10-2-3-5-数据划分"><a href="#10-2-3-5-数据划分" class="headerlink" title="10.2.3.5    数据划分"></a>10.2.3.5    数据划分</h4><ol>
<li>昨晚DCT变换后，进行Zigzag展开</li>
<li>将前一部分数据，作为基础层进行传输</li>
<li>将后面的数据，切分为若干个部分，作为增强层，进行传输</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230331092120370.png" alt="image-20230331092120370" style="zoom:80%;" /></p>
<h3 id="10-2-4-其他区别"><a href="#10-2-4-其他区别" class="headerlink" title="10.2.4    其他区别"></a>10.2.4    其他区别</h3><ol>
<li>MPEG-2有更好的容错率</li>
<li>MPEG-2既可以4:2:0，也可以4:2:2、4:4:4</li>
<li>Slice的划分不能跨越一行</li>
</ol>
<h1 id="十一、MPEG视频编码Ⅱ"><a href="#十一、MPEG视频编码Ⅱ" class="headerlink" title="十一、MPEG视频编码Ⅱ"></a>十一、MPEG视频编码Ⅱ</h1><h2 id="11-1-MPEG-4"><a href="#11-1-MPEG-4" class="headerlink" title="11.1    MPEG-4"></a>11.1    MPEG-4</h2><h3 id="11-1-1-概览"><a href="#11-1-1-概览" class="headerlink" title="11.1.1    概览"></a>11.1.1    概览</h3><ol>
<li><p>一个更新的标准，除了压缩，还支持数据的上传</p>
</li>
<li><p>是基于对象的编码<strong>object-based coding</strong></p>
<ol>
<li>提高<strong>压缩比</strong></li>
<li>便于对视频的内容进行<strong>再加工</strong>，即交互行为</li>
<li>静态图像编码</li>
<li>Face对象编码、动画</li>
<li>Body对象编码、动画</li>
</ol>
</li>
<li><p>bit率：5kbps ~ 10 Mbps</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407081343431.png" alt="image-20230407081343431" style="zoom:80%;" /></p>
</li>
<li><p>分离对象 =&gt; 对每个对象分别编码压缩 =&gt; 每个对象单独编码然后叠加</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407081256203.png" alt="image-20230407081256203" style="zoom:80%;" /></p>
</li>
<li><p>MPEG-4是一种全新的标准，可以支持：</p>
<ol>
<li>组合视频对象，从而创建出预期的场景</li>
<li>支持对视频不同质量的服务QoS</li>
<li>与音视频场景进行交互</li>
</ol>
</li>
<li><p>MPEG-4的结构：</p>
<ol>
<li>VS</li>
<li>VO</li>
<li>VOL：为了实现可伸缩编码，共享系数的GOV</li>
<li>GOV：相邻的一组VOP</li>
<li>VOP：某个时刻对于某个VO的一个快照</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407082043835.png" alt="image-20230407082043835" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="11-1-2-基于对象的编码"><a href="#11-1-2-基于对象的编码" class="headerlink" title="11.1.2    *基于对象的编码"></a>11.1.2    *基于对象的编码</h3><h4 id="11-1-2-1-Frame-Based-Coding-vs-VOP-Based-Coding"><a href="#11-1-2-1-Frame-Based-Coding-vs-VOP-Based-Coding" class="headerlink" title="11.1.2.1    Frame-Based Coding vs VOP-Based Coding"></a>11.1.2.1    Frame-Based Coding vs VOP-Based Coding</h4><ol>
<li><p>MPEG-1&amp;MPEG-2：基于块的运动估计，没有VOP的概念，直接对帧进行切割</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407082534795.png" alt="image-20230407082534795" style="zoom:80%;" /></p>
</li>
<li><p>MPEG-4：首先将帧分为Object，然后对不同的Object序列进行编码</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407082737695.png" alt="image-20230407082737695" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="11-1-2-2-VOP-Based-Coding"><a href="#11-1-2-2-VOP-Based-Coding" class="headerlink" title="11.1.2.2    VOP-Based Coding"></a>11.1.2.2    VOP-Based Coding</h4><ol>
<li><p>依旧是使用运动向量估计的方法，进行压缩</p>
<ol>
<li>运动估计</li>
<li>基于运动向量的预测</li>
<li>对残差进行编码</li>
</ol>
</li>
<li><p>也有I帧、P帧、B帧的概念</p>
</li>
<li><p>VOP会有不同的形状，最好对于形状和纹理分别编码</p>
</li>
<li><p>使用宏块将框出对象的包围盒</p>
<ol>
<li>包围盒的大小一定是宏块的整数倍</li>
<li>内部宏块：完全在对象内部的宏块 ==&gt; 直接进行编码</li>
<li>边缘宏块：一部分在对象内，一部分在对象外 ==&gt; 存在没有定义的像素，需要进行padding</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407083251149.png" alt="image-20230407083251149" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="11-1-2-3-Motion-Compensation"><a href="#11-1-2-3-Motion-Compensation" class="headerlink" title="11.1.2.3    Motion Compensation"></a>11.1.2.3    Motion Compensation</h4><ol>
<li><p>对于边缘宏块，在目标帧和参考帧之间，会存在没有定义的像素的预测，需要进行padding</p>
<ol>
<li>即填充像素的值，使得边缘宏块填充完整</li>
<li>水平填充、垂直填充：对边缘像素进行延申</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407083902071.png" alt="image-20230407083902071" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="11-1-2-4-纹理编码"><a href="#11-1-2-4-纹理编码" class="headerlink" title="11.1.2.4    纹理编码"></a>11.1.2.4    纹理编码</h4><ol>
<li><p>I-VOP：和JPEG的编码相同</p>
</li>
<li><p>P-VOP、B-VOP：需要进行编码</p>
</li>
<li><p>SA-DCT变换：</p>
<ol>
<li>先将图像推到上面，然后对每一列进行DCT变换</li>
<li>然后将图像推导左边，然后对每一行进行DCT变换</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407084222031.png" alt="image-20230407084222031" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="11-1-2-5-形状编码"><a href="#11-1-2-5-形状编码" class="headerlink" title="11.1.2.5    形状编码"></a>11.1.2.5    形状编码</h4><ol>
<li>恢复原图像时，仅有纹理信息是不够的，还需要有形状信息：<ol>
<li>对<strong>形状</strong>也进行DCT变换，记录下来</li>
<li>二元编码 Binary Shape coding</li>
<li>灰度编码 gray scale coding</li>
</ol>
</li>
</ol>
<h4 id="11-1-2-6-静态纹理压缩-Static-Texture-Coding"><a href="#11-1-2-6-静态纹理压缩-Static-Texture-Coding" class="headerlink" title="11.1.2.6    静态纹理压缩 Static Texture Coding"></a>11.1.2.6    静态纹理压缩 Static Texture Coding</h4><ol>
<li>使用<strong>小波变换</strong>进行编码</li>
</ol>
<h4 id="11-1-2-7-动态编码-Sprite-Coding"><a href="#11-1-2-7-动态编码-Sprite-Coding" class="headerlink" title="11.1.2.7    动态编码 Sprite Coding"></a>11.1.2.7    动态编码 Sprite Coding</h4><ol>
<li>可以将图像分为背景+运动物体的合成</li>
<li>对背景、运动物体分别处理<ol>
<li>背景：将大背景全部传过去，在每一帧时，修正相机的姿态，选取对应的位置</li>
<li>运动物体：正常编码</li>
<li>每一帧，将选中的背景与运动物体合成到一起</li>
</ol>
</li>
</ol>
<h3 id="11-1-3-动态物体编码"><a href="#11-1-3-动态物体编码" class="headerlink" title="11.1.3    动态物体编码"></a>11.1.3    动态物体编码</h3><ol>
<li><p>先将整个形象传过去，然后只需要传输人物的姿态变化</p>
<ol>
<li>第一帧：对角色进行网格剖分</li>
<li>之后每一帧：传输运动信息</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230407085901742.png" alt="image-20230407085901742" style="zoom:80%;" /></p>
</li>
</ol>
<h1 id="十二、基于内容的多媒体检索"><a href="#十二、基于内容的多媒体检索" class="headerlink" title="十二、基于内容的多媒体检索"></a>十二、基于内容的多媒体检索</h1><h2 id="12-1-CBMR：基于内容的多媒体检索"><a href="#12-1-CBMR：基于内容的多媒体检索" class="headerlink" title="12.1    CBMR：基于内容的多媒体检索"></a>12.1    CBMR：基于内容的多媒体检索</h2><ol>
<li>用于检索到各种类型的多媒体数据</li>
<li>包含图像、视频、音频、物理等</li>
<li>基于物理内容、语义内容，而不是字符串匹配</li>
</ol>
<p>CBMR的基础方法</p>
<ol>
<li>对多媒体数据进行表示</li>
<li>特称抽取</li>
<li>相似度匹配</li>
<li>结果排序</li>
<li>用户反馈</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230412081908864.png" alt="image-20230412081908864" style="zoom:80%;" /></p>
<h2 id="12-2-CBIR：基于内容的图像检索"><a href="#12-2-CBIR：基于内容的图像检索" class="headerlink" title="12.2    CBIR：基于内容的图像检索"></a>12.2    CBIR：基于内容的图像检索</h2><p>给定一个查询图像，返回与之相似的图像</p>
<ol>
<li>由于图像的尺寸不同，因此需要提取图像的有效特征<strong>features</strong></li>
<li>基于抽象特征，做索引</li>
<li>定义两个特征的相似度评价</li>
</ol>
<p>语义鸿沟 Semantic Gap</p>
<ol>
<li>如何让计算机理解图像/视频的内容</li>
<li>如何判断高维图像和低维语义之间的关系</li>
</ol>
<h3 id="12-2-1-特征"><a href="#12-2-1-特征" class="headerlink" title="12.2.1    特征"></a>12.2.1    特征</h3><p>用内容特征表示图像</p>
<ol>
<li><p>颜色</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230412083118857.png" alt="image-20230412083118857" style="zoom:80%;" /></p>
</li>
<li><p>形状</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230412083201460.png" alt="image-20230412083201460" style="zoom:80%;" /></p>
</li>
<li><p>纹理</p>
</li>
</ol>
<h3 id="12-2-2-相似度计算"><a href="#12-2-2-相似度计算" class="headerlink" title="12.2.2    相似度计算"></a>12.2.2    相似度计算</h3><p>用向量表示特征</p>
<ol>
<li>图像1：$I = [f<em>{11}\ f</em>{12}\ …\ f_{1n}]$</li>
<li>图像2：$Q = [f<em>{21}\ f</em>{22}\ …\ f_{2n}]$</li>
<li>相似度/距离函数：<ol>
<li>$D<em>1=\sum</em>{i=1}^{n}|I_i - Q_i|$</li>
<li>$D<em>1=\sum</em>{i=1}^{n}(I_i - Q_i)^2$</li>
<li>还可以计算两个向量的夹角、距离等等</li>
</ol>
</li>
</ol>
<h2 id="12-3-3DMR"><a href="#12-3-3DMR" class="headerlink" title="12.3    3DMR"></a>12.3    3DMR</h2><h3 id="12-3-1-特征提取"><a href="#12-3-1-特征提取" class="headerlink" title="12.3.1    特征提取"></a>12.3.1    特征提取</h3><ol>
<li>基于几何的方法<ol>
<li>提取形状</li>
<li>提取拓扑结构</li>
</ol>
</li>
<li>将模型投影为图像<ol>
<li>从不同角度进行拍照(形状采样)，然后编号</li>
<li>穷举对应顺序，取最小的作为相似度(取平均也可以)</li>
<li>也可以先分析重心，找到主轴，让主轴的方向相同，然后再拍照</li>
</ol>
</li>
</ol>
<h1 id="十三、视频结构化"><a href="#十三、视频结构化" class="headerlink" title="十三、视频结构化"></a>十三、视频结构化</h1><h2 id="13-1-视频结构"><a href="#13-1-视频结构" class="headerlink" title="13.1    视频结构"></a>13.1    视频结构</h2><h3 id="13-1-1-概念"><a href="#13-1-1-概念" class="headerlink" title="13.1.1    概念"></a>13.1.1    概念</h3><ol>
<li><strong>帧Frame</strong>：视频流中的基本组成单元<ol>
<li>物理上的最小单元</li>
<li>每一帧均可看成一个独立的图像</li>
<li>视频流数据就是由连续图像帧构成的</li>
</ol>
</li>
<li><strong>关键帧Key Frame</strong>：用来代表镜头内容的图像<ol>
<li>从一个镜头包含的帧中抽取一部分帧，代表这个镜头的内容</li>
</ol>
</li>
<li><strong>镜头Shot</strong>：摄像机拍下的不间断帧序列<ol>
<li>逻辑上的最小单元</li>
<li>是视频数据流进一步结构化的基础结构层</li>
<li>在同一组镜头中，属于同一组镜头的图像帧之间的特征保持稳定，如果相邻图像帧之间的特征发生了明显变化，认为发生了镜头变化，需要对视频数据进行切分</li>
</ol>
</li>
<li><strong>组Group</strong>：介于物理镜头和语义场景之间的结构<ol>
<li>例如：一段采访录像，镜头在主持人与被采访者之间频繁切换，整个采访属于一个场景，而那些关于主持人的所有镜头属于一组，关于被采访者的所有镜头属于另一组</li>
</ol>
</li>
<li><strong>场景Scecne</strong>：语义上相关和时间上相邻的若干组镜头组成了一个场景<ol>
<li>场景是视频所蕴含的高层抽象概念和语义表达</li>
<li>场景可以使用属于这个场景的若干个镜头所对应的关键帧来表示</li>
</ol>
</li>
<li><strong>视频Video</strong></li>
</ol>
<h3 id="13-1-2-视频结构化的任务"><a href="#13-1-2-视频结构化的任务" class="headerlink" title="13.1.2    视频结构化的任务"></a>13.1.2    视频结构化的任务</h3><ol>
<li>划分镜头</li>
<li>分组</li>
<li>构成场景</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230419081815165.png" alt="image-20230419081815165" style="zoom:80%;" /></p>
<h2 id="13-2-镜头检测"><a href="#13-2-镜头检测" class="headerlink" title="13.2    镜头检测"></a>13.2    镜头检测</h2><p>问题定义：给定一个视频V包含n个镜头，找到每个镜头的起始和结束</p>
<ol>
<li>也被称为 边界检测boundary detection 或 过渡检测transition detection</li>
</ol>
<h3 id="13-2-1-镜头的分类"><a href="#13-2-1-镜头的分类" class="headerlink" title="13.2.1    镜头的分类"></a>13.2.1    镜头的分类</h3><ol>
<li>Hard cuts：硬切，直接在两个镜头之间切换</li>
<li>Fades：前一个镜头淡出，下一个镜头淡入</li>
<li>Dissolves：上一个镜头淡出的同时，下一个镜头淡入，两个镜头之间会叠加起来</li>
<li>Wipe：其他花样切换方式</li>
</ol>
<h3 id="13-2-2-特征提取"><a href="#13-2-2-特征提取" class="headerlink" title="13.2.2    特征提取"></a>13.2.2    特征提取</h3><p>每次计算相邻两帧的特征差$\Delta=f(t+1)-f(t)$，如果发生跳变$\Delta&gt;T(k)$，则说明发生了镜头切换</p>
<ol>
<li>特征：可以是每一帧的直方图，彩色图像可以转化为灰度图像然后再计算直方图</li>
</ol>
<h3 id="13-2-3-镜头边缘检测算法"><a href="#13-2-3-镜头边缘检测算法" class="headerlink" title="13.2.3    镜头边缘检测算法"></a>13.2.3    镜头边缘检测算法</h3><p>实质：</p>
<ol>
<li>找到一种或几种良好的视频图像特征</li>
<li>然后基于这样的特征定义，计算其相似度函数</li>
<li>确定阈值</li>
</ol>
<h4 id="13-2-3-1-绝对帧间差法"><a href="#13-2-3-1-绝对帧间差法" class="headerlink" title="13.2.3.1    绝对帧间差法"></a>13.2.3.1    绝对帧间差法</h4><ol>
<li>判断相邻图像帧之间特征的绝对差是否大</li>
<li>具体特征：某一帧中所有像素的色彩亮度之和</li>
</ol>
<h4 id="13-2-3-2-图像像素差法"><a href="#13-2-3-2-图像像素差法" class="headerlink" title="13.2.3.2    图像像素差法"></a>13.2.3.2    图像像素差法</h4><ol>
<li>判断相邻图像帧中像素点发生变化的多少</li>
<li>缺点：对镜头移动十分明暗，对噪声的容错性较差</li>
</ol>
<h4 id="13-2-3-3-颜色直方图法"><a href="#13-2-3-3-颜色直方图法" class="headerlink" title="13.2.3.3    颜色直方图法"></a>13.2.3.3    颜色直方图法</h4><ol>
<li>将图像转化为灰度图像，然后计算归一化后的颜色直方图</li>
<li>判断特征差<ol>
<li>$d(f,f’)=\sum_{j=0}^{N}|H(f,j)-H(f’,j)|$</li>
<li>也可以是带权直方图、两个特征向量的夹角</li>
</ol>
</li>
</ol>
<h3 id="13-2-4-渐变镜头的数学模型"><a href="#13-2-4-渐变镜头的数学模型" class="headerlink" title="13.2.4    渐变镜头的数学模型"></a>13.2.4    渐变镜头的数学模型</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230419083834479.png" alt="image-20230419083834479" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230419084038381.png" alt="image-20230419084038381" style="zoom:80%;" /></p>
<blockquote>
<p>灰度均值：开口向下的抛物线</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230419084101885.png" alt="image-20230419084101885" style="zoom:80%;" /></p>
<blockquote>
<p>灰度方差：开口向上的抛物线</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20230419084200871.png" alt="image-20230419084200871" style="zoom:80%;" /></p>
<h2 id="13-3-关键帧抽取"><a href="#13-3-关键帧抽取" class="headerlink" title="13.3    关键帧抽取"></a>13.3    关键帧抽取</h2><ol>
<li>视频数据流中的图像帧之间存在空间和时间冗余度</li>
<li>可以从视频中找到一些代表性的帧，用这些少量的帧来代表冗长的视频数据流，使用户看过关键帧后，就能知道整个视频数据流所蕴含的内容，再通过提取这些帧的底层信息来建立索引，方便用户对视频内容查询</li>
</ol>
<h3 id="13-3-1-镜头边界法"><a href="#13-3-1-镜头边界法" class="headerlink" title="13.3.1    镜头边界法"></a>13.3.1    镜头边界法</h3><ol>
<li>将镜头中的第一幅图像和最后一幅图像作为镜头关键帧</li>
<li>每个镜头的关键帧只能有2个关键帧</li>
</ol>
<h3 id="13-3-2-基于特征转变法"><a href="#13-3-2-基于特征转变法" class="headerlink" title="13.3.2    基于特征转变法"></a>13.3.2    基于特征转变法</h3><ol>
<li>将镜头当前帧与之前判断的最后一个关键帧作比较，如果差异较大，则作为新的关键帧</li>
</ol>
<h3 id="13-3-3-基于运动分析法"><a href="#13-3-3-基于运动分析法" class="headerlink" title="13.3.3    基于运动分析法"></a>13.3.3    基于运动分析法</h3><ol>
<li>如果两个帧的重叠部分小于某个阈值，则将后一帧作为新的关键帧</li>
</ol>
<h3 id="13-3-4-基于聚类的关键帧提取"><a href="#13-3-4-基于聚类的关键帧提取" class="headerlink" title="13.3.4    基于聚类的关键帧提取"></a>13.3.4    基于聚类的关键帧提取</h3><ol>
<li>K平均聚类方法，聚类之后，从每一类中选择一个帧作为关键帧</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="unicorn2022.github.io">华丰夏</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://hzoi-unicorn.top/2023/03/01/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/">https://hzoi-unicorn.top/2023/03/01/多媒体技术/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://hzoi-unicorn.top" target="_blank">华风夏韵</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/">专业课</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="人工智能"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">人工智能</div></div></a></div><div class="next-post pull-right"><a href="/2023/02/28/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AF%BC%E8%AE%BA/" title="自然语言处理导论"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">自然语言处理导论</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/07/19/cmake%E6%8C%87%E4%BB%A4%E5%90%88%E9%9B%86/" title="cmake指令合集"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-19</div><div class="title">cmake指令合集</div></div></a></div><div><a href="/2023/07/15/cmake%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="cmake学习笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-15</div><div class="title">cmake学习笔记</div></div></a></div><div><a href="/2023/03/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="人工智能"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-01</div><div class="title">人工智能</div></div></a></div><div><a href="/2023/02/28/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AF%BC%E8%AE%BA/" title="自然语言处理导论"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-28</div><div class="title">自然语言处理导论</div></div></a></div><div><a href="/2023/02/27/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" title="编译原理"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-27</div><div class="title">编译原理</div></div></a></div><div><a href="/2022/09/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/" title="计算机图形学"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-15</div><div class="title">计算机图形学</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">华丰夏</div><div class="author-info__description">一切都是上天最好的安排</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/unicorn2022"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/unicorn2022" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:496300118@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">愿你前行的道路有群星闪耀。愿你留下的足迹有百花绽放。你即是上帝的馈赠，世界因你而瑰丽。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%A4%9A%E5%AA%92%E4%BD%93%E4%BB%8B%E7%BB%8D"><span class="toc-text">一、多媒体介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%9A%E5%AA%92%E4%BD%93"><span class="toc-text">1.1    什么是多媒体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE"><span class="toc-text">1.2    结构化数据</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%9B%BE%E5%BD%A2%E5%92%8C%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%A4%BA"><span class="toc-text">二、图形和图像数据表示</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E5%9F%BA%E7%A1%80%E5%9B%BE%E5%83%8F%E7%B1%BB%E5%9E%8B"><span class="toc-text">2.1    基础图像类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-1-bit-%E4%BA%8C%E5%80%BC%E5%9B%BE%E5%83%8F"><span class="toc-text">2.1.1    1-bit 二值图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-8-bit-%E7%81%B0%E5%BA%A6%E5%9B%BE%E5%83%8F"><span class="toc-text">2.1.2    8-bit 灰度图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-3-%E5%B0%86%E4%B8%80%E4%B8%AA8-bit%E5%9B%BE%E5%83%8F%E7%94%A8%E4%B8%80%E4%B8%AA1-bit%E6%89%93%E5%8D%B0%E6%9C%BA%E6%89%93%E5%8D%B0%E5%87%BA%E6%9D%A5"><span class="toc-text">2.1.3    将一个8-bit图像用一个1-bit打印机打印出来</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-4-24-Bit-%E7%9C%9F%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F"><span class="toc-text">2.1.4    24-Bit 真彩色图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-5-8-Bit-%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F%EF%BC%9A256%E8%89%B2%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F"><span class="toc-text">2.1.5    8-Bit 彩色图像：256色彩色图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-6-%E9%A2%9C%E8%89%B2%E6%9F%A5%E6%89%BE%E8%A1%A8-Color-Lookup-Table"><span class="toc-text">2.1.6    颜色查找表 Color Lookup Table</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-7-%E8%AE%BE%E8%AE%A1%E9%A2%9C%E8%89%B2%E6%9F%A5%E6%89%BE%E8%A1%A8"><span class="toc-text">2.1.7    设计颜色查找表</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-7-1-%E7%A4%BA%E4%BE%8B%EF%BC%9A3-bit-R%EF%BC%8C3-bit-G%EF%BC%8C2-bit-B"><span class="toc-text">2.1.7.1    示例：3-bit R，3-bit G，2-bit B</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-7-2-%E9%A2%9C%E8%89%B2%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="toc-text">2.1.7.2    颜色直方图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-7-3-Median-cut%EF%BC%9A%E4%B8%AD%E5%80%BC%E5%88%87%E5%88%86"><span class="toc-text">2.1.7.3    Median-cut：中值切分</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E5%9C%BA%E6%99%AF%E5%9B%BE%E5%83%8F%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F"><span class="toc-text">2.2    场景图像文件格式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-GIF"><span class="toc-text">2.2.1    GIF</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-JPEG%EF%BC%9AJoint-Photographic-Experts-Group"><span class="toc-text">2.2.2    JPEG：Joint Photographic Experts Group</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-BMP%EF%BC%9AWindows%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A0%BC%E5%BC%8F"><span class="toc-text">2.2.3    BMP：Windows的图像格式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E9%A2%9C%E8%89%B2"><span class="toc-text">三、图像和视频中的颜色</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E9%A2%9C%E8%89%B2%E7%A7%91%E5%AD%A6"><span class="toc-text">3.1    颜色科学</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-1-%E5%85%89%E4%B8%8E%E5%85%89%E8%B0%B1-Light-and-Spectra"><span class="toc-text">3.1.1    光与光谱 Light and Spectra</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-1-%E5%85%89%E6%98%AF%E4%B8%80%E7%A7%8D%E7%94%B5%E7%A3%81%E6%B3%A2%EF%BC%8C%E5%85%B6%E9%A2%9C%E8%89%B2%E4%BB%A5%E6%B3%A2%E9%95%BF%E4%B8%BA%E7%89%B9%E5%BE%81"><span class="toc-text">3.1.1.1    光是一种电磁波，其颜色以波长为特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-2-%E4%B8%8D%E5%90%8C%E6%B3%A2%E9%95%BF%E7%9A%84%E5%85%89%EF%BC%8C%E6%90%BA%E5%B8%A6%E7%9A%84%E8%83%BD%E9%87%8F%E4%B8%8D%E5%90%8C%EF%BC%9AE-%CE%BB"><span class="toc-text">3.1.1.2    不同波长的光，携带的能量不同：E(λ)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-3-%E4%BA%BA%E7%9A%84%E8%A7%86%E8%A7%89"><span class="toc-text">3.1.1.3    人的视觉</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-2-Gamma%E7%9F%AB%E6%AD%A3"><span class="toc-text">3.1.2    Gamma矫正</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-1-CRT%E6%98%BE%E7%A4%BA%E5%8E%9F%E7%90%86"><span class="toc-text">3.1.2.1    CRT显示原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3-%E9%A2%9C%E8%89%B2%E5%8C%B9%E9%85%8D%E5%87%BD%E6%95%B0"><span class="toc-text">3.1.3    颜色匹配函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-4-L-a-b-CIELAB-%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.1.4    L  a  b * (CIELAB) 颜色模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-4-1-%E9%9F%A6%E4%BC%AF%E5%AE%9A%E5%BE%8B"><span class="toc-text">3.1.4.1    韦伯定律</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-4-2-L-a-b-%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%BF%9D%E8%AF%81%E5%80%BC%E7%9A%84%E5%8F%98%E5%8C%96%E4%B8%8E%E4%BA%BA%E6%84%9F%E7%9F%A5%E7%9A%84%E5%8F%98%E5%8C%96%E7%9B%B8%E5%90%8C"><span class="toc-text">3.1.4.2    L  a  b * 颜色模型：保证值的变化与人感知的变化相同</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-4-3-%E5%85%B6%E4%BB%96%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%BA%BA%E8%84%91%E2%80%94LHS"><span class="toc-text">3.1.4.3    其他颜色模型：人脑—LHS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E5%9B%BE%E5%83%8F%E4%B8%AD%E7%9A%84%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.2    图像中的颜色模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-CRT%E6%98%BE%E7%A4%BA%EF%BC%9ARGB"><span class="toc-text">3.2.1    CRT显示：RGB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-%E6%89%93%E5%8D%B0%E6%9C%BA%EF%BC%9ACMY-K"><span class="toc-text">3.2.2    打印机：CMY(K)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-RGB-lt-gt-CMY"><span class="toc-text">3.2.3    RGB &lt;&#x3D;&gt; CMY</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.3    视频中的颜色模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-YUV%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.3.1    YUV颜色模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-2-YIQ%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.3.2    YIQ颜色模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-3-YCbCr%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B"><span class="toc-text">3.3.3    YCbCr颜色模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-text">四、视频基础概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E8%A7%86%E9%A2%91%E4%BF%A1%E5%8F%B7%E7%B1%BB%E5%88%AB"><span class="toc-text">4.1    视频信号类别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-%E5%88%86%E9%87%8F%E8%A7%86%E9%A2%91"><span class="toc-text">4.1.1    分量视频</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-%E5%A4%8D%E5%90%88%E8%A7%86%E9%A2%91"><span class="toc-text">4.1.2    复合视频</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-3-S-Video"><span class="toc-text">4.1.3    S-Video</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E6%A8%A1%E6%8B%9F%E8%A7%86%E9%A2%91%E5%88%B6%E5%BC%8F-%E4%B8%8E%E7%A1%AC%E4%BB%B6%E6%9C%89%E5%85%B3"><span class="toc-text">4.2    模拟视频制式(与硬件有关)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="toc-text">4.2.1    相关概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-NTSC%E4%BF%A1%E5%8F%B7"><span class="toc-text">4.2.2    NTSC信号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-3-PAL%E4%BF%A1%E5%8F%B7"><span class="toc-text">4.2.3    PAL信号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-4-SECAM%E4%BF%A1%E5%8F%B7"><span class="toc-text">4.2.4    SECAM信号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-5-%E4%B8%89%E7%A7%8D%E4%BF%A1%E5%8F%B7%E5%AF%B9%E6%AF%94"><span class="toc-text">4.2.5    三种信号对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91"><span class="toc-text">4.3    数字视频</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-1-%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-text">4.3.1    数字视频的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-2-%E8%89%B2%E5%BA%A6%E4%B8%8B%E9%87%87%E6%A0%B7-Chroma-subsampling"><span class="toc-text">4.3.2    色度下采样 Chroma subsampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-3-CCIR%E6%A0%87%E5%87%86"><span class="toc-text">4.3.3    CCIR标准</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-4-CIF%E6%A0%87%E5%87%86"><span class="toc-text">4.3.4    CIF标准</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-5-HDTV%EF%BC%9AHigh-Definition-TV"><span class="toc-text">4.3.5    HDTV：High Definition TV</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%95%B0%E5%AD%97%E9%9F%B3%E9%A2%91%E5%9F%BA%E7%A1%80"><span class="toc-text">五、数字音频基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E5%A3%B0%E9%9F%B3%E7%9A%84%E6%95%B0%E5%AD%97%E5%8C%96"><span class="toc-text">5.1    声音的数字化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%A3%B0%E9%9F%B3"><span class="toc-text">5.1.1    什么是声音</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-2-%E6%95%B0%E5%AD%97%E5%8C%96"><span class="toc-text">5.1.2    数字化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-3-%E5%A5%88%E5%A5%8E%E6%96%AF%E7%89%B9%E5%AE%9A%E7%90%86"><span class="toc-text">5.1.3    奈奎斯特定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-4-%E4%BF%A1%E5%99%AA%E6%AF%94SNR"><span class="toc-text">5.1.4    信噪比SNR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-5-SQNR"><span class="toc-text">5.1.5    SQNR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-6-%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%87%87%E6%A0%B7"><span class="toc-text">5.1.6    非线性采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-7-%E5%A3%B0%E9%9F%B3%E8%BF%87%E6%BB%A4"><span class="toc-text">5.1.7    声音过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-8-%E9%9F%B3%E9%A2%91%E8%B4%A8%E9%87%8F%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9F%E7%8E%87"><span class="toc-text">5.1.8    音频质量与数据速率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-9-%E5%90%88%E6%88%90%E5%A3%B0%E9%9F%B3"><span class="toc-text">5.1.9    合成声音</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E4%B9%90%E5%99%A8%E6%95%B0%E5%AD%97%E6%8E%A5%E5%8F%A3"><span class="toc-text">5.2    乐器数字接口</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1-MIDI"><span class="toc-text">5.2.1    MIDI</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E9%9F%B3%E9%A2%91%E7%9A%84%E9%87%8F%E5%8C%96%E5%92%8C%E4%BC%A0%E8%BE%93"><span class="toc-text">5.3    音频的量化和传输</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-%E5%A3%B0%E9%9F%B3%E7%9A%84%E7%BC%96%E7%A0%81"><span class="toc-text">5.3.1    声音的编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-PCM%EF%BC%9APulse-Code-Modulation"><span class="toc-text">5.3.2    PCM：Pulse Code Modulation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-3-%E9%9F%B3%E9%A2%91%E7%9A%84%E5%B7%AE%E5%88%86%E7%BC%96%E7%A0%81-Difference-coding-of-audio"><span class="toc-text">5.3.3    音频的差分编码 Difference coding of audio</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-4-%E6%97%A0%E6%8D%9F%E9%A2%84%E6%B5%8B%E7%BC%96%E7%A0%81-Lossless-Predictive-Coding"><span class="toc-text">5.3.4    无损预测编码 Lossless Predictive Coding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-5-DPCM"><span class="toc-text">5.3.5    DPCM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%97%A0%E6%8D%9F%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="toc-text">六、无损压缩算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="toc-text">6.1    信息论基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-1-%E8%83%8C%E6%99%AF"><span class="toc-text">6.1.1    背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-2-%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E8%8C%83%E5%BC%8F"><span class="toc-text">6.1.2    数据压缩范式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-3-%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="toc-text">6.1.3    信息论基础</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-%E6%97%A0%E6%8D%9F%E7%BC%96%E7%A0%81%E7%AE%97%E6%B3%95"><span class="toc-text">6.2    无损编码算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-1-Run-Length-Coding-%E6%B8%B8%E7%A8%8B%E7%BC%96%E7%A0%81"><span class="toc-text">6.2.1    Run-Length Coding 游程编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-2-Variable-Length-Coding-%E5%8F%AF%E5%8F%98%E9%95%BF%E7%BC%96%E7%A0%81"><span class="toc-text">6.2.2    Variable-Length Coding 可变长编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-3-Dictionary-Based-Coding-%E5%AD%97%E5%85%B8%E7%BC%96%E7%A0%81"><span class="toc-text">6.2.3    Dictionary-Based Coding 字典编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-4-Arithmetic-Coding-%E7%AE%97%E6%9C%AF%E7%BC%96%E7%A0%81"><span class="toc-text">6.2.4    Arithmetic Coding 算术编码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-%E6%97%A0%E6%8D%9F%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9"><span class="toc-text">6.3    无损图像压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-1-%E5%9B%BE%E5%83%8F%E5%B7%AE%E5%88%86%E7%BC%96%E7%A0%81%EF%BC%9A%E9%99%8D%E4%BD%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E7%86%B5"><span class="toc-text">6.3.1    图像差分编码：降低数据的熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-2-%E6%97%A0%E6%8D%9FJPEG"><span class="toc-text">6.3.2    无损JPEG</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%9C%89%E6%8D%9F%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="toc-text">七、有损压缩算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E6%8D%9F%E5%A4%B1%E6%B5%8B%E9%87%8F-Distortion-Measures"><span class="toc-text">7.2    损失测量 Distortion Measures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-2-Distortion%E7%9A%84%E6%95%B0%E5%AD%A6%E6%B5%8B%E9%87%8F"><span class="toc-text">7.2.2    Distortion的数学测量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-%E5%A4%B1%E7%9C%9F%E7%8E%87"><span class="toc-text">7.3    失真率</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-2-R-D%E5%87%BD%E6%95%B0"><span class="toc-text">7.3.2    R-D函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-%E9%87%8F%E5%8C%96-Quantization%E2%80%94%E4%BA%A7%E7%94%9F%E6%8D%9F%E5%A4%B1"><span class="toc-text">7.4    量化 Quantization—产生损失</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-2-Uniform-Scalar-Quantization"><span class="toc-text">7.4.2    Uniform Scalar Quantization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-5-Transform-Coding"><span class="toc-text">7.5    Transform Coding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-1-%E5%9F%BA%E7%A1%80%E6%80%9D%E6%83%B3"><span class="toc-text">7.5.1    基础思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-2-DCT%EF%BC%9A%E7%A6%BB%E6%95%A3%E4%BD%99%E5%BC%A6%E5%8F%98%E6%8D%A2-Discrete-Cosine-Transform"><span class="toc-text">7.5.2    DCT：离散余弦变换 Discrete Cosine Transform</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-1-%E4%B8%80%E7%BB%B4DCT%E5%8F%98%E6%8D%A2"><span class="toc-text">7.5.2.1    一维DCT变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-2-%E5%9C%A8%E4%B8%89%E7%BB%B4%E7%A9%BA%E9%97%B4%E7%9A%84DCT%E5%8F%98%E6%8D%A2%E7%A4%BA%E4%BE%8B"><span class="toc-text">7.5.2.2    在三维空间的DCT变换示例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-3-DCT%E6%98%AF%E6%AD%A3%E4%BA%A4%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%EF%BC%8C%E5%8D%B3%E4%B8%8D%E5%90%8C%E8%A1%8C%E5%90%91%E9%87%8F%E7%9A%84%E5%86%85%E7%A7%AF%E4%B8%BA0"><span class="toc-text">7.5.2.3    DCT是正交线性变换，即不同行向量的内积为0</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-4-DCT%E6%98%AF%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%EF%BC%8C%E6%BB%A1%E8%B6%B3%E5%8A%A0%E6%B3%95%E6%80%A7%E8%B4%A8%EF%BC%9A-T-alpha-p-beta-q-alpha-p-beta-q"><span class="toc-text">7.5.2.4    DCT是线性变换，满足加法性质：$T(\alpha p+ \beta q) &#x3D; \alpha p + \beta q$</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-5-DCT%E7%9A%84%E7%89%A9%E7%90%86%E5%90%AB%E4%B9%89%EF%BC%9A%E7%BB%99%E5%AE%9A%E4%BB%BB%E6%84%8F%E4%B8%80%E4%B8%AA%E8%BE%93%E5%85%A5%E4%BF%A1%E5%8F%B7%EF%BC%8C%E5%91%8A%E8%AF%89%E8%AF%A5%E4%BF%A1%E5%8F%B7%E6%98%AF%E5%A6%82%E4%BD%95%E6%9C%89%E5%9F%BA%E4%BF%A1%E5%8F%B7%E7%BB%84%E5%90%88%E8%80%8C%E6%88%90%E7%9A%84"><span class="toc-text">7.5.2.5    DCT的物理含义：给定任意一个输入信号，告诉该信号是如何有基信号组合而成的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-5-2-6-2%E7%BB%B4DCT%E5%8F%98%E6%8D%A2%EF%BC%9A%E5%AE%9A%E4%B9%89%E4%BA%86%E4%B8%80%E7%BB%84%E5%9F%BA%E7%9F%A9%E9%98%B5"><span class="toc-text">7.5.2.6    2维DCT变换：定义了一组基矩阵</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-2-6-DFT%EF%BC%9A%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2"><span class="toc-text">7.5.2.6    DFT：离散傅里叶变换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-6-Wavelet-Based-Coding-%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2"><span class="toc-text">7.6    Wavelet-Based Coding 小波变换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-6-2-%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E7%A4%BA%E4%BE%8B"><span class="toc-text">7.6.2    小波变换示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-6-3-%E4%B8%80%E7%BB%B4Harr%E5%8F%98%E6%8D%A2"><span class="toc-text">7.6.3    一维Harr变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-6-4-%E4%BA%8C%E7%BB%B4Harr%E5%8F%98%E6%8D%A2"><span class="toc-text">7.6.4    二维Harr变换</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9%E6%A0%87%E5%87%86"><span class="toc-text">八、图像压缩标准</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-JPEG%E6%A0%87%E5%87%86"><span class="toc-text">8.1    JPEG标准</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-1-JEPG%E5%8E%8B%E7%BC%A9%E6%AD%A5%E9%AA%A4"><span class="toc-text">8.1.1    JEPG压缩步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-1-DCT"><span class="toc-text">8.1.1.1    DCT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-2-%E9%87%8F%E5%8C%96"><span class="toc-text">8.1.1.2    量化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-3-Zigzag%E5%B1%95%E5%BC%80"><span class="toc-text">8.1.1.3    Zigzag展开</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-4-%E5%AF%B9AC%E4%BF%A1%E5%8F%B7%E5%81%9ARLE%E7%BC%96%E7%A0%81"><span class="toc-text">8.1.1.4    对AC信号做RLE编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-5-%E5%AF%B9DC%E4%BF%A1%E5%8F%B7%E5%81%9ADPCM%E7%BC%96%E7%A0%81"><span class="toc-text">8.1.1.5    对DC信号做DPCM编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-6-%E5%AF%B9%E7%BB%93%E6%9E%9C%E5%81%9A%E7%86%B5%E7%BC%96%E7%A0%81"><span class="toc-text">8.1.1.6    对结果做熵编码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-2-JPEG%E6%A8%A1%E5%BC%8F"><span class="toc-text">8.1.2    JPEG模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-1-%E9%A1%BA%E5%BA%8F%E6%A8%A1%E5%BC%8F-Sequential"><span class="toc-text">8.1.2.1    顺序模式 Sequential</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-2-%E6%B8%90%E8%BF%9B%E6%A8%A1%E5%BC%8F-Progressive"><span class="toc-text">8.1.2.2    渐进模式 Progressive</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-3-%E5%B1%82%E6%AC%A1%E6%A8%A1%E5%BC%8F-Hierarchical"><span class="toc-text">8.1.2.3    层次模式 Hierarchical</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-4-%E6%97%A0%E6%8D%9F%E6%A8%A1%E5%BC%8F-Lossless"><span class="toc-text">8.1.2.4    无损模式 Lossless</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-JEPG2000%E6%A0%87%E5%87%86"><span class="toc-text">8.2    JEPG2000标准</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E5%9F%BA%E7%A1%80%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="toc-text">九、基础视频压缩算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-Introduction"><span class="toc-text">9.1    Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-2-%E5%9F%BA%E4%BA%8E%E8%BF%90%E5%8A%A8%E8%A1%A5%E5%81%BF%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9"><span class="toc-text">9.2    基于运动补偿的视频压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-1-%E6%97%B6%E9%97%B4%E5%86%97%E4%BD%99%E6%80%A7"><span class="toc-text">9.2.1    时间冗余性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-2-%E8%BF%90%E5%8A%A8%E8%A1%A5%E5%81%BF-Motion-Compensation"><span class="toc-text">9.2.2    运动补偿 Motion Compensation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-3-%E6%90%9C%E7%B4%A2%E8%BF%90%E5%8A%A8%E5%90%91%E9%87%8F"><span class="toc-text">9.3    搜索运动向量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-1-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E5%8C%B9%E9%85%8D"><span class="toc-text">9.3.1    判断是否匹配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-2-%E9%A1%BA%E5%BA%8F%E6%90%9C%E7%B4%A2-Sequential-Search"><span class="toc-text">9.3.2    顺序搜索 Sequential Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-3-2%E7%BB%B4%E5%AF%B9%E6%95%B0%E6%90%9C%E7%B4%A2-2D-Logarithmic-search"><span class="toc-text">9.3.3    2维对数搜索 2D-Logarithmic-search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-4-%E5%B1%82%E6%AC%A1%E6%90%9C%E7%B4%A2-Hierarchical-Search"><span class="toc-text">9.3.4    层次搜索 Hierarchical Search</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-4-H-261"><span class="toc-text">9.4    H.261</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-1-%E6%80%BB%E8%A7%88"><span class="toc-text">9.4.1    总览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-2-Intra-Frame-Coding"><span class="toc-text">9.4.2    Intra-Frame Coding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-3-Inter-Frame-predictive-Coding"><span class="toc-text">9.4.3    Inter-Frame predictive Coding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-4-%E9%87%8F%E5%8C%96"><span class="toc-text">9.4.4    量化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-5-%E6%95%B4%E4%B8%AA%E8%BF%87%E7%A8%8B"><span class="toc-text">9.4.5    整个过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-6-H-261-%E8%A7%86%E9%A2%91Bit%E6%B5%81"><span class="toc-text">9.4.6    H.261 视频Bit流</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-5-H-263"><span class="toc-text">9.5    H.263</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E3%80%81MPEG%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81"><span class="toc-text">十、MPEG视频编码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-MPEG-1"><span class="toc-text">10.1    MPEG-1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-1-%E8%BF%90%E5%8A%A8%E8%A1%A5%E5%81%BF"><span class="toc-text">10.1.1    运动补偿</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-2-MPEG-1%E4%B8%8EH-261%E5%8C%BA%E5%88%AB"><span class="toc-text">10.1.2    MPEG-1与H.261区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-3-MPEG-1%E8%A7%86%E9%A2%91%E6%AF%94%E7%89%B9%E6%B5%81"><span class="toc-text">10.1.3    MPEG-1视频比特流</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-MPEG-2"><span class="toc-text">10.2    MPEG-2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-1-%E6%80%BB%E8%A7%88"><span class="toc-text">10.2.1    总览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-2-%E6%94%AF%E6%8C%81%E9%9A%94%E8%A1%8C%E6%89%AB%E6%8F%8F"><span class="toc-text">10.2.2    支持隔行扫描</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-3-MPEG-2-Scalabilities-%E5%8F%AF%E4%BC%B8%E7%BC%A9%E6%80%A7"><span class="toc-text">10.2.3    MPEG-2 Scalabilities 可伸缩性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-3-1-%E5%8F%AF%E4%BC%B8%E7%BC%A9%E7%BC%96%E7%A0%81-Scalable-Coding"><span class="toc-text">10.2.3.1    可伸缩编码 Scalable Coding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-3-2-SNR%E5%8F%AF%E4%BC%B8%E7%BC%A9"><span class="toc-text">10.2.3.2    SNR可伸缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-3-3-%E7%A9%BA%E9%97%B4%E5%8F%AF%E4%BC%B8%E7%BC%A9"><span class="toc-text">10.2.3.3    空间可伸缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-3-4-%E6%97%B6%E9%97%B4%E5%8F%AF%E4%BC%B8%E7%BC%A9"><span class="toc-text">10.2.3.4    时间可伸缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-3-5-%E6%95%B0%E6%8D%AE%E5%88%92%E5%88%86"><span class="toc-text">10.2.3.5    数据划分</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-4-%E5%85%B6%E4%BB%96%E5%8C%BA%E5%88%AB"><span class="toc-text">10.2.4    其他区别</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81MPEG%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E2%85%A1"><span class="toc-text">十一、MPEG视频编码Ⅱ</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-MPEG-4"><span class="toc-text">11.1    MPEG-4</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-1-%E6%A6%82%E8%A7%88"><span class="toc-text">11.1.1    概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-2-%E5%9F%BA%E4%BA%8E%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BC%96%E7%A0%81"><span class="toc-text">11.1.2    *基于对象的编码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-1-Frame-Based-Coding-vs-VOP-Based-Coding"><span class="toc-text">11.1.2.1    Frame-Based Coding vs VOP-Based Coding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-2-VOP-Based-Coding"><span class="toc-text">11.1.2.2    VOP-Based Coding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-3-Motion-Compensation"><span class="toc-text">11.1.2.3    Motion Compensation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-4-%E7%BA%B9%E7%90%86%E7%BC%96%E7%A0%81"><span class="toc-text">11.1.2.4    纹理编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-5-%E5%BD%A2%E7%8A%B6%E7%BC%96%E7%A0%81"><span class="toc-text">11.1.2.5    形状编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-6-%E9%9D%99%E6%80%81%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9-Static-Texture-Coding"><span class="toc-text">11.1.2.6    静态纹理压缩 Static Texture Coding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-2-7-%E5%8A%A8%E6%80%81%E7%BC%96%E7%A0%81-Sprite-Coding"><span class="toc-text">11.1.2.7    动态编码 Sprite Coding</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-3-%E5%8A%A8%E6%80%81%E7%89%A9%E4%BD%93%E7%BC%96%E7%A0%81"><span class="toc-text">11.1.3    动态物体编码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E5%A4%9A%E5%AA%92%E4%BD%93%E6%A3%80%E7%B4%A2"><span class="toc-text">十二、基于内容的多媒体检索</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#12-1-CBMR%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E5%A4%9A%E5%AA%92%E4%BD%93%E6%A3%80%E7%B4%A2"><span class="toc-text">12.1    CBMR：基于内容的多媒体检索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-2-CBIR%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2"><span class="toc-text">12.2    CBIR：基于内容的图像检索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-1-%E7%89%B9%E5%BE%81"><span class="toc-text">12.2.1    特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-2-%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-text">12.2.2    相似度计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-3-3DMR"><span class="toc-text">12.3    3DMR</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-3-1-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">12.3.1    特征提取</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%89%E3%80%81%E8%A7%86%E9%A2%91%E7%BB%93%E6%9E%84%E5%8C%96"><span class="toc-text">十三、视频结构化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#13-1-%E8%A7%86%E9%A2%91%E7%BB%93%E6%9E%84"><span class="toc-text">13.1    视频结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-1-%E6%A6%82%E5%BF%B5"><span class="toc-text">13.1.1    概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-2-%E8%A7%86%E9%A2%91%E7%BB%93%E6%9E%84%E5%8C%96%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="toc-text">13.1.2    视频结构化的任务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-2-%E9%95%9C%E5%A4%B4%E6%A3%80%E6%B5%8B"><span class="toc-text">13.2    镜头检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-1-%E9%95%9C%E5%A4%B4%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-text">13.2.1    镜头的分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-2-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">13.2.2    特征提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-3-%E9%95%9C%E5%A4%B4%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-text">13.2.3    镜头边缘检测算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13-2-3-1-%E7%BB%9D%E5%AF%B9%E5%B8%A7%E9%97%B4%E5%B7%AE%E6%B3%95"><span class="toc-text">13.2.3.1    绝对帧间差法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-2-3-2-%E5%9B%BE%E5%83%8F%E5%83%8F%E7%B4%A0%E5%B7%AE%E6%B3%95"><span class="toc-text">13.2.3.2    图像像素差法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-2-3-3-%E9%A2%9C%E8%89%B2%E7%9B%B4%E6%96%B9%E5%9B%BE%E6%B3%95"><span class="toc-text">13.2.3.3    颜色直方图法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-4-%E6%B8%90%E5%8F%98%E9%95%9C%E5%A4%B4%E7%9A%84%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B"><span class="toc-text">13.2.4    渐变镜头的数学模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-3-%E5%85%B3%E9%94%AE%E5%B8%A7%E6%8A%BD%E5%8F%96"><span class="toc-text">13.3    关键帧抽取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-1-%E9%95%9C%E5%A4%B4%E8%BE%B9%E7%95%8C%E6%B3%95"><span class="toc-text">13.3.1    镜头边界法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-2-%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E8%BD%AC%E5%8F%98%E6%B3%95"><span class="toc-text">13.3.2    基于特征转变法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-3-%E5%9F%BA%E4%BA%8E%E8%BF%90%E5%8A%A8%E5%88%86%E6%9E%90%E6%B3%95"><span class="toc-text">13.3.3    基于运动分析法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-4-%E5%9F%BA%E4%BA%8E%E8%81%9A%E7%B1%BB%E7%9A%84%E5%85%B3%E9%94%AE%E5%B8%A7%E6%8F%90%E5%8F%96"><span class="toc-text">13.3.4    基于聚类的关键帧提取</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/19/cmake%E6%8C%87%E4%BB%A4%E5%90%88%E9%9B%86/" title="cmake指令合集">cmake指令合集</a><time datetime="2023-07-19T12:19:11.000Z" title="发表于 2023-07-19 20:19:11">2023-07-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/15/cmake%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="cmake学习笔记">cmake学习笔记</a><time datetime="2023-07-15T10:00:00.000Z" title="发表于 2023-07-15 18:00:00">2023-07-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/13/hexo%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/" title="hexo常用指令">hexo常用指令</a><time datetime="2023-07-13T13:11:11.000Z" title="发表于 2023-07-13 21:11:11">2023-07-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/04/01/GAMES104/" title="GAMES104">GAMES104</a><time datetime="2023-04-01T04:49:00.000Z" title="发表于 2023-04-01 12:49:00">2023-04-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="人工智能">人工智能</a><time datetime="2023-03-01T02:00:00.000Z" title="发表于 2023-03-01 10:00:00">2023-03-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 华丰夏</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>