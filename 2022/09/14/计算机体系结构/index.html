<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>计算机体系结构 | 华风夏韵</title><meta name="author" content="华丰夏"><meta name="copyright" content="华丰夏"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="计算机体系结构学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机体系结构">
<meta property="og:url" content="https://hzoi-unicorn.top/2022/09/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/index.html">
<meta property="og:site_name" content="华风夏韵">
<meta property="og:description" content="计算机体系结构学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/avatar.png">
<meta property="article:published_time" content="2022-09-14T02:00:00.000Z">
<meta property="article:modified_time" content="2023-07-22T11:41:31.975Z">
<meta property="article:author" content="华丰夏">
<meta property="article:tag" content="专业课">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/avatar.png"><link rel="shortcut icon" href="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/favicon.png"><link rel="canonical" href="https://hzoi-unicorn.top/2022/09/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="codeva-PpLfvQYdq5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 华丰夏","link":"链接: ","source":"来源: 华风夏韵","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '计算机体系结构',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-07-22 19:41:31'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/avatar.png" onerror="onerror=null;src='https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/resources/"><i class="fa-fw fa fa-book"></i><span> 资源</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/default_top_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="华风夏韵"><span class="site-name">华风夏韵</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/resources/"><i class="fa-fw fa fa-book"></i><span> 资源</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">计算机体系结构</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-14T02:00:00.000Z" title="发表于 2022-09-14 10:00:00">2022-09-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-22T11:41:31.975Z" title="更新于 2023-07-22 19:41:31">2023-07-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">专业课学习笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">18.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>62分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="计算机体系结构"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>





<h1 id="Chapter-1：Introduction"><a href="#Chapter-1：Introduction" class="headerlink" title="Chapter 1：Introduction"></a>Chapter 1：Introduction</h1><h2 id="1-1-Current-computer"><a href="#1-1-Current-computer" class="headerlink" title="1.1    Current computer"></a>1.1    Current computer</h2><ol>
<li><p>什么是<strong>CA</strong>(Computer Architecture)</p>
<ol>
<li><p>计算机架构是：<strong>选择</strong>和连接硬件组件以创建满足<strong>功能</strong>、<strong>性能</strong>、<strong>成本</strong>和<strong>功率</strong>目标的计算机的科学和艺术</p>
</li>
<li><p>它是计算机各个部分的需求和设计实现的<strong>蓝图</strong>和功能描述，主要关注中央处理单元（CPU）内部执行和访问内存地址的方式</p>
</li>
<li><p><strong>Tradeoff</strong>取舍</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220918160513641.png" alt="image-20220918160513641" style="zoom:80%;" /></p>
</li>
</ol>
</li>
<li><p><strong>Computer Architecture</strong>包含了三个主要的方面</p>
<ol>
<li><strong>ISA</strong>，七个维度如下：<ol>
<li>Class of ISA</li>
<li>Memory addressing</li>
<li>Addressing modes</li>
<li>Types and sizes of operands</li>
<li>Operations</li>
<li>Control flow instructions</li>
<li>Encoding an ISA</li>
</ol>
</li>
<li><strong>Microarchitecture</strong>：也叫Computer  organization，是对系统的较低层次、更具体和更详细的描述，涉及系统的组成部分如何互连以及它们如何互操作以实现ISA</li>
<li><strong>System Design</strong>：包括计算系统中所有其他硬件组件的系统设计，如：逻辑实现</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220918161931403.png" alt="image-20220918161931403" style="zoom:80%;" /></p>
</li>
<li><p>处理器芯片的发展趋势</p>
<ol>
<li>工艺、主频遇到瓶颈后，开始通过增加核数的方式来提升性能；</li>
<li>芯片的物理尺寸有限制，不能无限制的增加；</li>
<li>ARM的众核横向扩展空间优势明显</li>
</ol>
</li>
<li><p><strong>SoC</strong>：System of Chips，芯片上的系统</p>
</li>
<li><p>CPU发展的三个挑战</p>
<ol>
<li><strong>ILP</strong>：指令集之间的并行</li>
<li><strong>Memory</strong>：内存到CPU之间的时间开销</li>
<li><strong>Power</strong>：功耗</li>
</ol>
</li>
<li><p>Bandwidth和Latency</p>
<ol>
<li><strong>Bandwidth带宽/throughput吞吐率</strong>：单位时间内能够完成的任务</li>
<li><strong>Latency延迟/response time反应时间</strong>：完成单个任务所需的时间</li>
<li>有时候不一定Latency降低，Bandwidth就提高了</li>
</ol>
</li>
<li><p>降低能耗：</p>
<ol>
<li>休眠：在没有core运行时就休眠</li>
<li>动态调压：降低电压/频率<ol>
<li>频率：开关晶体管的次数</li>
</ol>
</li>
<li>为典型的情况做设计</li>
<li>超频Overlocking</li>
<li>尽快将所有的任务完成Race-to-halt</li>
</ol>
</li>
<li><p>功耗</p>
<ol>
<li>动态功耗Dynamic power：由于开关晶体管导致的功耗<ol>
<li>$Power_{dynamic}=\frac{1}{2}<em>电容负载</em>电压^2$</li>
<li>$Energy_{dynamic}=电容负载*电压^2$</li>
</ol>
</li>
<li>静态功耗Static power：即便不导通，晶体管也会有电压泄露<ol>
<li>$Power_{dynamic}=静态电流*电压$</li>
</ol>
</li>
<li>一般来说，电压降低10%，功率降低30%</li>
</ol>
</li>
</ol>
<h2 id="1-2-Dependability-需要计算"><a href="#1-2-Dependability-需要计算" class="headerlink" title="1.2    Dependability(需要计算)"></a>1.2    Dependability(需要计算)</h2><ol>
<li><p><strong>Availability</strong>：可用性，一定时间内有多长时间是可以正常工作的</p>
<ol>
<li>也是某个时间，不可用的几率</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220926193308993.png" alt="image-20220926193308993" style="zoom:80%;" /></p>
</li>
<li><p><strong>Reliability</strong>：可靠性</p>
<ol>
<li>指一个人或系统在日常环境以及敌对或意外环境中执行和维护其功能的能力</li>
<li>IEEE将其定义为：“某个系统或组件在规定条件下，在规定时间内执行其所需功能的能力。”</li>
</ol>
</li>
<li><p><strong>Maintainability</strong>：可维护性</p>
</li>
<li><p><strong>Dependability</strong>：可信性，所提供服务的质量，以便可以合理地依赖此服务</p>
<ol>
<li><strong>MTTF</strong>：Mean Time To Failure，从开始工作到失效的平均时间</li>
<li><strong>MTTR</strong>：Mean Time To Repair，从失效到再次重新工作的平均时间</li>
<li><strong>MTBF</strong>：Mean Time Between Failure，两次失效之间的平均时间<ol>
<li><strong>MTBF = MTTF + MTTR</strong></li>
</ol>
</li>
<li><strong>FIT</strong>：Failure In Time，失败出现的机会<ol>
<li><strong>FIT = 1 / MTTF</strong></li>
</ol>
</li>
<li><strong>Module Availability</strong>：模块可用的时间<ol>
<li><strong>$\frac{MTTF}{MTTF+MTTR}=\frac{MTTF}{MTBF}$</strong></li>
</ol>
</li>
</ol>
</li>
<li><p><strong>已知每个部分的MTTF，求整个系统的MTTF</strong>：</p>
<ol>
<li>求出各个部分的<strong>FIT~i~ = 1 / MTTF~i~</strong></li>
<li>求出整个系统的<strong>FIT = FIT~1~+FIT~2~+…+FIT~n~</strong></li>
<li>求出整个系统的<strong>MTTF = 1 / FIT</strong></li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220926195354943.png" alt="image-20220926195354943" style="zoom:80%;" /></p>
</li>
<li><p>应对failure：<strong>Redundancy冗余</strong></p>
<ol>
<li><strong>Time Redundancy</strong>：重复做一遍</li>
<li><strong>Resource Redundancy</strong>：用另一个部件替换坏掉的部件</li>
</ol>
</li>
</ol>
<h2 id="1-3-测量-报告-总结-性能-需要计算"><a href="#1-3-测量-报告-总结-性能-需要计算" class="headerlink" title="1.3    测量/报告/总结 性能(需要计算)"></a>1.3    测量/报告/总结 性能(需要计算)</h2><ol>
<li><p>比较两个计算机的性能</p>
<ol>
<li><strong>Execution time</strong>：计算的速度</li>
<li><strong>Throught</strong>：吞吐率</li>
<li><strong>MIPS</strong>：millions of instructions per second每秒多少百万条指令</li>
<li>使用<strong>Benchmark</strong>进行测量</li>
</ol>
</li>
<li><p><strong>Wall-clock Time</strong>：一个程序从开始到结束所需时间(包含中间停顿所需的时间)</p>
</li>
<li><p><strong>CPU Time</strong>：一个程序实际在CPU上所需的时间</p>
<ol>
<li><strong>User Time</strong>：在user mode下使用的时间</li>
<li><strong>System Time</strong>：在operating system中使用的时间</li>
</ol>
</li>
<li><p><strong>MIPS</strong>：每秒钟计算的多少百万条指令</p>
<ol>
<li><strong>MIPS = benchmark中的指令数 / (benchmark运行的时间 * 1,000,000)</strong></li>
<li>指令集中的每条指令，权重不一定一样，且已经包含在了<strong>benchmark</strong>中</li>
</ol>
</li>
<li><p><strong>Benchmark</strong>的种类</p>
<ol>
<li>Real applications：一个真实的程序</li>
<li>Modified (or scripted) applications：对程序进行一些修改，关注于其中的一些点</li>
<li>Kernels：程序的最主要的部分</li>
<li>Toy：只关注一些部分</li>
<li>Synthetic：创建来表示程序的某些方面</li>
</ol>
</li>
<li><p><strong>计算A比B快多少</strong>：<strong>A所需的时间 / B所需的时间，得到一个&gt;1的数字</strong></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220926211157177.png" alt="image-20220926211157177" style="zoom:80%;" /></p>
</li>
</ol>
<h1 id="Chapter-3：Memory-hierarchy"><a href="#Chapter-3：Memory-hierarchy" class="headerlink" title="Chapter 3：Memory hierarchy"></a>Chapter 3：Memory hierarchy</h1><h2 id="3-1-Introduction"><a href="#3-1-Introduction" class="headerlink" title="3.1    Introduction"></a>3.1    Introduction</h2><ol>
<li><p><strong>DRAM</strong>：Dynamic Random Access Memory</p>
<ol>
<li>高密度、低功耗、便宜、速度慢</li>
<li>不能放在CPU里面，因为有电容，有充放电(交流信号 )，会影响CPU的计算</li>
<li>Dynamic动态：需要定期“刷新”，刷新时不能进行读写</li>
</ol>
</li>
<li><p><strong>SRAM</strong>：Static Random Access Memory</p>
<ol>
<li>低密度、高功率、昂贵、快速</li>
<li>唯一可以放在CPU里面的，因为没有电容</li>
<li>Static静态：内容将“永远”保存（直到失去动力）</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20220926213915597.png" alt="image-20220926213915597" style="zoom:80%;" /></p>
</li>
</ol>
<h2 id="3-2-Cache"><a href="#3-2-Cache" class="headerlink" title="3.2    Cache"></a>3.2    Cache</h2><h3 id="3-2-1-组相联计算"><a href="#3-2-1-组相联计算" class="headerlink" title="3.2.1    组相联计算"></a>3.2.1    组相联计算</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207100226371.png" alt="image-20221207100226371" style="zoom:80%;" /></p>
<ol>
<li>4G：地址为32位</li>
<li>Cache 8K，Block-offset为5位：共2^8^个block</li>
<li>2-way组相联：index= 8-1=7位</li>
</ol>
<h3 id="3-2-2-block的替换策略"><a href="#3-2-2-block的替换策略" class="headerlink" title="3.2.2    block的替换策略"></a>3.2.2    block的替换策略</h3><blockquote>
<p>  只有在全关联/组关联的时候，会有替换策略</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207101045729.png" alt="image-20221207101045729" style="zoom:67%;" /></p>
</blockquote>
<ol>
<li><p>Random replacement：随机选择一个块替换</p>
<ol>
<li>随机数的硬件实现：<ol>
<li>设计一个专门的组件</li>
<li>用一根电线什么也不接，然后读取这个引脚的电压，理论上是白噪声，电压是随机分布的</li>
</ol>
</li>
</ol>
</li>
<li><p>LRU：选择最近最少访问的块替换</p>
<ol>
<li>伪LRU算法(体系不考察LRU)</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207101613432.png" alt="image-20221207101613432" style="zoom:80%;" /></p>
</li>
<li><p>FIFO：选择第一个进入cache的块替换</p>
</li>
</ol>
<h3 id="3-2-3-写策略"><a href="#3-2-3-写策略" class="headerlink" title="3.2.3    写策略"></a>3.2.3    写策略</h3><ol>
<li><strong>write-through</strong>：同时修改cache和memory<ol>
<li>cache的控制位：valid bit</li>
<li>始终保证memory中的数据是最新的</li>
<li>通常会写入buffer，从而让cache不用等待memory</li>
</ol>
</li>
<li><strong>write-back</strong>：只修改cache，block被替换时写入memory<ol>
<li>cache的控制位：valid bit，dirty bit</li>
<li>带宽更小，因为重复访问时不需要写memory</li>
</ol>
</li>
</ol>
<p>选择<strong>write-through</strong>时，会有两种更新策略</p>
<ol>
<li><strong>write-stall</strong>：CPU等待write-through完成</li>
<li><strong>write-buffer</strong>：写入buffer，CPU不用等待write-through完成<ol>
<li>buffer的大小不是无限的，buffer满时需要stall</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207102327940.png" alt="image-20221207102327940" style="zoom:80%;" /></p>
<p><strong>miss</strong>时的写策略：(读策略肯定是将block放入cache)</p>
<ol>
<li><strong>write-allocate</strong>：将对应的block放入cache（通常是write-back对应的策略，write-through也可以用）</li>
<li><strong>write-around</strong>：直接写memory，不取对应的cache（通常是write-through对应的策略）</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207103235415.png" alt="image-20221207103235415" style="zoom:80%;" /></p>
<h3 id="3-2-4-数据和指令的cache是否分离"><a href="#3-2-4-数据和指令的cache是否分离" class="headerlink" title="3.2.4    数据和指令的cache是否分离"></a>3.2.4    数据和指令的cache是否分离</h3><ol>
<li><strong>average miss rate = 指令占比% × 指令的miss rate + 数据占比% × 数据的miss rate</strong></li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207104617121.png" alt="image-20221207104617121" style="zoom:80%;" /></p>
<h3 id="3-2-5-Supervisor-cache-User-cache"><a href="#3-2-5-Supervisor-cache-User-cache" class="headerlink" title="3.2.5    Supervisor cache / User cache"></a>3.2.5    Supervisor cache / User cache</h3><ol>
<li>Supervisor 和 User 所要访问的空间肯定有很大的区别，可以将它们两个分别赋予一个cache</li>
<li>指令cache</li>
<li>Supervisor / User Space Bit<ol>
<li>1：Supervisor access only</li>
<li>0：Supervisor / User access</li>
</ol>
</li>
</ol>
<h3 id="3-2-6-Cache-Performance-计算"><a href="#3-2-6-Cache-Performance-计算" class="headerlink" title="3.2.6    Cache Performance (计算)"></a>3.2.6    Cache Performance (<strong>计算</strong>)</h3><h4 id="3-2-6-1-CPU-Time"><a href="#3-2-6-1-CPU-Time" class="headerlink" title="3.2.6.1    CPU Time"></a>3.2.6.1    CPU Time</h4><ol>
<li><strong>CPU时间 = (CPU时钟周期 + Memory-Stall周期) × 一个周期的时间</strong></li>
<li><strong>Memory-Stall周期 = 指令数量IC × 平均每条指令访问内存的次数 × Miss-Rate × Miss惩罚</strong></li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207105355773.png" alt="image-20221207105355773" style="zoom:80%;" /></p>
<h4 id="3-2-6-2-AMAT：平均内存访问时间"><a href="#3-2-6-2-AMAT：平均内存访问时间" class="headerlink" title="3.2.6.2    AMAT：平均内存访问时间"></a>3.2.6.2    AMAT：平均内存访问时间</h4><ol>
<li><p><strong>AMAT = 命中时间 + Miss率 × Miss惩罚</strong></p>
<p>​            <strong>= (命中时间~指令~ + Miss率~指令~ × Miss惩罚~指令~) + 命中时间~数据~ + Miss率~数据~ × Miss惩罚~数据~)</strong></p>
</li>
<li></li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207105609421.png" alt="image-20221207105609421" style="zoom:80%;" /></p>
<h4 id="3-2-6-3-Cache性能的测试指标"><a href="#3-2-6-3-Cache性能的测试指标" class="headerlink" title="3.2.6.3    Cache性能的测试指标"></a>3.2.6.3    Cache性能的测试指标</h4><ol>
<li>Miss Rate<ol>
<li>与硬件的速度无关</li>
</ol>
</li>
<li>Average Memory Access Time<ol>
<li>是性能的间接表现</li>
</ol>
</li>
<li>CPU time</li>
</ol>
<h4 id="3-2-6-4-示例"><a href="#3-2-6-4-示例" class="headerlink" title="3.2.6.4    示例"></a>3.2.6.4    示例</h4><ol>
<li><p>例1：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207110058159.png" alt="image-20221207110058159" style="zoom:80%;" /></p>
</li>
<li><p>例2：</p>
<ol>
<li><strong>1 + 0.5</strong>：每条指令在取指令的时候都可能miss(1) + 这些指令中的50%是访问数据，也会miss(0.5)</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207110555774.png" alt="image-20221207110555774" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207110723683.png" alt="image-20221207110723683" style="zoom:80%;" /></p>
</li>
<li><p>例3：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111108659.png" alt="image-20221207111108659" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111432070.png" alt="image-20221207111432070" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111233382.png" alt="image-20221207111233382" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111245213.png" alt="image-20221207111245213" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111301770.png" alt="image-20221207111301770" style="zoom:80%;" /></p>
</li>
<li><p>例4：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111805960.png" alt="image-20221207111805960" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111817521.png" alt="image-20221207111817521" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207111828369.png" alt="image-20221207111828369" style="zoom:80%;" /></p>
</li>
<li><p>例5：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207112106592.png" alt="image-20221207112106592" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207112118603.png" alt="image-20221207112118603" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207112125809.png" alt="image-20221207112125809" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207112134237.png" alt="image-20221207112134237" style="zoom:80%;" /></p>
</li>
</ol>
<h1 id="Chapter-4：How-to-improve-memory-performance"><a href="#Chapter-4：How-to-improve-memory-performance" class="headerlink" title="Chapter 4：How to improve memory performance"></a>Chapter 4：How to improve memory performance</h1><script type="math/tex; mode=display">
AMAT = hit\_time + miss\_rate × miss\_penalty</script><ol>
<li><p>降低hit time</p>
<ol>
<li>更小的一级cache，路径预测</li>
<li>避免地址转换，Trace cache</li>
</ol>
</li>
<li><p>增加bandwidth</p>
<ol>
<li>流水线cache，multibanked cache，non-blocking caches</li>
</ol>
</li>
<li><p>降低miss penalty</p>
<ol>
<li>多级cache</li>
<li>读miss优先于写miss</li>
<li>Critical word first，merging write buffers，victim caches</li>
</ol>
</li>
<li><p>降低miss rate</p>
<ol>
<li>更大的block size，更大的cache size，更高的关联度(2路组相联 =&gt; 4路组相联)</li>
<li>编译器优化</li>
</ol>
</li>
<li><p>通过并行，降低miss_penalty 或 miss_rate</p>
<ol>
<li>硬件/编译器预取</li>
</ol>
</li>
</ol>
<h2 id="4-1-降低hit-time"><a href="#4-1-降低hit-time" class="headerlink" title="4.1    降低hit time"></a>4.1    降低hit time</h2><h3 id="4-1-1-小而简单的cache"><a href="#4-1-1-小而简单的cache" class="headerlink" title="4.1.1    小而简单的cache"></a>4.1.1    小而简单的cache</h3><p>使用小型，直接映射cache</p>
<ol>
<li>实现缓存所需的硬件越少，通过硬件的关键路径就越短</li>
<li>无论是读还是写，直接映射都比组关联快</li>
<li>将cache安装进CPU芯片上，也可以提高访问速度</li>
</ol>
<blockquote>
<p>  一级cache和关联度对性能的影响</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207194810330.png" alt="image-20221207194810330" style="zoom:80%;" /></p>
</blockquote>
<h3 id="4-1-2-Way-Prediction"><a href="#4-1-2-Way-Prediction" class="headerlink" title="4.1.2    Way Prediction"></a>4.1.2    Way Prediction</h3><ol>
<li>额外的位保存在缓存中以预测下一次缓存访问的方式或块</li>
<li>如果预测是正确的，指令缓存延迟是1个时钟周期</li>
<li>如果不是，它尝试另一个块，改变方式预测，并有一个额外的1个时钟周期的延迟</li>
<li>使用SPEC95进行仿真表明，集预测精度超过85%，因此预测方式节省了流水线阶段85%以上的指令读取</li>
</ol>
<h3 id="4-1-3-在cache上做索引时避免Address-Translation"><a href="#4-1-3-在cache上做索引时避免Address-Translation" class="headerlink" title="4.1.3    在cache上做索引时避免Address Translation"></a>4.1.3    在cache上做索引时避免Address Translation</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207195323138.png" alt="image-20221207195323138" style="zoom:80%;" /></p>
<ol>
<li>每个进程都有一个页表</li>
<li>页表是内存中的一个巨大的数据结构</li>
<li>每次load/store/instruction_fetch都需要2次内存访问</li>
<li>解决方法：<ol>
<li>方法1：如果cache中的index+offset均在页表中的page-offset中，那么可以先将页表中的page-offset送入cache进行搜索，然后再将MMU翻译出的tag送入cache进行比对</li>
<li>方法2：cache中的内容可以是虚地址，但是换进程/进内核的时候需要清空cache</li>
<li>方法3：对页表建立一个cache</li>
</ol>
</li>
</ol>
<h4 id="4-1-3-1-TLB：Translation-Lookat-Buffer"><a href="#4-1-3-1-TLB：Translation-Lookat-Buffer" class="headerlink" title="4.1.3.1    TLB：Translation Lookat Buffer"></a>4.1.3.1    TLB：Translation Lookat Buffer</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207200143731.png" alt="image-20221207200143731" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207200404505.png" alt="image-20221207200404505" style="zoom:80%;" /></p>
<ol>
<li>实际上就是将页表放入cache</li>
<li>TLB的大小通常是128~256个entry，通常使用全相联</li>
</ol>
<blockquote>
<p>  Fast hits by Avoiding Address Translation</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207200515798.png" alt="image-20221207200515798" style="zoom:80%;" /></p>
</blockquote>
<h4 id="4-1-3-2-Virtual-Cache"><a href="#4-1-3-2-Virtual-Cache" class="headerlink" title="4.1.3.2    Virtual Cache"></a>4.1.3.2    Virtual Cache</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207200644869.png" alt="image-20221207200644869" style="zoom:80%;" /></p>
<ol>
<li>cache中的内容可以是虚地址</li>
<li>但是换进程/进内核的时候需要清空cache，因为不同的进程使用的虚页号可能相同，但对应的物理地址是不同的地址</li>
</ol>
<h3 id="4-1-4-Trace-Caches"><a href="#4-1-4-Trace-Caches" class="headerlink" title="4.1.4    Trace Caches"></a>4.1.4    Trace Caches</h3><ol>
<li><p>找到一个动态序列的指令，序列包含采取分支加载到缓存块</p>
</li>
<li><p>由CPU而不是内存布局决定block的边界</p>
<ol>
<li>例如有一个循环跨越了两个block，可以将这个循环访问到的数据放到trace cache中的一个block</li>
</ol>
</li>
<li><p>需要复杂的地址映射机制</p>
</li>
<li><p>使用trace cache后，如果每个循环有N个指令</p>
<ol>
<li>没有 I-cache miss</li>
<li>没有 prediction miss</li>
<li>没有 packet breaks</li>
</ol>
</li>
<li><p>Trace：dynamic instruction sequence</p>
<ol>
<li>当指令(操作)退出管道时，将指令段打包到trace中，并将它们存储在trace cache中，包括分支指令</li>
<li>虽然分支指令可能会去不同的目标，但大多数情况下，下一个操作顺序将与上一个顺序相同(locality)</li>
</ol>
</li>
<li><p>优点：引入一个额外的cache，可以突破block的边界</p>
</li>
<li><p>Trace in CPU：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207202135321.png" alt="image-20221207202135321" style="zoom: 67%;" /></p>
</li>
<li><p>Instruction segment：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207202257646.png" alt="image-20221207202257646" style="zoom:67%;" /></p>
</li>
</ol>
<h2 id="4-2-增加bandwidth"><a href="#4-2-增加bandwidth" class="headerlink" title="4.2    增加bandwidth"></a>4.2    增加bandwidth</h2><h3 id="4-2-1-Pipelined-Cache"><a href="#4-2-1-Pipelined-Cache" class="headerlink" title="4.2.1    Pipelined Cache"></a>4.2.1    Pipelined Cache</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207202853389.png" alt="image-20221207202853389" style="zoom:80%;" /></p>
<h3 id="4-2-2-Nonblocking-Caches"><a href="#4-2-2-Nonblocking-Caches" class="headerlink" title="4.2.2    Nonblocking Caches"></a>4.2.2    Nonblocking Caches</h3><ol>
<li>一个Nonblocking(Lookup-free) Caches，允许cache在处理read miss时继续提供hit<ol>
<li>“Hit under miss” ， “Hit under multiple miss”</li>
</ol>
</li>
<li>复杂的cache甚至可能有多个未执行的miss(miss under miss)</li>
<li>Nonblocking与乱序执行相结合，可以让CPU在数据cache miss后继续执行之后的指令<ol>
<li>之后的指令与当前指令不能有依赖关系</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207203839462.png" alt="image-20221207203839462" style="zoom:80%;" /></p>
<h3 id="4-2-3-Multibanked-Caches"><a href="#4-2-3-Multibanked-Caches" class="headerlink" title="4.2.3    Multibanked Caches"></a>4.2.3    Multibanked Caches</h3><ol>
<li>将cache分成几个独立的bank，它们可以同时被访问</li>
<li>可以让多条指令同时进cache，但是WB阶段还是要排队</li>
<li>需要编译器的支持，实现对内存的交错访问</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207203800593.png" alt="image-20221207203800593" style="zoom:80%;" /></p>
<h2 id="4-3-降低miss-penalty"><a href="#4-3-降低miss-penalty" class="headerlink" title="4.3    降低miss penalty"></a>4.3    降低miss penalty</h2><h3 id="4-3-1-Multilevel-Caches"><a href="#4-3-1-Multilevel-Caches" class="headerlink" title="4.3.1    Multilevel Caches"></a>4.3.1    Multilevel Caches</h3><ol>
<li>一级cache较小，二级cache较大</li>
<li>如果一级cache miss，二级cache hit，此时会降低miss penalty</li>
<li><strong>AMAT = Hit_Time~L1~ + Miss_Rate~L1~ × (Hit_Time~L2~ + Miss_Rate~L2~ × Miss_Penalty~L2~)</strong></li>
<li>两个概念：<ol>
<li><strong>Local miss rate</strong>：当前cache miss的次数 / 访问当前cache的指令数</li>
<li><strong>Global miss rate</strong>：当前cache miss的次数 / 总指令数</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207204044541.png" alt="image-20221207204044541" style="zoom:80%;" /></p>
<h3 id="4-3-2-Critical-Word-First-amp-Early-Restart"><a href="#4-3-2-Critical-Word-First-amp-Early-Restart" class="headerlink" title="4.3.2    Critical Word First &amp; Early Restart"></a>4.3.2    Critical Word First &amp; Early Restart</h3><ol>
<li><p>不要等到加载满块后才重新启动CPU：</p>
<ol>
<li>Critical Word First：一旦发生miss，立即将请求的word从内存中取出并发送给CPU，让CPU继续执行，之后再慢慢填充block。也叫wrapped fetch / requested word first</li>
<li>Early restart：还是从内存中取出一个block，但是一旦当请求的word到达，就把它发送给CPU，让CPU继续执行</li>
</ol>
</li>
<li><p>通常在block比较大的时候比较有用</p>
</li>
<li><p>示例：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207205240171.png" alt="image-20221207205240171" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-3-3-Giving-Priority-to-Read-Misses-over-Writes"><a href="#4-3-3-Giving-Priority-to-Read-Misses-over-Writes" class="headerlink" title="4.3.3    Giving Priority to Read Misses over Writes"></a>4.3.3    Giving Priority to Read Misses over Writes</h3><ol>
<li><p>读miss优先于写miss执行</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207205426405.png" alt="image-20221207205426405" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-3-4-Merging-write-Buffer"><a href="#4-3-4-Merging-write-Buffer" class="headerlink" title="4.3.4    Merging write Buffer"></a>4.3.4    Merging write Buffer</h3><ol>
<li>用 multiword writes 替代 one word writes</li>
<li>在write-througe策略中：<ol>
<li>当写入失败时，如果缓冲区包含其他修改的块，则可以检查地址，以查看这个新数据的地址是否与有效的写入缓冲区项的地址匹配</li>
<li>如果是，则将新数据与该条目合并</li>
</ol>
</li>
<li>降低了同一个地址被多次写时的开销，也可以降低write buffer full的次数</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207205924147.png" alt="image-20221207205924147" style="zoom:80%;" /></p>
<h3 id="4-3-5-Victim-Caches"><a href="#4-3-5-Victim-Caches" class="headerlink" title="4.3.5    Victim Caches"></a>4.3.5    Victim Caches</h3><ol>
<li>Victim Caches：是一个小的、全关联的cache</li>
<li>当cache中的块被替换时，可以将其先放入 Victim Caches<ol>
<li>如果下一次的miss仍在该块中，可以直接将其拿回来 / 直接修改 Victim Caches 中的块 </li>
</ol>
</li>
</ol>
<h2 id="4-4-降低miss-rate"><a href="#4-4-降低miss-rate" class="headerlink" title="4.4    降低miss rate"></a>4.4    降低miss rate</h2><p>miss的来源：</p>
<ol>
<li>Compulsory：由于cache为空而导致的miss<ol>
<li>Misses in even an Infinite Cache</li>
</ol>
</li>
<li>Capacity：由于cache容量已满而导致的miss<ol>
<li>Misses in Fully Associative Size X Cache</li>
</ol>
</li>
<li>Conflict：由于当前block应当放到的cache中的位置已经有block而导致的miss<ol>
<li>Misses in N-way Associative, Size X Cache</li>
</ol>
</li>
<li>Coherence：由于cache一致性问题导致的miss</li>
</ol>
<blockquote>
<p>  以下策略均在cache size不变的情况下讨论</p>
</blockquote>
<h3 id="4-4-1-更大的Block-Size"><a href="#4-4-1-更大的Block-Size" class="headerlink" title="4.4.1    更大的Block Size"></a>4.4.1    更大的Block Size</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207211509692.png" alt="image-20221207211509692" style="zoom:67%;" /></p>
<ol>
<li><p>优点：</p>
<ol>
<li>利用空间局部性降低了compulsory miss rate</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li>会提高miss penalty：因为每次miss需要取更多的数据</li>
<li>会提高conflict miss rate：因为cache中的块数降低了</li>
<li>会提高capacity miss rate：因为小的cache中包含的块数变少了，就更容易满了</li>
</ol>
</li>
<li><p>权衡：</p>
<ol>
<li>尽可能最小化 miss rate 和 miss penalty</li>
<li>block size的选择取决于memory的延迟和带宽</li>
</ol>
</li>
<li><p>示例：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207211544779.png" alt="image-20221207211544779" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-4-2-更大的cache"><a href="#4-4-2-更大的cache" class="headerlink" title="4.4.2    更大的cache"></a>4.4.2    更大的cache</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207211623532.png" alt="image-20221207211623532" style="zoom: 67%;" /></p>
<ol>
<li>thumb定律：2倍的size =&gt; miss rate降低25%</li>
<li>优点：<ol>
<li>降低了capacity miss rate</li>
</ol>
</li>
<li>缺点：<ol>
<li>会提高hit time</li>
<li>会提高cost</li>
<li>AMAT曲线是U型的</li>
</ol>
</li>
</ol>
<h3 id="4-4-3-更高的Associativity"><a href="#4-4-3-更高的Associativity" class="headerlink" title="4.4.3    更高的Associativity"></a>4.4.3    更高的Associativity</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207212125595.png" alt="image-20221207212125595" style="zoom:67%;" /></p>
<ol>
<li><p>2:1 rule of thumb：</p>
<ol>
<li>大小为N的直接映射的cache 与 大小为N/2的2-way组相联的cache 的miss rate相同</li>
<li>8-way组相联在降低miss rate方面，与提高8倍的cache size效果相同</li>
</ol>
</li>
<li><p>优点：</p>
<ol>
<li>降低了conflict miss rate</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li>会提高hit time</li>
</ol>
</li>
<li><p>AMAT vs. Miss Rate</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221207212317832.png" alt="image-20221207212317832" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-4-4-编译器优化"><a href="#4-4-4-编译器优化" class="headerlink" title="4.4.4    编译器优化"></a>4.4.4    编译器优化</h3><ol>
<li>指令    <ol>
<li>重新排列内存中的程序，以减少冲突、未命中</li>
<li>分析冲突（使用他们开发的工具）</li>
</ol>
</li>
<li>数据<ol>
<li>合并数组Merging Arrays：通过单个数组提高空间局部性</li>
<li>循环交换Loop Interchange：修改循环访问数据的嵌套次序</li>
<li>循环融合Loop Fusion：将两个有相同循环、类似变量的循环合并为一个</li>
<li>阻塞Blocking：重复数据与向下移动整列或整行</li>
</ol>
</li>
</ol>
<h4 id="4-4-4-1-Merging-Arrays"><a href="#4-4-4-1-Merging-Arrays" class="headerlink" title="4.4.4.1    Merging Arrays"></a>4.4.4.1    Merging Arrays</h4><ol>
<li>将两个独立的数组合并到一起</li>
<li>这样使用的时候，可以在一个block中读取到</li>
<li>提高空间局部性</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214102128193.png" alt="image-20221214102128193" style="zoom:80%;" /></p>
<h4 id="4-4-4-2-Loop-Interchange"><a href="#4-4-4-2-Loop-Interchange" class="headerlink" title="4.4.4.2    Loop Interchange"></a>4.4.4.2    Loop Interchange</h4><ol>
<li>遍历矩阵时，修改遍历的顺序，保证内层循环在列上</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214102823363.png" alt="image-20221214102823363" style="zoom:80%;" /></p>
<h4 id="4-4-4-3-Loop-fusion"><a href="#4-4-4-3-Loop-fusion" class="headerlink" title="4.4.4.3    Loop fusion"></a>4.4.4.3    Loop fusion</h4><ol>
<li>将两个独立的循环合并为一个</li>
<li>两个循环中使用了相同的变量，合并之后可以减少miss</li>
</ol>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214113143734.png" alt="image-20221214113143734"></p>
<h4 id="4-4-4-4-Blocking-optimized-Matrix-Multiplication"><a href="#4-4-4-4-Blocking-optimized-Matrix-Multiplication" class="headerlink" title="4.4.4.4     Blocking optimized Matrix Multiplication"></a>4.4.4.4     Blocking optimized Matrix Multiplication</h4><ol>
<li>将大矩阵分为小矩阵，使得小矩阵的每一列可以存进cache中</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214122238575.png" alt="image-20221214122238575" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214122530845.png" alt="image-20221214122530845" style="zoom:80%;" /></p>
<h4 id="4-4-4-5-示例"><a href="#4-4-4-5-示例" class="headerlink" title="4.4.4.5    示例"></a>4.4.4.5    示例</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214123001322.png" alt="image-20221214123001322" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214123218445.png" alt="image-20221214123218445" style="zoom:80%;" /></p>
<h2 id="4-5-硬件相关知识"><a href="#4-5-硬件相关知识" class="headerlink" title="4.5    硬件相关知识"></a>4.5    硬件相关知识</h2><h3 id="4-5-1-DRAM-amp-SRAM"><a href="#4-5-1-DRAM-amp-SRAM" class="headerlink" title="4.5.1     DRAM &amp; SRAM"></a>4.5.1     DRAM &amp; SRAM</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214123602777.png" alt="image-20221214123602777" style="zoom:80%;" /></p>
<p>SRAM：</p>
<ol>
<li>6个晶体管，表示1个bit</li>
<li>不需要刷新</li>
</ol>
<p>DRAM：</p>
<ol>
<li><p>1个电容，表示1个bit</p>
</li>
<li><p>电容越大，积累的电荷越多，自放电越慢，刷新的频率越低；但每一次写入的时间越长，单位面积存放的电容越少，存储容量越少</p>
</li>
<li><p>DRAM的周期性刷新，会产生一个大的交流信号，导致DRAM不能与CPU做在一起</p>
</li>
<li><p>通常会做成矩阵形式</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214124159094.png" alt="image-20221214124159094" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-5-2-SDRAM：Synchronous-DRAM"><a href="#4-5-2-SDRAM：Synchronous-DRAM" class="headerlink" title="4.5.2    SDRAM：Synchronous DRAM"></a>4.5.2    SDRAM：Synchronous DRAM</h3><ol>
<li>在DRAM的基础上增加了clock，达到同步效果</li>
<li>可以有burst mode，让关键字先写</li>
</ol>
<h3 id="4-5-3-DDR：Double-data-rate"><a href="#4-5-3-DDR：Double-data-rate" class="headerlink" title="4.5.3    DDR：Double data rate"></a>4.5.3    DDR：Double data rate</h3><ol>
<li>在上升沿和下降沿各做依次写</li>
</ol>
<h3 id="4-5-4-flash"><a href="#4-5-4-flash" class="headerlink" title="4.5.4    flash"></a>4.5.4    flash</h3><ol>
<li>flash在读上比DRAM慢</li>
</ol>
<h1 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h1><blockquote>
<p>  选A：cost尽可能便宜，speed尽可能快</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214124711597.png" alt="image-20221214124711597"></p>
<blockquote>
<p>  选B：两级cache时，一级cache不需要很大</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214124755592.png" alt="image-20221214124755592"  /></p>
<blockquote>
<p>  选A</p>
<ol>
<li>B：I/O不仅指与人的交互，还有CPU与内存的交互</li>
<li>C：I/O性能很重要</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214125100925.png" alt="image-20221214125100925"></p>
<blockquote>
<p>  选C：直接映射时block conflict的概率最高</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214174637040.png" alt="image-20221214174637040"></p>
<blockquote>
<p>  选D：当进程工作时，并不是程序访问的所有内容都会被放到主存。如果电脑有<strong>虚拟内存</strong>，一些内容会仍停留在<strong>磁盘</strong>。地址空间会被划分成固定大小的block，称为<strong>pages</strong>。任何时候，每一个<strong>page</strong>会停留在主存或<strong>磁盘</strong>中。</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214174742777.png" alt="image-20221214174742777"  /></p>
<blockquote>
<p>  选A：</p>
<ol>
<li>Write through 与 Write back 对比，对虚拟内存没有影响</li>
<li>full-associative map 与 其它映射方法 对比</li>
<li>TLB cache 与 no cache 对比</li>
<li>LRU replacement 与 其它替换策略 对比</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214175356757.png" alt="image-20221214175356757"></p>
<blockquote>
<p>  选A</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214175804610.png" alt="image-20221214175804610"></p>
<blockquote>
<p>  选B：</p>
<ol>
<li>内存为256MB：28bit</li>
<li>4KB cache：2^12^</li>
<li>block size 32B：5bit</li>
<li>2-way associative：1bit</li>
<li>index的长度：12-5-1=6bit</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214175819564.png" alt="image-20221214175819564"></p>
<blockquote>
<p>  选B：把1个bank替换为多个banks，有哪些好处–提高了带宽</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214180148625.png" alt="image-20221214180148625"></p>
<blockquote>
<p>  选D：</p>
<ol>
<li>AMAT = Hit Time + Miss Rate * Miss Penalty</li>
<li>IC <em> CC </em> IPC</li>
<li>改进的程度 = Told / Tnew</li>
<li>CPU Time = IC <em> CC </em> CPI</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214180335701.png" alt="image-20221214180335701"></p>
<blockquote>
<p>  选B：当程序运行的时候，使用的内存地址为<strong>逻辑地址</strong></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214180527597.png" alt="image-20221214180527597"></p>
<blockquote>
<p>  选A：对于全关联来说，组关联的优点在于–tag更小，占用的芯片面积更少</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214180639388.png" alt="image-20221214180639388"></p>
<blockquote>
<p>  选D：假设cache中有M个block，每K个block分为一个组，则它是一个K-way组关联</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214180841186.png" alt="image-20221214180841186"></p>
<blockquote>
<p>  选A：增强了空间局部性—访问了x，x的附近也会被访问</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214181048556.png" alt="image-20221214181048556"></p>
<blockquote>
<ol>
<li>cache大小：64KB—2^16^</li>
<li>每一行大小：128B—2^7^</li>
<li>4-way组关联：2^2^</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214181405480.png" alt="image-20221214181405480"></p>
<blockquote>
<p>  选B：如果block size增大了，miss rate可能会降低，正确的表述为：在一定范围内，block size增大，miss rate降低</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214181455496.png" alt="image-20221214181455496"></p>
<blockquote>
<p>  选D：二级cache的AMAT = Hit time~L1~ + Miss rate~L1~ <em> (Hit time~L2~ + Miss rate~L2~ </em> Miss penalty~L2~)</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214181556596.png" alt="image-20221214181556596"></p>
<blockquote>
<p>  在一个2-way组关联的cache中，假设cache有4个block，每个block有1word，每个set有2个block。对于指令<code>LOAD R1, 0x18</code>，这次访问<strong>miss</strong>了，<strong>不需要replacement</strong>，新的block会放在<strong>Set 0 Block 0</strong></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214181716064.png" alt="image-20221214181716064"></p>
<blockquote>
<p>  memory的表现为：</p>
<ol>
<li>送地址：4 clock</li>
<li>访问每个word：56 clock</li>
<li><p>传输数据：4 clock</p>
<p>假设一个block有4 word，一个word有8 byte，那么miss penalty为<strong>(4 + 56 + 4) × 4 = 256</strong> clock，bandwidth为<strong>$\frac{4 * 8}{256}=\frac{1}{8}$</strong></p>
</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214182030080.png" alt="image-20221214182030080"></p>
<blockquote>
<ol>
<li>miss rate = 50%<ol>
<li>每次访问数组时，偶数次miss，然后装入2 word，从而奇数次hit</li>
</ol>
</li>
<li>AMAT = 8 + 50% * 70 = 43 ns</li>
<li>CPI计算：<ol>
<li>先用AMAT与频率换算成clock cycle</li>
<li>然后再计算平均每条指令需要的clock cycle</li>
</ol>
</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214182448100.png" alt="image-20221214182448100"></p>
<blockquote>
<p>  假设cache的其它参数(容量、关联性、block大小)都不变，对于下列三个问题：</p>
<ol>
<li>block size翻倍，block数量降低，index变小，tag变大，但不是翻倍的关系</li>
<li>直接映射的cache，容量翻倍，block数量翻倍，会降低conflict miss</li>
<li>直接映射的cache，容量翻倍，强制miss的次数倍增</li>
</ol>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214182751718.png" alt="image-20221214182751718"  /></p>
<blockquote>
<p>  什么是virtual indexed和physical tagged cache？</p>
<ol>
<li>virtual indexed：index部分在page-offset中，因此不需要经过MMU翻译</li>
<li><p>physical tagged：tag在page number中，需要经过MMU翻译</p>
<p>通过index在cache中找对应的block 与 MMU翻译page number并行进行，降低了时间消耗</p>
</li>
</ol>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214183259142.png" alt="image-20221214183259142"></p>
<blockquote>
<p>  假设一个cache使用write-back策略，被交换的block有20%的几率为dirty，cache miss的概率为10%。假设hit time为1 cycle，miss penalty为20 cycle，写回dirty block为20 cycle</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214184127692.png" alt="image-20221214184127692"></p>
<blockquote>
<p>  第3问需要：图+语言描述</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214184359869.png" alt="image-20221214184359869"></p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214184439146.png" alt="image-20221214184439146"></p>
<h1 id="Chapter-5：Extend-2-Supporting-M-Coperation"><a href="#Chapter-5：Extend-2-Supporting-M-Coperation" class="headerlink" title="Chapter 5：Extend 2 Supporting M Coperation"></a>Chapter 5：Extend 2 Supporting M Coperation</h1><h2 id="5-1-之前的流水线CPU"><a href="#5-1-之前的流水线CPU" class="headerlink" title="5.1    之前的流水线CPU"></a>5.1    之前的流水线CPU</h2><ol>
<li>ALU部分是一个门电路，只需要1个cycle就可以完成计算</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214185314918.png" alt="image-20221214185314918" style="zoom:80%;" /></p>
<h2 id="5-2-扩展流水线CPU，支持多周期运算"><a href="#5-2-扩展流水线CPU，支持多周期运算" class="headerlink" title="5.2    扩展流水线CPU，支持多周期运算"></a>5.2    扩展流水线CPU，支持多周期运算</h2><h3 id="5-2-1-包含FP运算单元的5阶段流水线"><a href="#5-2-1-包含FP运算单元的5阶段流水线" class="headerlink" title="5.2.1    包含FP运算单元的5阶段流水线"></a>5.2.1    包含FP运算单元的5阶段流水线</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214185627169.png" alt="image-20221214185627169" style="zoom: 80%;" /></p>
<h3 id="5-2-2-两个指标：Latency和Initiation-interval"><a href="#5-2-2-两个指标：Latency和Initiation-interval" class="headerlink" title="5.2.2    两个指标：Latency和Initiation interval"></a>5.2.2    两个指标：Latency和Initiation interval</h3><ol>
<li><strong>Latency</strong>：指令开始到结束所需的时间</li>
<li><strong>Initiation interval</strong>：指令开始后，再经过多长时间，可以重新开始</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214185908103.png" alt="image-20221214185908103" style="zoom:80%;" /></p>
<blockquote>
<p>  流水级</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214190024718.png" alt="image-20221214190024718" style="zoom:80%;" /></p>
<blockquote>
<p>  新的情况</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214190600531.png" alt="image-20221214190600531" style="zoom:80%;" /></p>
<h3 id="5-2-3-按序发射，乱序完成"><a href="#5-2-3-按序发射，乱序完成" class="headerlink" title="5.2.3    按序发射，乱序完成"></a>5.2.3    按序发射，乱序完成</h3><p>结构冲突：</p>
<ol>
<li><p>WB阶段要写寄存器，ID阶段要读寄存器：double bump，上升沿写，下降沿读</p>
</li>
<li><p>IF和MEM都要访问存储器：将存储器分为指令存储器、数据存储器</p>
</li>
<li>同一个周期有多个WB<ol>
<li>多端口读写，但成本太高</li>
<li>阻塞stall<ol>
<li>在ID阶段stall：多增加一些判断逻辑，但是与原来的CPU是统一的</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214190709233.png" alt="image-20221214190709233" style="zoom:80%;" /></p>
<h3 id="5-2-4-如何解决write-port-conflict"><a href="#5-2-4-如何解决write-port-conflict" class="headerlink" title="5.2.4    如何解决write port conflict"></a>5.2.4    如何解决write port conflict</h3><p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214191641942.png" alt="image-20221214191641942"></p>
<h2 id="5-3-data-hazard的种类"><a href="#5-3-data-hazard的种类" class="headerlink" title="5.3    data hazard的种类"></a>5.3    data hazard的种类</h2><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221214192313856.png" alt="image-20221214192313856" style="zoom:80%;" /></p>
<ol>
<li><strong>RAW</strong> true dependence：A写Rx，B读Rx</li>
<li><strong>WAW</strong> output dependence：A写Rx，B写Rx</li>
<li><strong>WAR</strong> anti-dependence：A读Rx，B写Rx</li>
</ol>
<h3 id="5-3-1-RAW依赖"><a href="#5-3-1-RAW依赖" class="headerlink" title="5.3.1    RAW依赖"></a>5.3.1    RAW依赖</h3><ol>
<li>B在A写寄存器之前，就读了寄存器的值，可能导致B得到了一个旧的value</li>
<li>解决方法：forwarding</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215005704708.png" alt="image-20221215005704708" style="zoom:80%;" /></p>
<blockquote>
<p>  填写技巧：</p>
<ol>
<li>一旦有一行stall，下面都是stall</li>
<li>stall一定出现在ID的后面</li>
<li>stall结束时，与上一行的stage之间一定有一个forward</li>
</ol>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215010356977.png" alt="image-20221215010356977" style="zoom:80%;" /></p>
<h3 id="5-3-2-WAW依赖"><a href="#5-3-2-WAW依赖" class="headerlink" title="5.3.2    WAW依赖"></a>5.3.2    WAW依赖</h3><ol>
<li>B在A写寄存器之前，就写了寄存器的值，可能导致A再次写寄存器，从而使寄存器保存了一个旧的value</li>
<li>解决方法：<ol>
<li>阻塞A</li>
<li>直接扔掉A这条指令</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215005805734.png" alt="image-20221215005805734" style="zoom:80%;" /></p>
<blockquote>
<ol>
<li>在WB之前检测是否需要stall</li>
<li>注意：整数指令，MEM=&gt;WB；浮点指令，没有MEM阶段</li>
</ol>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215010510079.png" alt="image-20221215010510079" style="zoom:80%;" /></p>
<h3 id="5-3-3-WAR依赖"><a href="#5-3-3-WAR依赖" class="headerlink" title="5.3.3    WAR依赖"></a>5.3.3    WAR依赖</h3><ol>
<li>B在A读寄存器之前，就写了寄存器的值，可能导致A读寄存器时，读到了一个新的不正确的value</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215010048032.png" alt="image-20221215010048032" style="zoom:80%;" /></p>
<h3 id="5-3-4-在ID阶段需要检查的内容"><a href="#5-3-4-在ID阶段需要检查的内容" class="headerlink" title="5.3.4    在ID阶段需要检查的内容"></a>5.3.4    在ID阶段需要检查的内容</h3><ol>
<li>结构冲突<ol>
<li>除法、寄存器写端口</li>
</ol>
</li>
<li>RAW冲突<ol>
<li>如果有RAW冲突，则直接stall，直到<ol>
<li>源寄存器不再是其它指令的目标寄存器</li>
<li>源寄存器不再是EX/MEM阶段load指令的目标寄存器</li>
</ol>
</li>
</ol>
</li>
<li>WAW冲突<ol>
<li>如果有WAW冲突，则直接stall / cancel</li>
</ol>
</li>
</ol>
<h1 id="Chpater-7：Dynamic-Schedule—Scoreboard"><a href="#Chpater-7：Dynamic-Schedule—Scoreboard" class="headerlink" title="Chpater 7：Dynamic Schedule—Scoreboard"></a>Chpater 7：Dynamic Schedule—Scoreboard</h1><p>统计数据表明，每5条指令，大概率就有一条跳转指令</p>
<h2 id="7-1-指令级并行ILP"><a href="#7-1-指令级并行ILP" class="headerlink" title="7.1    指令级并行ILP"></a>7.1    指令级并行ILP</h2><h3 id="7-1-1-指令级并行的目标：最小化CPI"><a href="#7-1-1-指令级并行的目标：最小化CPI" class="headerlink" title="7.1.1    指令级并行的目标：最小化CPI"></a>7.1.1    指令级并行的目标：最小化CPI</h3><p>CPI = 理想CPI + 结构冲突导致的stall + 数据冲突导致的stall + 控制冲突导致的stall</p>
<ol>
<li>理想CPI：实现某个算法的最优表现</li>
<li>结构冲突：HW不能支持这种指令的组合</li>
<li>数据冲突：当前指令依赖于之前指令的结果</li>
<li>控制冲突：由获取指令和决定控制流更改(分支和跳转)之间的延迟引起冲突</li>
</ol>
<h3 id="7-1-2-如何实现ILP"><a href="#7-1-2-如何实现ILP" class="headerlink" title="7.1.2    如何实现ILP"></a>7.1.2    如何实现ILP</h3><ol>
<li>基于硬件的动态解决方案</li>
<li>基于编译优化的静态解决方案</li>
</ol>
<h3 id="7-1-3-降低stall的方法"><a href="#7-1-3-降低stall的方法" class="headerlink" title="7.1.3    降低stall的方法"></a>7.1.3    降低stall的方法</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215012529320.png" alt="image-20221215012529320" style="zoom:80%;" /></p>
<h3 id="7-1-4-Instruction-Level-Parallelism-ILP"><a href="#7-1-4-Instruction-Level-Parallelism-ILP" class="headerlink" title="7.1.4    Instruction-Level Parallelism ILP"></a>7.1.4    Instruction-Level Parallelism ILP</h3><ol>
<li>为了获得实质性的性能增强，我们必须跨多个基本块利用ILP</li>
<li>最简单：循环级并行性，利用循环迭代之间的并行性<ol>
<li>使用<code>Vector</code>(<code>SIMD</code>) &amp; <code>GPU</code></li>
<li><code>Vector</code>：如将多个寄存器与多个寄存器相加，结果保存到多个寄存器中–即同时处理多个寄存器</li>
<li>如果不是<code>Vector</code>，则通过分支预测进行动态ILP，或通过编译器展开循环进行静态ILP</li>
</ol>
</li>
</ol>
<h2 id="7-2-数据依赖"><a href="#7-2-数据依赖" class="headerlink" title="7.2    数据依赖"></a>7.2    数据依赖</h2><h3 id="7-2-1-真实数据依赖：RAW-写后读"><a href="#7-2-1-真实数据依赖：RAW-写后读" class="headerlink" title="7.2.1    真实数据依赖：RAW 写后读"></a>7.2.1    真实数据依赖：RAW 写后读</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215013129216.png" alt="image-20221215013129216" style="zoom:80%;" /></p>
<h3 id="7-2-2-命名依赖"><a href="#7-2-2-命名依赖" class="headerlink" title="7.2.2    命名依赖"></a>7.2.2    命名依赖</h3><ol>
<li><p>命名依赖：后面要写的寄存器，出现在了前面的源/目的寄存器中</p>
<ol>
<li>可以通过寄存器重命名解决<ol>
<li>编译器解决：更容易知道重命名到什么时候</li>
<li>硬件解决：需要考虑重命名到什么时候、CPU是否支持多个重命名同时存在</li>
</ol>
</li>
</ol>
</li>
<li><p>WAR 读后写—anti-dependence</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215013200891.png" alt="image-20221215013200891" style="zoom:80%;" /></p>
</li>
<li><p>WAW 写后写–output dependence</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221215013602548.png" alt="image-20221215013602548" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="7-2-3-控制依赖"><a href="#7-2-3-控制依赖" class="headerlink" title="7.2.3    控制依赖"></a>7.2.3    控制依赖</h3><ol>
<li>一般情况下，CPU的指令重排只在两个跳转之间进行，不会跨越跳转</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224121945082.png" alt="image-20221224121945082" style="zoom:80%;" /></p>
<blockquote>
<p>  Example 1：由于beq的存在，or指令可能与add有依赖，也可能与sub有依赖</p>
<p>  Example 2：x4在skip后没有使用，sub指令可能可以被移动到beq之前</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224122000258.png" alt="image-20221224122000258" style="zoom:80%;" /></p>
</blockquote>
<h3 id="7-2-4-异常"><a href="#7-2-4-异常" class="headerlink" title="7.2.4    异常"></a>7.2.4    异常</h3><ol>
<li>指令重排不能影响异常的精确性</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224122519160.png" alt="image-20221224122519160" style="zoom:80%;" /></p>
<h2 id="7-3-ILP：软件方法—静态调度"><a href="#7-3-ILP：软件方法—静态调度" class="headerlink" title="7.3    ILP：软件方法—静态调度"></a>7.3    ILP：软件方法—静态调度</h2><h3 id="7-3-1-相关技术"><a href="#7-3-1-相关技术" class="headerlink" title="7.3.1    相关技术"></a>7.3.1    相关技术</h3><ol>
<li>实现ILP的基本编译器技术<ol>
<li>循环展开</li>
</ol>
</li>
<li>静态分支预测</li>
<li>静态多重问题：VLIW</li>
<li>实现ILP的高级编译器支持<ol>
<li>软件流水线</li>
<li>全局代码调度</li>
</ol>
</li>
<li>在编译时实现更高ILP的硬件支持<ol>
<li>硬件为编译器提供更多指令级</li>
<li>条件或谓词指令</li>
<li>具有硬件支持的编译器推测</li>
</ol>
</li>
</ol>
<h3 id="7-3-2-示例"><a href="#7-3-2-示例" class="headerlink" title="7.3.2    示例"></a>7.3.2    示例</h3><blockquote>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224124330255.png" alt="image-20221224124330255" style="zoom:80%;" /></p>
<p>  指令没有重排：</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224124339110.png" alt="image-20221224124339110" style="zoom:80%;" /></p>
<p>  指令重排后：</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224124538331.png" alt="image-20221224124538331" style="zoom:80%;" /></p>
</blockquote>
<h3 id="7-3-3-跳转指令的delay-slot"><a href="#7-3-3-跳转指令的delay-slot" class="headerlink" title="7.3.3    跳转指令的delay slot"></a>7.3.3    跳转指令的delay slot</h3><ol>
<li>跳转指令后面的一条指令，不论跳转是否成功，都可以执行完成</li>
<li>可以把一条指令(不论跳还是不跳都要执行)放在branch的后面，就可以充分利用branch的delay slot</li>
<li>一般是从跳转前拿一条指令放在后面，这条指令的执行不影响跳转的结果</li>
</ol>
<h2 id="7-4-ILP：硬件方法—动态调度"><a href="#7-4-ILP：硬件方法—动态调度" class="headerlink" title="7.4    ILP：硬件方法—动态调度"></a>7.4    ILP：硬件方法—动态调度</h2><h3 id="7-4-1-为什么需要动态调度"><a href="#7-4-1-为什么需要动态调度" class="headerlink" title="7.4.1    为什么需要动态调度"></a>7.4.1    为什么需要动态调度</h3><blockquote>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224125602940.png" alt="image-20221224125602940" style="zoom:80%;" /></p>
</blockquote>
<ol>
<li>某个被stall的指令，与之前的指令没有依赖关系，但由于之前的指令stall了，它也不得不stall</li>
<li>可以通过动态调度，让后面的指令先执行</li>
<li>也成为指令重排</li>
</ol>
<h3 id="7-4-2-基本思路"><a href="#7-4-2-基本思路" class="headerlink" title="7.4.2    基本思路"></a>7.4.2    基本思路</h3><ol>
<li>将指令的ID阶段分为两个阶段<ol>
<li>Issue(发射)：译码指令，判断是否有结构冲突</li>
<li>Read Operands：等待，直到没有数据冲突，然后读寄存器，这里要有能够支持等待的存储单元</li>
</ol>
</li>
</ol>
<h2 id="7-5-Scoreboard-计分板"><a href="#7-5-Scoreboard-计分板" class="headerlink" title="7.5    Scoreboard 计分板"></a>7.5    Scoreboard 计分板</h2><ol>
<li>当资源充足且无数据依赖性时，允许指令无序执行</li>
<li>顺序issue</li>
<li>乱序EXE</li>
<li>乱序completion</li>
</ol>
<h3 id="7-5-1-基本结构"><a href="#7-5-1-基本结构" class="headerlink" title="7.5.1    基本结构"></a>7.5.1    基本结构</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224131058716.png" alt="image-20221224131058716" style="zoom: 67%;" /></p>
<h3 id="7-5-2-计分板的流水级"><a href="#7-5-2-计分板的流水级" class="headerlink" title="7.5.2    计分板的流水级"></a>7.5.2    计分板的流水级</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224131346039.png" alt="image-20221224131346039" style="zoom: 80%;" /></p>
<ol>
<li>发出（Issue）：在以下情况下发出指令<ol>
<li>功能单元可用</li>
<li>没有其他活动指令具有相同的目标寄存器。</li>
<li>没有<strong>structural</strong>冲突、<strong>WAW</strong>冲突</li>
</ol>
</li>
<li>读取操作数（RO）<ol>
<li>两个操作数都可用，才能进入EX阶段，否则一直在RO阶段</li>
<li>这意味着以前发出但未完成的指令都没有将操作数作为目标</li>
<li>这可动态解决<strong>RAW</strong>冲突</li>
</ol>
</li>
<li>执行（EX）<ol>
<li>完成后通知记分板，以便重新使用功能单元</li>
</ol>
</li>
<li>写入结果（WB）<ol>
<li>记分板检查<strong>WAR</strong>冲突，如果有则stall</li>
</ol>
</li>
</ol>
<h3 id="7-5-3-计分板算法"><a href="#7-5-3-计分板算法" class="headerlink" title="7.5.3    计分板算法"></a>7.5.3    计分板算法</h3><ol>
<li><p>记分板全权负责指令发布和执行</p>
<ol>
<li>创建相关性记录</li>
<li>决定何时获取操作数</li>
<li>决定何时开始执行</li>
<li>决定何时可以将结果写入寄存器</li>
</ol>
</li>
<li><p>三种数据结构</p>
<ol>
<li><p><strong>Instruction status</strong></p>
<ol>
<li>指令在四个步骤中的哪一个</li>
</ol>
</li>
<li><p><strong>Functional unit status</strong></p>
<p>|  状态  |                            解释                             |<br>| :——: | :————————————————————————————-: |<br>|  Busy  |                   表示当前单元是否被占用                    |<br>|   Op   |          当前单元正在执行的指令(如add or subtract)          |<br>|   Fi   |                         目标寄存器                          |<br>| Fj, Fk |                          源寄存器                           |<br>| Qj, Qk |                生成源寄存器Fj, Fk的功能单元                 |<br>| Rj, Rk | 判断源寄存器Fj, Fk是否已经ready；当操作数被读取之后，设为NO |</p>
</li>
<li><p><strong>Register result status</strong></p>
<ol>
<li>哪个功能单元将写入该寄存器</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="7-5-4-记分牌算法的具体运行方式"><a href="#7-5-4-记分牌算法的具体运行方式" class="headerlink" title="7.5.4    记分牌算法的具体运行方式"></a>7.5.4    记分牌算法的具体运行方式</h3><p>指令的等待：Function Unit，每个Function Unit最多有1条指令等待执行</p>
<ol>
<li><strong>Issue</strong>：<ol>
<li>如果对应功能部件被占用，则<strong>stall</strong>：防止结构冲突</li>
<li>计算完成后，更新记分牌<ol>
<li><code>Function Unit Status</code>：<ol>
<li><code>Busy</code>：设置为<code>Yes</code></li>
<li><code>Op</code>：设置为对应的操作</li>
<li><code>Fi</code>：设置为目标寄存器</li>
<li><code>Fj,Fk</code>：设置为源寄存器</li>
<li><code>Qj,Qk</code>：如果源寄存器被占用，则设置为对应的功能部件</li>
<li><code>Rj,Rk</code>：如果源寄存器未被占用，则为<code>Yes</code>；否则为<code>No</code></li>
</ol>
</li>
<li><code>Register Result Statue</code>：<ol>
<li><code>Fi</code>对应的位置：设置为当前部件</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong>RO</strong>：<ol>
<li>如果<code>Rj,Rk</code>不全为<code>Yes</code>，则<strong>stall</strong>：防止RAW冲突</li>
<li>读取源寄存器</li>
</ol>
</li>
<li><strong>EXE</strong>：<ol>
<li>功能部件计算结果</li>
<li>计算完成后，更新记分牌<ol>
<li><code>Function Unit Status</code>：<ol>
<li><code>Rj,Rk</code>：设置为<code>No</code>，表示释放对应的寄存器</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong>WB</strong>：<ol>
<li>将计算结果写入目标寄存器</li>
<li>计算完成后，更新记分牌：<ol>
<li><code>Function Unit Status</code>：<ol>
<li>清空当前功能部件</li>
<li>如果其它功能部件中，<code>Qj,Qk</code>对应的部件为当前部件，则将其清除，并将<code>Rj,Rk</code>设置为<code>Yes</code></li>
</ol>
</li>
<li><code>Register Result Statue</code>：<ol>
<li>清空<code>Fi</code>对应的位置</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="7-5-5-示例"><a href="#7-5-5-示例" class="headerlink" title="7.5.5    示例"></a>7.5.5    示例</h3><blockquote>
<p>  详见视频讲解</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224132827051.png" alt="image-20221224132827051"></p>
<h3 id="7-5-6-Scoreboard的局限性"><a href="#7-5-6-Scoreboard的局限性" class="headerlink" title="7.5.6    Scoreboard的局限性"></a>7.5.6    Scoreboard的局限性</h3><ol>
<li>如果后面的每一条指令都依赖前面的指令，则Scoreboard用处不大</li>
<li>issue queue的大小问题：<ol>
<li>window：CPU有多少指令可以处于等待状态，一般不能超出一个branch的范围</li>
</ol>
</li>
<li>放弃了功能部件的流水性</li>
<li>存在WAR和WAW冲突，但Scoreboard选择stall解决</li>
</ol>
<h2 id="7-6-寄存器重命名"><a href="#7-6-寄存器重命名" class="headerlink" title="7.6    寄存器重命名"></a>7.6    寄存器重命名</h2><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224143115212.png" alt="image-20221224143115212" style="zoom:80%;" /></p>
<ol>
<li>任何指令的写，都不写入寄存器，而是写入换名寄存器中</li>
<li>之后对该寄存器的读，直接读取换名寄存器</li>
</ol>
<h2 id="7-7-Scoreboard-vs-Tomasulo"><a href="#7-7-Scoreboard-vs-Tomasulo" class="headerlink" title="7.7    Scoreboard vs. Tomasulo"></a>7.7    Scoreboard vs. Tomasulo</h2><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224151613454.png" alt="image-20221224151613454" style="zoom:80%;" /></p>
<h1 id="Chapter-8：Dynamic-Schedule—Tomasulo"><a href="#Chapter-8：Dynamic-Schedule—Tomasulo" class="headerlink" title="Chapter 8：Dynamic Schedule—Tomasulo"></a>Chapter 8：Dynamic Schedule—Tomasulo</h1><h2 id="8-1-Tomasulo算法"><a href="#8-1-Tomasulo算法" class="headerlink" title="8.1    Tomasulo算法"></a>8.1    Tomasulo算法</h2><h3 id="8-1-1-基础思想"><a href="#8-1-1-基础思想" class="headerlink" title="8.1.1    基础思想"></a>8.1.1    基础思想</h3><ol>
<li>指令&amp;缓存 被分布在每个功能单元(FU，Function Units)中<ol>
<li><strong>FU buffer</strong>被称作<strong>保留站(RS，reservation stations)</strong>，具有挂起的操作数</li>
</ol>
</li>
<li>指令中的寄存器被替换为 <strong>具体的值</strong> / <strong>指向保留站的指针</strong>，被称为<code>register renaming</code><ol>
<li>避免了WAR、WAW冲突</li>
<li>保留站比寄存器多，因此可以进行一些编译器不能进行的优化</li>
</ol>
</li>
<li>当指令要进行计算时，操作数 从保留站中通过<strong>CDB(Common Data Bus)</strong>广播获取，而不是寄存器<ol>
<li>寄存器进保留站只有一个时刻：指令进入保留站的时候</li>
</ol>
</li>
<li>Load、Store也被视为FU，也拥有RS</li>
<li>整数指令可以穿过branch使用，如循环中下一次的指令可以直接使用上一次计算出来的值</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224153655313.png" alt="image-20221224153655313" style="zoom:80%;" /></p>
<h3 id="8-1-2-保留站的内容"><a href="#8-1-2-保留站的内容" class="headerlink" title="8.1.2    保留站的内容"></a>8.1.2    保留站的内容</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">状态</th>
<th style="text-align:center">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Busy</td>
<td style="text-align:center">表示当前行是否有指令</td>
</tr>
<tr>
<td style="text-align:center">Op</td>
<td style="text-align:center">当前行的指令(如add or subtract)</td>
</tr>
<tr>
<td style="text-align:center">Vj, Vk</td>
<td style="text-align:center">源寄存器能读取到的数据</td>
</tr>
<tr>
<td style="text-align:center">Qj, Qk</td>
<td style="text-align:center">尚不能读取到的数据将由哪条指令算出</td>
</tr>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">指令的地址，用于存放立即数和计算得到的地址数据</td>
</tr>
</tbody>
</table>
</div>
<h3 id="8-1-3-三个阶段"><a href="#8-1-3-三个阶段" class="headerlink" title="8.1.3    三个阶段"></a>8.1.3    三个阶段</h3><p>Tomasulo算法的调度分为三个步骤：<strong>发射</strong>、<strong>执行</strong>、<strong>写回</strong></p>
<ol>
<li>发射<strong>Issue</strong>：<ol>
<li><strong>Tomasulo算法是顺序发射的</strong>，即指令按照程序中的顺序一条接一条被发射到保留站</li>
<li><strong>判断能否发射的唯一标准是指令对应通路的保留站是否有空余位置</strong>，只要保留站有空余，就可以把指令发射到保留站中</li>
<li>周期结束时会更新保留站和寄存器结果状态表，如果指令有可以读取的数据，就会立刻拷贝到保留站中</li>
<li>寄存器结果状态表中总是存有最新的值，即如果后序指令的目的寄存器和前序指令的目的寄存器重合，那就只保留后序指令的写信息</li>
</ol>
</li>
<li>执行<strong>EXE</strong>：<ol>
<li>指令通过拷贝数据和监听CDB获得源数据，然后开始执行</li>
<li>执行可能是多周期的，在执行过程中不改变处理器状态</li>
</ol>
</li>
<li>写回<strong>WB</strong>：<ol>
<li>指令在写回阶段通过CDB总线将数据直通到寄存器堆和各个保留站</li>
<li>周期结束时，根据寄存器结果状态表来更新寄存器堆，并且清除保留站和寄存器结果状态表的信息</li>
</ol>
</li>
</ol>
<h3 id="8-1-4-Data-Path"><a href="#8-1-4-Data-Path" class="headerlink" title="8.1.4    Data Path"></a>8.1.4    Data Path</h3><ol>
<li>Normal Data Bus：数据 + 目标地址</li>
<li>Common Data Bus：数据 + 源地址<ol>
<li>64-bit数据 + 4-bit 功能单元的源地址</li>
<li>如果与期望的功能单元地址匹配，则写入</li>
</ol>
</li>
</ol>
<h3 id="8-1-5-具体运行方式"><a href="#8-1-5-具体运行方式" class="headerlink" title="8.1.5    具体运行方式"></a>8.1.5    具体运行方式</h3><ol>
<li><strong>Issue</strong>：<ol>
<li>如果对应功能部件被占用，则<strong>stall</strong>：防止结构冲突</li>
<li>计算完成后，更新保留站<ol>
<li><code>Reservation Station</code>：<ol>
<li><code>Busy</code>：设置为<code>Yes</code></li>
<li><code>Op</code>：设置为对应的操作</li>
<li><code>Vj,Vk</code>：设置为读取到的源寄存器的值</li>
<li><code>Qj,Qk</code>：如果源寄存器被占用，则设置为对应的功能部件</li>
<li><code>A</code>：如果指令为LD/ST，则设置为计算出的目标地址</li>
</ol>
</li>
<li><code>Register Result Statue</code>：<ol>
<li>目标寄存器对应的位置：设置为当前部件</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong>EXE</strong>：<ol>
<li>如果<code>Vj,Vk</code>没有都被填入，则<strong>stall</strong>：防止RAW冲突</li>
<li>功能部件计算结果</li>
</ol>
</li>
<li><strong>WB</strong>：<ol>
<li>将计算出的结果放入<code>CDB</code>中进行广播，并写入寄存器堆</li>
<li>计算完成后，更新保留站<ol>
<li><code>Reservation Station</code>：<ol>
<li>清空当前功能部件</li>
<li>如果其它功能部件中，<code>Qj,Qk</code>对应的部件为当前部件，则读取CDB中的值，放入对应的<code>Vj,Vk</code>中</li>
</ol>
</li>
<li><code>Register Result Statue</code>：<ol>
<li>清空<code>Fi</code>对应的位置</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="8-1-6-示例"><a href="#8-1-6-示例" class="headerlink" title="8.1.6    示例"></a>8.1.6    示例</h3><blockquote>
<p>  具体见视频</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224160451110.png" alt="image-20221224160451110" style="zoom:80%;" /></p>
<h3 id="8-1-7-优缺点"><a href="#8-1-7-优缺点" class="headerlink" title="8.1.7    优缺点"></a>8.1.7    优缺点</h3><blockquote>
<p>  Tomasulo算法记录寄存器的值，Scoreboard算法只记录寄存器的编号</p>
</blockquote>
<p>优点：</p>
<ol>
<li>将hazard detection logic分散开<ol>
<li>每个功能单元都有一个保留站，使用CDB进行广播</li>
<li>如果多条指令等待同一个结果，并且每条指令都有其它的操作数，当目标结果在CDB中被广播时，这些指令可以同时释放</li>
</ol>
</li>
<li>可以消除WAW、WAR冲突</li>
</ol>
<p>缺点：</p>
<ol>
<li>需要实现一个高速CDB</li>
<li>每一个cycle只能有一个功能部件完成，因为CDB上同时只有一个数据</li>
</ol>
<h3 id="8-1-8-Tomasolo算法的指令可以跨越循环的前后轮"><a href="#8-1-8-Tomasolo算法的指令可以跨越循环的前后轮" class="headerlink" title="8.1.8    Tomasolo算法的指令可以跨越循环的前后轮"></a>8.1.8    Tomasolo算法的指令可以跨越循环的前后轮</h3><ol>
<li>Tomasolo算法可以实现事实上的动态展开循环，每一轮都可以正常进行<ol>
<li>要求branch为预测跳转</li>
</ol>
</li>
<li>寄存器重命名<ol>
<li>多次迭代使用不同的物理目标</li>
</ol>
</li>
<li>寄存器重命名<ol>
<li>多次迭代使用不同的寄存器物理目的地（动态循环展开）</li>
</ol>
</li>
<li>保留站<ol>
<li>允许发出指令以推进过去的整数控制流操作</li>
<li>还缓冲寄存器的旧值—完全避免了我们在记分板上看到的WAR暂停</li>
</ol>
</li>
<li>其他观点：Tomasulo动态构建数据流依赖图</li>
</ol>
<blockquote>
<p>  示例：</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224163547124.png" alt="image-20221224163547124" style="zoom:80%;" /></p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224164347175.png" alt="image-20221224164347175" style="zoom:80%;" /></p>
<ol>
<li>注意，这里直接将Load2写入了F0对应的位置<ol>
<li>因为需要Load1结果的指令MULTD此时等待的是Load1的值，而不是F0的值</li>
</ol>
</li>
</ol>
</blockquote>
<h3 id="8-1-9-精确中断"><a href="#8-1-9-精确中断" class="headerlink" title="8.1.9    精确中断"></a>8.1.9    精确中断</h3><ol>
<li>Tomasulo算法的特点：<ol>
<li>顺序issue</li>
<li>乱序execution</li>
<li>乱序completion</li>
</ol>
</li>
<li>需要修复乱序完成的操作，从而能在指令流中找到精确的断点<ol>
<li>Speculation</li>
<li>Reorder buffer</li>
</ol>
</li>
</ol>
<h2 id="8-2-Scoreboard算法：通过寄存器重命名避免WAR、WAW等待"><a href="#8-2-Scoreboard算法：通过寄存器重命名避免WAR、WAW等待" class="headerlink" title="8.2    Scoreboard算法：通过寄存器重命名避免WAR、WAW等待"></a>8.2    Scoreboard算法：通过寄存器重命名避免WAR、WAW等待</h2><h3 id="8-2-1-Scoreboard的流水级"><a href="#8-2-1-Scoreboard的流水级" class="headerlink" title="8.2.1    Scoreboard的流水级"></a>8.2.1    Scoreboard的流水级</h3><ol>
<li><strong>Issue</strong>：在以下情况下发出指令<ol>
<li>功能单元可用</li>
<li>没有其他活动指令具有相同的目标寄存器。</li>
<li>解决了：<strong>structural</strong>冲突、<strong>WAW</strong>冲突</li>
</ol>
</li>
<li><strong>Read Operands</strong>（RD）<ol>
<li>两个操作数都可用，才能进入EX阶段，否则一直在RO阶段</li>
<li>这意味着以前发出但未完成的指令都没有将操作数作为目标</li>
<li>解决了：<strong>RAW</strong>冲突</li>
</ol>
</li>
<li><strong>Execution</strong>（EX）<ol>
<li>完成后通知记分板，以便重新使用功能单元</li>
</ol>
</li>
<li><strong>Write Result</strong>（WB）<ol>
<li>记分板检查<strong>WAR</strong>冲突，如果有则stall</li>
</ol>
</li>
</ol>
<h3 id="8-2-2-Scoreboard算法"><a href="#8-2-2-Scoreboard算法" class="headerlink" title="8.2.2    Scoreboard算法"></a>8.2.2    Scoreboard算法</h3><ol>
<li><p>记分板全权负责指令发布和执行</p>
<ol>
<li>创建相关性记录</li>
<li>决定何时获取操作数</li>
<li>决定何时开始执行</li>
<li>决定何时可以将结果写入寄存器</li>
</ol>
</li>
<li><p>三种数据结构</p>
<ol>
<li><p><strong>Instruction status</strong></p>
<ol>
<li>指令在四个步骤中的哪一个</li>
</ol>
</li>
<li><strong>Functional unit status</strong><ol>
<li>buzy，op，Fi，Fj，Fk，Qj，Qk，Rj，Rk</li>
</ol>
</li>
<li><strong>Register result status</strong><ol>
<li>哪个功能单元将写入该寄存器</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="8-2-3-Explicit-Renaming-显式寄存器重命名"><a href="#8-2-3-Explicit-Renaming-显式寄存器重命名" class="headerlink" title="8.2.3    Explicit Renaming 显式寄存器重命名"></a>8.2.3    Explicit Renaming 显式寄存器重命名</h3><h4 id="8-2-3-1-前提"><a href="#8-2-3-1-前提" class="headerlink" title="8.2.3.1    前提"></a>8.2.3.1    前提</h4><ol>
<li>物理寄存器 &gt; 逻辑寄存器</li>
</ol>
<h4 id="8-2-3-2-核心思路"><a href="#8-2-3-2-核心思路" class="headerlink" title="8.2.3.2    核心思路"></a>8.2.3.2    核心思路</h4><p>对每一条需要写寄存器的指令，分配一个新的物理目标寄存器</p>
<ol>
<li>与编译器优化方式(SSA, Static Single Assignment)类似，但是是硬件实现</li>
<li>消除了WAR和WAW冲突</li>
<li>与Tomasulo类似，更加容易支持全乱序完成</li>
<li>类似于基于硬件的动态编译</li>
</ol>
<h4 id="8-2-3-3-实现机制"><a href="#8-2-3-3-实现机制" class="headerlink" title="8.2.3.3    实现机制"></a>8.2.3.3    实现机制</h4><p>维护一个<strong>translation table</strong></p>
<ol>
<li>映射：ISA寄存器 =&gt; 物理寄存器</li>
<li>写寄存器时：从freelist中得到一个新的寄存器，替换原有项</li>
<li>释放物理寄存器的时机：所有使用该物理寄存器的指令均已执行完成<ol>
<li>由于第二次写同一个逻辑寄存器时，该逻辑寄存器会被分配另一个物理寄存器</li>
<li>因此，只有两次写同一个逻辑寄存器之间的指令，有可能使用同一个物理寄存器</li>
</ol>
</li>
</ol>
<h4 id="8-2-3-4-优点"><a href="#8-2-3-4-优点" class="headerlink" title="8.2.3.4    优点"></a>8.2.3.4    优点</h4><ol>
<li>将<strong>renaming</strong>与<strong>scheduling</strong>分离<ol>
<li>流水线可以更贴近于标准MIPS流水线，只是每个周期可能会发射多条指令</li>
<li>否则的话，流水线更类似于Tomasulo或Scoreboard</li>
<li>可以使用标准的<code>forwarding</code>、<code>bypassing</code></li>
</ol>
</li>
<li>允许数据从单个寄存器组中读取<ol>
<li>不需要从<code>reservation stations</code>或<code>reorder buffer</code>中获取数据</li>
<li>对平衡流水线来说，很重要</li>
</ol>
</li>
<li>是另一种获取<strong>精确断点</strong>的方式：<ol>
<li>要获得精确的断点，所有需要“撤消”的操作就是撤消表映射</li>
<li>在<code>reorder buffer</code>和<code>future file</code>之间提供有趣的混合<ol>
<li>结果立即写回寄存器文件</li>
<li>寄存器名称按程序顺序“释放”（通过ROB）</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="8-2-3-5-需要的支持"><a href="#8-2-3-5-需要的支持" class="headerlink" title="8.2.3.5    需要的支持"></a>8.2.3.5    需要的支持</h4><ol>
<li>快速访问翻译表</li>
<li>一种物理寄存器文件，其寄存器数超过ISA指定的寄存器数</li>
<li>能够找出哪些物理寄存器是free的<ol>
<li>没有free的寄存器 ⇒ issue会被stall</li>
</ol>
</li>
<li>寄存器重命名不需要保留站，然而：<ol>
<li>许多现代体系结构使用<code>explicit register renaming</code> + <code>Tomasulo-like reservation stations</code>来控制执行流程</li>
</ol>
</li>
<li>两个问题：<ol>
<li>如何管理<code>free list</code>？</li>
<li>显示寄存器重命名 如何与 精确中断相结合？</li>
</ol>
</li>
</ol>
<h4 id="8-2-3-6-示例"><a href="#8-2-3-6-示例" class="headerlink" title="8.2.3.6    示例"></a>8.2.3.6    示例</h4><blockquote>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224183942183.png" alt="image-20221224183942183" style="zoom:80%;" /></p>
<ol>
<li>物理寄存器表 &gt; ISA寄存器表</li>
<li><p>在<code>issue</code>阶段，每条指令从<code>freelist</code>中申请一个寄存器，作为自己的目的寄存器</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184043723.png" alt="image-20221224184043723" style="zoom:80%;" /></p>
</li>
<li><p>注意物理寄存器<code>P0</code>在这次load之后已经<code>dead</code></p>
<ol>
<li>当我们完成load操作后，我们释放该寄存器</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184301168.png" alt="image-20221224184301168" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184324219.png" alt="image-20221224184324219" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184354451.png" alt="image-20221224184354451" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184405761.png" alt="image-20221224184405761" style="zoom:80%;" /></p>
</li>
</ol>
</blockquote>
<h4 id="8-2-3-7-在Scoreboard中使用显式重命名"><a href="#8-2-3-7-在Scoreboard中使用显式重命名" class="headerlink" title="8.2.3.7    在Scoreboard中使用显式重命名"></a>8.2.3.7    在Scoreboard中使用显式重命名</h4><ol>
<li>实现一个Rename Table：告诉Scoreboard，指令里面的哪个寄存器被换成哪个寄存器了</li>
<li>Rename Table后面是一个更大的寄存器表，该表不对ISA公开，只能由Rename Table使用</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224184559742.png" alt="image-20221224184559742" style="zoom:80%;" /></p>
<h4 id="8-2-3-8-显式重命名Scoreboard的四个阶段"><a href="#8-2-3-8-显式重命名Scoreboard的四个阶段" class="headerlink" title="8.2.3.8    显式重命名Scoreboard的四个阶段"></a>8.2.3.8    显式重命名Scoreboard的四个阶段</h4><ol>
<li><strong>Issue</strong>：指令译码、检查是否有结构冲突、<strong>为目标寄存器申请新的物理寄存器</strong><ol>
<li>指令按序issue</li>
<li>如果没有物理寄存器，则stall</li>
<li>如果有结构冲突，则stall</li>
</ol>
</li>
<li><strong>Read Operands</strong>：直到没有冲突的时候，读取操作数<ol>
<li>解决了RAW冲突，因为我们等待指令写回数据</li>
</ol>
</li>
<li><strong>Execution</strong>：计算</li>
<li><strong>Write Result</strong>：结束计算</li>
<li>在这个过程中，没有检查WAR、WAW冲突</li>
</ol>
<blockquote>
<p>  示例见视频</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224202935623.png" alt="image-20221224202935623" style="zoom:80%;" /></p>
</blockquote>
<h1 id="Chapter-9-：Branch-Predictor-amp-Speculation"><a href="#Chapter-9-：Branch-Predictor-amp-Speculation" class="headerlink" title="Chapter 9 ：Branch Predictor &amp; Speculation"></a>Chapter 9 ：Branch Predictor &amp; Speculation</h1><h2 id="9-1-Control-Hazard"><a href="#9-1-Control-Hazard" class="headerlink" title="9.1    Control Hazard"></a>9.1    Control Hazard</h2><ol>
<li><strong>Flushing</strong>：<ol>
<li>每次遇到跳转，直接stall，直到跳转指令完成</li>
</ol>
</li>
<li><strong>Predict-not-taken</strong>：<ol>
<li>直接读入跳转指令的下一条指令</li>
<li>如果发现跳转指令为跳转，则清空流水线，此时浪费了1个周期</li>
</ol>
</li>
<li><strong>Predict-taken</strong>：<ol>
<li>读入如果跳转时的下一条指令</li>
<li>如果发现跳转指令为不跳转，则清空流水线，此时浪费了1个周期</li>
</ol>
</li>
<li><strong>Delayed Branch</strong></li>
</ol>
<h2 id="9-2-动态硬件预测"><a href="#9-2-动态硬件预测" class="headerlink" title="9.2    动态硬件预测"></a>9.2    动态硬件预测</h2><blockquote>
<p>  动态硬件预测，只有当前跳转指令被反复执行到的前提下，才有意义</p>
<p>  预测是基于数据的预测，因此只能预测下一次遇到当前地址的跳转指令时，是否跳转</p>
</blockquote>
<h3 id="9-2-1-1-bit-Branch-Prediction-Buffer"><a href="#9-2-1-1-bit-Branch-Prediction-Buffer" class="headerlink" title="9.2.1    1-bit Branch-Prediction Buffer"></a>9.2.1    1-bit Branch-Prediction Buffer</h3><ol>
<li>Performance = ƒ(accuracy, cost of misprediction)</li>
<li><strong>BHT</strong>，<code>Branch History Table</code>：<ol>
<li><code>index</code>：PC地址的低位</li>
<li><code>value</code>：1位，记录上一次是否跳转</li>
</ol>
</li>
<li>问题：<ol>
<li>在一个循环中，1-bit BHT会导致2次misprediction：进入循环、退出循环</li>
<li>accurancy：(n-2)/n</li>
</ol>
</li>
</ol>
<h3 id="9-2-2-2-bit-Branch-Prediction-Buffer"><a href="#9-2-2-2-bit-Branch-Prediction-Buffer" class="headerlink" title="9.2.2    2-bit Branch-Prediction Buffer"></a>9.2.2    2-bit Branch-Prediction Buffer</h3><blockquote>
<p>  策略1：初始为Taken，发生2次not-taken后，才预测not-taken</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224204931564.png" alt="image-20221224204931564" style="zoom:80%;" /></p>
<blockquote>
<p>  策略2：进入临时状态后，如果是taken，就回到taken了</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224205039036.png" alt="image-20221224205039036" style="zoom:80%;" /></p>
<h3 id="9-2-3-n-bit-Branch-Prediction-Buffer"><a href="#9-2-3-n-bit-Branch-Prediction-Buffer" class="headerlink" title="9.2.3    n-bit Branch-Prediction Buffer"></a>9.2.3    n-bit Branch-Prediction Buffer</h3><blockquote>
<p>  与1-bit和2-bit类似，设计更加复杂的状态图</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224205242395.png" alt="image-20221224205242395" style="zoom:80%;" /></p>
<h3 id="9-2-4-Branch-Target-Buffer"><a href="#9-2-4-Branch-Target-Buffer" class="headerlink" title="9.2.4    Branch Target Buffer"></a>9.2.4    Branch Target Buffer</h3><ol>
<li>在循环中，每次跳转时，跳转的目的地址都是一样的</li>
<li>可以将跳转的目的地址缓存起来，减少一次加法</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224210044159.png" alt="image-20221224210044159" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224210258569.png" alt="image-20221224210258569" style="zoom:80%;" /></p>
<h3 id="9-2-5-Integrated-Instruction-Fetch-Units-集成指令获取单元"><a href="#9-2-5-Integrated-Instruction-Fetch-Units-集成指令获取单元" class="headerlink" title="9.2.5    Integrated Instruction Fetch Units 集成指令获取单元"></a>9.2.5    Integrated Instruction Fetch Units 集成指令获取单元</h3><p>将IF阶段扩展，IF阶段可以实现：</p>
<ol>
<li>branch predication</li>
<li>Instruction prefetch</li>
<li>Instruction memory access and buffering</li>
</ol>
<h3 id="9-2-6-Return-Address-Predictor"><a href="#9-2-6-Return-Address-Predictor" class="headerlink" title="9.2.6    Return Address Predictor"></a>9.2.6    Return Address Predictor</h3><ol>
<li>间接跳转：目的地地址在运行时变化<ol>
<li>如从函数返回、使用函数指针跳转、对虚函数的访问</li>
</ol>
</li>
<li>寄存器的存在，使得难以预测跳转的地址</li>
<li>SPEC89：程序返回占间接跳转的85%</li>
<li><code>Branch Target Buffer</code>对return不起作用</li>
<li><code>LR(Link Register)</code>寄存器：用于存储函数的返回地址，在RISCV中是<code>ra</code>寄存器<ol>
<li>进入函数时，通常会先将<code>LR</code>寄存器保存进堆栈，然后再执行函数的逻辑</li>
</ol>
</li>
</ol>
<h2 id="9-3-Hardware-Based-Speculation-投机"><a href="#9-3-Hardware-Based-Speculation-投机" class="headerlink" title="9.3    Hardware Based Speculation 投机"></a>9.3    Hardware Based Speculation 投机</h2><h3 id="9-3-1-Tomasulo的缺点"><a href="#9-3-1-Tomasulo的缺点" class="headerlink" title="9.3.1    Tomasulo的缺点"></a>9.3.1    Tomasulo的缺点</h3><ol>
<li>无法实现精确中断<ol>
<li>精确中断：中断发生时，该指令之前的指令均执行完成，后面的指令均没有执行</li>
</ol>
</li>
<li>WB阶段检测中断<ol>
<li>外部中断：找到最后面已经完成的指令，这之前的全部完成，之后的全部没有完成</li>
<li>内部中断：<ol>
<li>非法指令、除0异常：直接终止程序</li>
<li>缺页异常：仍需要回到产生中断的那条指令，要求必须精确中断。可以通过添加内存栅栏，让CPU强制等待到当前指令</li>
</ol>
</li>
</ol>
</li>
<li>会部分overlap<ol>
<li>整数单元先跑，浮点单元后跑</li>
<li>尽管可以issue，但后续基本块在分支解决之前无法开始执行</li>
</ol>
</li>
</ol>
<h3 id="9-3-2-Hardward-based-Speculation"><a href="#9-3-2-Hardward-based-Speculation" class="headerlink" title="9.3.2    Hardward-based Speculation"></a>9.3.2    Hardward-based Speculation</h3><blockquote>
<p>  投机：在不知道branch指令是否跳转的情况下，先去做后面的指令</p>
</blockquote>
<ol>
<li>对branch的结果做speculation，假装预测是对的来执行程序</li>
<li>关键点<ol>
<li>动态分支预测，选择跳转到哪里</li>
<li>由于跳转指令依赖于寄存器，因此跳转指令可能也要等待其它指令的执行完成</li>
<li>指令可以先执行，但指令的执行结果必须等待之前的指令均执行完，才能写入内存/寄存器</li>
<li><strong>乱序执行、顺序写入</strong></li>
</ol>
</li>
<li>算法<ol>
<li>按照预测的顺序执行，但是不commit</li>
<li>只有预测的结果正确时，才将其提交：写寄存器组、写内存</li>
<li>如果预测结果不正确，则回滚：清空Reorder Buffer</li>
</ol>
</li>
</ol>
<h3 id="9-3-3-基于Tomasulo算法的投机执行-Speculative-execution"><a href="#9-3-3-基于Tomasulo算法的投机执行-Speculative-execution" class="headerlink" title="9.3.3    基于Tomasulo算法的投机执行 Speculative execution"></a>9.3.3    基于Tomasulo算法的投机执行 Speculative execution</h3><h4 id="9-3-3-1-基础思想"><a href="#9-3-3-1-基础思想" class="headerlink" title="9.3.3.1    基础思想"></a>9.3.3.1    基础思想</h4><ol>
<li>将指令的完成、指令的提交、结果的bypass分开<ol>
<li>如果当前指令的结果是其它指令所需要的，则仍可以给出去，即使当前指令是推测执行的</li>
<li>因为后面的指令也保证不会写入</li>
</ol>
</li>
<li>处于推测执行的指令，均可以正常执行，但不会写回，直到当前指令不再是speculative<ol>
<li>按照顺序commit</li>
<li>当branch指令commit的时候<ol>
<li>如果branch指令预测正确，则后续所有指令按序commit</li>
<li>如果branch指令预测错误，则直接舍弃后面的指令</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="9-3-3-2-结构"><a href="#9-3-3-2-结构" class="headerlink" title="9.3.3.2    结构"></a>9.3.3.2    结构</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221224214459406.png" alt="image-20221224214459406" style="zoom:80%;" /></p>
<ol>
<li>指令队列<code>Instruction queue</code>：用于一次取值取多条指令</li>
<li><code>Reorder Buffer</code>：<ol>
<li>Reorder Buffer的来源是CDB、地址单元，出口是寄存器组、内存单元</li>
<li>即原来的<code>store buffer</code>的拓展，记录哪个地址有哪个值需要写入</li>
<li>排序的依据：原来的指令顺序</li>
<li>由于要commit的指令，要么写寄存器，要么写内存，因此可以使用该模块实现顺序commit</li>
<li>原来CDB广播的数据是直接进寄存器组的，这里添加了一个Reorder Buffer，让其能够顺序commit</li>
</ol>
</li>
</ol>
<h4 id="9-3-3-3-和Tomasulo算法的区别"><a href="#9-3-3-3-和Tomasulo算法的区别" class="headerlink" title="9.3.3.3    和Tomasulo算法的区别"></a>9.3.3.3    和Tomasulo算法的区别</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227210505579.png" alt="image-20221227210505579" style="zoom: 80%;" /></p>
<ol>
<li>增加了<code>Reorder Buffer</code>，删除了<code>Store Buffer</code></li>
<li><p>寄存器的重命名是通过<code>Reorder Buffer</code>，而不是通过保留站</p>
<ol>
<li>即，通过<code>Reorder Buffer</code>暂存数据</li>
</ol>
</li>
<li><p>保留站只用来存放：已经issue，没有execution的指令的opcode、operands</p>
</li>
<li><code>Reorder Buffer</code>会保存指令的结果，并且将操作数bypass给还没有完成的指令</li>
</ol>
<h4 id="9-3-3-4-Reorder-Buffer-的每个实例包含"><a href="#9-3-3-4-Reorder-Buffer-的每个实例包含" class="headerlink" title="9.3.3.4    Reorder Buffer 的每个实例包含"></a>9.3.3.4    Reorder Buffer 的每个实例包含</h4><ol>
<li>指令的类型</li>
<li>目的寄存器</li>
<li>计算出的值</li>
<li>是否已经就绪</li>
<li>异常向量</li>
</ol>
<h4 id="9-3-3-5-投机Tomasulo算法的四个步骤"><a href="#9-3-3-5-投机Tomasulo算法的四个步骤" class="headerlink" title="9.3.3.5    投机Tomasulo算法的四个步骤"></a>9.3.3.5    投机Tomasulo算法的四个步骤</h4><ol>
<li><strong>Issue</strong>：从FP Op Queue中得到一条指令<ol>
<li>如果保留站、Reorder Buffer均有空，则发射该指令</li>
<li>将该指令存入保留站，并且在Reorder Buffer中为目的寄存器分配一个空间<ol>
<li>这一步也叫<strong>dispatch(分派)</strong></li>
</ol>
</li>
<li>更新该实例的控制单元为<code>in use</code></li>
</ol>
</li>
<li><strong>Execution</strong>：对操作数进行计算<ol>
<li>如果两个操作数均ready，则进行计算</li>
<li>否则，等待<code>CDB</code>广播两个操作数，直到两个操作数均在保留站中</li>
<li>解决<strong>RAW</strong>冲突</li>
</ol>
</li>
<li><strong>Write Result</strong>：完成计算<ol>
<li>写入<code>CDB</code>进行广播</li>
<li>写入<code>Reorder Buffer</code></li>
<li>标记保留站中对应的位置为<code>free</code></li>
</ol>
</li>
<li><strong>Commit</strong>：使用<code>Reorder</code>的结果更新寄存器<ol>
<li>当<code>Reorder Buffer</code>头部的指令已经有结果了，更新寄存器/写入内存，并将其从<code>Reorder Buffer</code>中移除</li>
<li>如果跳转指令预测错误，则清空<code>Reorder Buffer</code><ol>
<li>这一步也叫<strong>graduation(毕业)</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="9-3-3-6-commit时的操作"><a href="#9-3-3-6-commit时的操作" class="headerlink" title="9.3.3.6    commit时的操作"></a>9.3.3.6    commit时的操作</h4><p>当一条指令变为<code>Reorder Buffer</code>的头部指令，并且已经计算出结果时</p>
<ol>
<li>如果当前指令不是跳转指令<ol>
<li>更新寄存器</li>
<li>从<code>ROB</code>中删除该寄存器</li>
<li>如果是<code>store</code>指令，则更新内存</li>
</ol>
</li>
<li>如果是跳转指令，但是预测错误<ol>
<li>清空<code>ROB</code></li>
<li>流水线从branch的正确分支那里重新开始执行</li>
</ol>
</li>
<li>如果是跳转指令，并且预测正确<ol>
<li>branch的执行就结束了</li>
</ol>
</li>
</ol>
<h4 id="9-3-3-7-示例"><a href="#9-3-3-7-示例" class="headerlink" title="9.3.3.7    示例"></a>9.3.3.7    示例</h4><ol>
<li>使用<code>ROB</code>实现重命名：保留站中等待的，是<code>ROB</code>中的项，而不是之前的保留站的项</li>
<li><code>ROB</code>保证了提交的顺序与原始指令的顺序是一样的</li>
</ol>
<blockquote>
<p>  详细见视频</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227213235003.png" alt="image-20221227213235003" style="zoom:80%;" /></p>
<ol>
<li>跳转指令依旧需要进入<code>ROB</code></li>
<li>当后面的指令需要读寄存器时，要选择离它最近的<code>ROB</code>项</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227213510760.png" alt="image-20221227213510760" style="zoom:80%;" /></p>
<h4 id="9-3-3-8-新问题：memory-disambiguation"><a href="#9-3-3-8-新问题：memory-disambiguation" class="headerlink" title="9.3.3.8    新问题：memory disambiguation"></a>9.3.3.8    新问题：memory disambiguation</h4><ol>
<li><p>问题：给定一个指令序列，先store后load，它们两个访问的地址是否时相同的</p>
<ol>
<li>或者说，两条指令是否有RWA冲突</li>
<li>如下面的例子中，R2可能与R3的值相同，导致访问同一个地址</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227214115916.png" alt="image-20221227214115916" style="zoom:80%;" /></p>
</li>
<li><p>我们是否能够先执行LD指令，后执行ST指令？</p>
<ol>
<li>如果存储的是寄存器的值，可能会由于一些对于R2的操作指令，使得ST指令被delay很长时间</li>
<li>我们可能想要在同一个周期里，开始执行这两条指令(ST和LD可以通过double bump在同一个周期内完成)</li>
</ol>
</li>
<li><p>解决方法：</p>
<ol>
<li>在进行内存操作时，要保证<code>ROB</code>中所有内存操作的地址均已得到，才能进行内存操作</li>
<li><code>ROB</code>需要跟踪所有修改内存的指令，按照源码的顺序<ol>
<li>当地址已经获得的时候，记录地址、值，而不是寄存器的地址</li>
<li>保存先进先出的顺序：保证<code>load</code>和<code>store</code>的执行顺序没有被打乱<ol>
<li>如下图中，LD指令必须在ST指令之后执行</li>
</ol>
</li>
</ol>
</li>
<li>硬件支持：<ol>
<li>当我们有一个<code>load</code>的地址的时候，检查<code>store</code>队列<ol>
<li>如果在<code>load</code>之前有<code>store</code>指令的地址于其相同，则暂停<code>load</code>指令</li>
<li>如果<code>load</code>指令的地址与之前的<code>store</code>指令的地址相同时，会有一个<strong>memory-induced RAW hazard</strong><ol>
<li>如果<code>store</code>的值已经可用，则返回该值</li>
<li>如果<code>store</code>的值不可用，则将对应<code>ROB</code>的序号放入<code>load</code>指令的source中</li>
</ol>
</li>
<li>否则，执行<code>load</code>指令</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227214615277.png" alt="image-20221227214615277" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="9-3-3-9-对精确中断的硬件支持"><a href="#9-3-3-9-对精确中断的硬件支持" class="headerlink" title="9.3.3.9    对精确中断的硬件支持"></a>9.3.3.9    对精确中断的硬件支持</h4><ol>
<li>如果在某一条指令产生了中断，则将<code>ROB</code>中对应指令的<ol>
<li>后面的指令全部清空</li>
<li>前面的指令正常运行</li>
</ol>
</li>
</ol>
<h2 id="9-4-记分牌、Tomasulo、带投机的Tomasulo三种算法对比"><a href="#9-4-记分牌、Tomasulo、带投机的Tomasulo三种算法对比" class="headerlink" title="9.4    记分牌、Tomasulo、带投机的Tomasulo三种算法对比"></a>9.4    记分牌、Tomasulo、带投机的Tomasulo三种算法对比</h2><p>三者按顺序，依次解决了更多的问题</p>
<ol>
<li>记分牌：RAW问题</li>
<li>Tomasulo：WAW、WAR问题；RAW问题</li>
<li>带投机的Tomasulo：精确中断；WAW、WAR问题；RAW问题</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221227220037677.png" alt="image-20221227220037677" style="zoom:80%;" /></p>
<h1 id="Chapter-10：SuperScalar-amp-VLIW"><a href="#Chapter-10：SuperScalar-amp-VLIW" class="headerlink" title="Chapter 10：SuperScalar &amp; VLIW"></a>Chapter 10：SuperScalar &amp; VLIW</h1><h2 id="10-1-获取CPI-lt-1：Multiple-Issue-Processor-多发处理器"><a href="#10-1-获取CPI-lt-1：Multiple-Issue-Processor-多发处理器" class="headerlink" title="10.1    获取CPI&lt;1：Multiple Issue Processor 多发处理器"></a>10.1    获取CPI&lt;1：Multiple Issue Processor 多发处理器</h2><p>CPI&lt;1：单位时间内能够处理多条指令</p>
<ol>
<li><strong>Vector Processing</strong>：向量计算（把数据拼在一起、数据并行）<ol>
<li>将多个数据拼成一个向量，指令对向量进行计算</li>
<li>在RISCV中，该指令称为vector指令</li>
<li>在其它处理器中，该指令称为SIMD指令</li>
</ol>
</li>
<li><strong>Superscalar</strong>：超标量<ol>
<li>每个周期可以执行的指令数量是变化的(1~8)</li>
<li>可以由编译器或硬件调度(Tomasulo)</li>
<li>如：IBM PowerPC、Sun UltraSparc</li>
</ol>
</li>
<li><strong>Very Long Instruction Words(VLIW)</strong>：超长指令字（把指令拼在一起、指令并行）<ol>
<li>在一个指令中，放固定数量的指令</li>
<li>该指令由编译器产生，将操作放到wide templates(TBD)中</li>
<li>编译器要保证放在一起的这几条指令之间，没有依赖关系</li>
</ol>
</li>
<li>新的性能指标：<strong>Instruction Per Clock cycle，IPC</strong></li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228133757237.png" alt="image-20221228133757237" style="zoom:80%;" /></p>
<h2 id="10-2-SuperScalar"><a href="#10-2-SuperScalar" class="headerlink" title="10.2    SuperScalar"></a>10.2    SuperScalar</h2><ol>
<li>每个周期尽可能发射足够多的指令，让每个功能单元均处于busy状态<ol>
<li>静态调度：编译器优化，按序执行</li>
<li>动态调度：使用基于Tomasulo算法的技术，乱序执行</li>
</ol>
</li>
</ol>
<h3 id="10-2-1-静态调度SuperScalar"><a href="#10-2-1-静态调度SuperScalar" class="headerlink" title="10.2.1    静态调度SuperScalar"></a>10.2.1    静态调度SuperScalar</h3><ol>
<li><p>指令按序发射</p>
</li>
<li><p>在issue的时候，会检查所有流水线冲突，会在一个周期内发射<strong>0~8</strong>条指令</p>
</li>
<li><p><strong>Issue packet</strong>：fetch unit在取值的时候，会在一个周期内取多条指令，这些指令可能会在一个周期内发射</p>
<ol>
<li>如果指令存在结构冲突/数据冲突，则指令就不会issue</li>
<li>如果是N-issue，则一个周期内发射0~N条指令</li>
</ol>
</li>
<li><p>Issue阶段会被分开，并且实现流水</p>
<ol>
<li><strong>within packet</strong>：确定当前packet中会有多少指令能够同时发射</li>
<li><strong>between packet</strong>：检查选中的指令中，是否与之前的packet有冲突</li>
</ol>
</li>
<li><p>在一个周期内执行issue check，会限制clock cycle time：需要O(n^2^-n)次比较</p>
<ol>
<li>因此，将issue阶段分割，并且实现流水<ol>
<li>第一个阶段：决定由多少指令可以同时发射</li>
<li>第二个阶段：检查是否与之前的指令由冲突</li>
</ol>
</li>
<li>branch penalties会更高，因此预测准确更重要</li>
</ol>
</li>
<li><p>多发的难点：</p>
<ol>
<li><p>译码</p>
</li>
<li><p>issue：难于找到一条FP和一条整数指令，两者完全没有关系</p>
</li>
<li><p>寄存器组：需要在一个周期内完成2 <em> N个写、 1 </em> N 个读</p>
</li>
<li><p>Rename的逻辑：必须能够在一个周期内，对同一个寄存器，换名两次，举例如下</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228140028153.png" alt="image-20221228140028153" style="zoom:67%;" /></p>
</li>
<li><p>Result buses：需要在一个周期内，完成多条指令</p>
<ol>
<li>因此，需要一个<strong>multiple buses</strong>，对于每一个保留站都有一个匹配逻辑</li>
<li>或者，需要<strong>multiple forwarding paths</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<blockquote>
<p>  双发流水线：dual-issue pipeline</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228134516306.png" alt="image-20221228134516306" style="zoom:80%;" /></p>
<p>  Scalar MIPS</p>
<ol>
<li><p>一次两条指令，一条浮点，一条整数</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228135012355.png" alt="image-20221228135012355" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228135030569.png" alt="image-20221228135030569" style="zoom:80%;" /></p>
</li>
</ol>
</blockquote>
<h3 id="10-2-2-动态调度SuperScalar"><a href="#10-2-2-动态调度SuperScalar" class="headerlink" title="10.2.2    动态调度SuperScalar"></a>10.2.2    动态调度SuperScalar</h3><ol>
<li>两种不同的方法用于解决一个周期内issue多条指令：<ol>
<li><strong>pipeline</strong>：将两条指令分别在一个周期的上升沿、下降沿执行</li>
<li><strong>widen issue logic</strong>：有一个更宽的逻辑单元，同时可以处理两条指令</li>
<li>现在一般两种方法都用</li>
</ol>
</li>
</ol>
<blockquote>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228164443843.png" alt="image-20221228164443843" style="zoom:80%;" /></p>
<ol>
<li><p>双发 ≠ 双执行，只有数据都准备好了，才能执行</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228164841564.png" alt="image-20221228164841564"  /></p>
</li>
<li><p>如果有多个整数单元，则</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228165033244.png" alt="image-20221228165033244"></p>
</li>
<li><p>假设整数部分有3个单元：ALU、计算地址(ADD)、比较器(SUB)</p>
<ol>
<li><p>双发，但不使用speculation</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228165428654.png" alt="image-20221228165428654"></p>
</li>
<li><p>双发，使用speculation</p>
<p><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228165822014.png" alt="image-20221228165822014"></p>
</li>
</ol>
</li>
</ol>
</blockquote>
<h3 id="10-2-3-ILP软件方法"><a href="#10-2-3-ILP软件方法" class="headerlink" title="10.2.3    ILP软件方法"></a>10.2.3    ILP软件方法</h3><ol>
<li>循环展开</li>
<li>静态分支预测</li>
<li>静态多发：VLIW(超长指令字)</li>
<li>高级编译器支持：<ol>
<li>软件流水线：software pipeline</li>
<li>全局代码调度：global code scheduling</li>
</ol>
</li>
<li>硬件对软件的支持<ol>
<li>条件/预测指令，如ADDHI(前面的比较成功，则执行)、SUBLO(前面的比较s失败，则执行)</li>
<li>编译器投机</li>
</ol>
</li>
</ol>
<blockquote>
<p>  示例：</p>
<ol>
<li><p>C代码：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228171353327.png" alt="image-20221228171353327" style="zoom:50%;" /></p>
</li>
<li><p>翻译为MIPS</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228171429256.png" alt="image-20221228171429256" style="zoom: 67%;" /></p>
</li>
<li><p>检查hazard</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228171251264.png" alt="image-20221228171251264" style="zoom: 80%;" /></p>
</li>
<li><p>利用延迟槽减少stall</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228171559410.png" alt="image-20221228171559410" style="zoom:67%;" /></p>
</li>
<li><p>循环展开：要求循环次数必须是4的整数倍</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228171733770.png" alt="image-20221228171733770" style="zoom:67%;" /></p>
</li>
</ol>
</blockquote>
<p>从编译器角度看code movement</p>
<ol>
<li>编译器要考虑程序里面的依赖关系</li>
<li>不管流水线是否有硬件冲突</li>
<li>编译器要通过指令重排，避免冲突</li>
<li>编译器主要考虑RAW(真实依赖)，通过寄存器来判断</li>
<li>如果有RAW依赖，则不能并行</li>
<li>编译器很难判断<code>memory disambiguation</code><ol>
<li><code>100(R4)</code>与<code>20(R6)</code>是否相等?</li>
<li>在不同的循环中，<code>100(R4)</code>与<code>20(R6)</code>是否相等?</li>
</ol>
</li>
</ol>
<p>循环展开的细节</p>
<ol>
<li>通常不知道循环的具体次数</li>
<li>假设有n次，且我们会将循环中的内容展开k遍</li>
<li>通常不是简单展开，而是产生一个相邻循环的pair<ol>
<li>先执行<code>n % k</code>遍</li>
<li>然后再进行<code>n / k</code>次展开</li>
</ol>
</li>
</ol>
<h2 id="10-3-静态多发：VLIW"><a href="#10-3-静态多发：VLIW" class="headerlink" title="10.3    静态多发：VLIW"></a>10.3    静态多发：VLIW</h2><ol>
<li>VLIW：Very Long Instruction Word</li>
<li>每个超长指令字中，存储的指令的类型是固定的</li>
<li>在指令集的设计中需要进行平衡tradeoff<ol>
<li>超长指令字可以提供多条指令的空间</li>
<li>编译器放入的多条指令，相互之间是没有依赖关系的</li>
<li>例如：2个整数指令、2个FP指令、2个Memory访问、1个branch</li>
<li>需要编译技术，在多个跳转之间进行调度</li>
</ol>
</li>
<li>VLIW的问题：<ol>
<li>技术问题：<ol>
<li>代码大小增加了</li>
<li>会有unused function slots</li>
<li>任何功能单元上的stall，会引起多条指令的stall</li>
</ol>
</li>
<li>逻辑问题：<ol>
<li>二进制代码的兼容性</li>
</ol>
</li>
<li>多发处理器的主要挑战：<ol>
<li>如何实现更大的ILP</li>
</ol>
</li>
</ol>
</li>
</ol>
<blockquote>
<p>  VLIW的循环展开示例：</p>
<p>  <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228173334604.png" alt="image-20221228173334604" style="zoom:80%;" /></p>
</blockquote>
<h1 id="Chapter-11：Multithreading"><a href="#Chapter-11：Multithreading" class="headerlink" title="Chapter 11：Multithreading"></a>Chapter 11：Multithreading</h1><h2 id="11-1-多线程软件"><a href="#11-1-多线程软件" class="headerlink" title="11.1    多线程软件"></a>11.1    多线程软件</h2><h3 id="11-1-1-进程-amp-线程"><a href="#11-1-1-进程-amp-线程" class="headerlink" title="11.1.1    进程&amp;线程"></a>11.1.1    进程&amp;线程</h3><ol>
<li>进程<ol>
<li>每个进程有独特的地址空间<strong>unique address space</strong></li>
<li>可以有多个线程</li>
</ol>
</li>
<li>线程：每个线程有它独特的执行上下文<strong>unique execution context</strong><ol>
<li>独立的<strong>PC、registers、stack</strong></li>
<li>一个进程的所有线程，共享相同的地址空间</li>
<li>可以有私有的堆空间，但一般情况下，一个进程的所有线程共用一个堆</li>
</ol>
</li>
</ol>
<h3 id="11-1-2-多线程应用：进程被划分成了线程"><a href="#11-1-2-多线程应用：进程被划分成了线程" class="headerlink" title="11.1.2    多线程应用：进程被划分成了线程"></a>11.1.2    多线程应用：进程被划分成了线程</h3><ol>
<li>增加并发度concurrency/并行度<ol>
<li>并发<strong>concurrent</strong>：外面来了一件事，但手头的事不能停下，因此会<strong>被动</strong>的同时做两件事</li>
<li>并行<strong>parallel</strong>：<strong>主动</strong>将任务分为两部分，同时进行</li>
</ol>
</li>
<li>部分阻塞</li>
<li>集中资源管理</li>
</ol>
<h3 id="11-1-3-如何保证流水线之间的指令没有依赖关系"><a href="#11-1-3-如何保证流水线之间的指令没有依赖关系" class="headerlink" title="11.1.3    如何保证流水线之间的指令没有依赖关系"></a>11.1.3    如何保证流水线之间的指令没有依赖关系</h3><ol>
<li>交替执行不同线程的指令</li>
<li>寄存器组是分bank的，每个线程使用不同的bank</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228200901905.png" alt="image-20221228200901905" style="zoom:80%;" /></p>
<h3 id="11-1-4-多线程体系结构"><a href="#11-1-4-多线程体系结构" class="headerlink" title="11.1.4    多线程体系结构"></a>11.1.4    多线程体系结构</h3><ol>
<li>如果处理器可以执行多个软件线程，则<ol>
<li>可以同时执行：线程可以由硬件切换(交替执行interleaved)，而不是由OS控制</li>
</ol>
</li>
<li>共享资源<ol>
<li>更好的资源利用率、更好的吞吐量</li>
</ol>
</li>
<li>可以是同一个进程，也可以不是<ol>
<li>如果不是，问题主要是页表的切换</li>
<li>页表可能会有多份</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228201817048.png" alt="image-20221228201817048" style="zoom:80%;" /></p>
<h3 id="11-1-5-多线程的开销"><a href="#11-1-5-多线程的开销" class="headerlink" title="11.1.5    多线程的开销"></a>11.1.5    多线程的开销</h3><ol>
<li>对于每个软件来说，CPU更慢了</li>
<li>每个线程需要有各自独立的user state：GPRs、PC</li>
<li>也需要独立的OS控制状态：虚拟内存页表、异常处理寄存器</li>
</ol>
<h3 id="11-1-6-线程调度策略"><a href="#11-1-6-线程调度策略" class="headerlink" title="11.1.6    线程调度策略"></a>11.1.6    线程调度策略</h3><ol>
<li>Fixed interleave（CDC 6600 PPUs，1965）<ol>
<li>每N个周期，每N个线程各自执行一条指令</li>
<li>如果线程没有ready，就stall</li>
</ol>
</li>
<li>Software-controlled interleave（TI ASC PPUs，1971）<ol>
<li>OS在N个线程之间，分配S个流水线槽位</li>
<li>硬件在S个流水线槽位之间，做固定的interleave</li>
</ol>
</li>
<li>Hardware-controlled thread scheduling（HEP，1982）<ol>
<li>硬件跟踪哪个线程ready to go</li>
<li>根据硬件优先的模式，选择下一个要执行的线程</li>
</ol>
</li>
</ol>
<blockquote>
<p>  Denelcor HEP是一个<code>uniform shared memory multiprocessor</code></p>
<ol>
<li>有多个处理器，共享一个内存<code>uniform shared memory</code></li>
<li>是一个细粒度(fine-grain)的多线程</li>
<li>可以忍受内存的延迟、同步的延迟、功能单元的延迟</li>
<li>每个处理器有120个线程，时钟周期频率为10MHz</li>
</ol>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228205019642.png" alt="image-20221228205019642" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228205100162.png" alt="image-20221228205100162" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228205956744.png" alt="image-20221228205956744" style="zoom:80%;" /></p>
<h3 id="11-1-7-Coarse-Grain-Multithreading-粗粒度多线程"><a href="#11-1-7-Coarse-Grain-Multithreading-粗粒度多线程" class="headerlink" title="11.1.7    Coarse-Grain Multithreading 粗粒度多线程"></a>11.1.7    Coarse-Grain Multithreading 粗粒度多线程</h3><ol>
<li>Tera MTA为超算应用设计<ol>
<li>数据特点：数据集很大，局部性较低</li>
<li>没有data cache</li>
<li>有很多并行的线程，去隐藏一个large memory latency</li>
</ol>
</li>
<li>其它应用会更加cache friendly<ol>
<li>当cache hit时，会有更少的流水线bubble</li>
<li>只增加一部分线程，去隐藏偶尔的cache miss latencies</li>
<li>当cache miss的时候，交换线程</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228211102172.png" alt="image-20221228211102172" style="zoom:80%;" /></p>
<h2 id="11-2-多线程设计"><a href="#11-2-多线程设计" class="headerlink" title="11.2    多线程设计"></a>11.2    多线程设计</h2><ol>
<li>细粒度多线程<code>Fine-grained multithreading</code><ol>
<li>每一个时钟周期，都在不同线程间切换</li>
<li>多个线程的指令执行，是交织(interleave)在一起的</li>
<li>interleave是以轮询的方式进行的：CPU认为指令序列就是交替好的</li>
<li>一旦发生停顿，所有线程均中断</li>
</ol>
</li>
<li>粗粒度多线程<code>Coarse-grained multithreading</code><ol>
<li>一直跑单个线程，只有在成本比较高的停顿发生时，才会进行线程切换</li>
<li>如：二级/三级cache miss、功能单元的数据冲突</li>
<li>会有线程切换的开销</li>
<li>在解决停顿时间较长的情况时，比较划算</li>
</ol>
</li>
<li>设计时需要考虑<ol>
<li>上下文切换的开销</li>
<li>需要支持多少线程</li>
<li>期望的应用级并行度</li>
</ol>
</li>
</ol>
<h3 id="11-2-1-Superscalar-Machine-Efficiency"><a href="#11-2-1-Superscalar-Machine-Efficiency" class="headerlink" title="11.2.1    Superscalar Machine Efficiency"></a>11.2.1    Superscalar Machine Efficiency</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228212635659.png" alt="image-20221228212635659" style="zoom:80%;" /></p>
<ol>
<li>垂直waste：通常是cache miss</li>
</ol>
<h3 id="11-2-2-垂直多线程"><a href="#11-2-2-垂直多线程" class="headerlink" title="11.2.2    垂直多线程"></a>11.2.2    垂直多线程</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228212716432.png" alt="image-20221228212716432" style="zoom:80%;" /></p>
<ol>
<li>消除了垂直waste，但是会没有解决水平waste</li>
</ol>
<h3 id="11-2-3-芯片多线程"><a href="#11-2-3-芯片多线程" class="headerlink" title="11.2.3    芯片多线程"></a>11.2.3    芯片多线程</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228212851825.png" alt="image-20221228212851825" style="zoom:80%;" /></p>
<ol>
<li>消除了水平waste，但是还有一部分垂直waste</li>
</ol>
<h3 id="11-2-4-同时多线程-Out-of-Order-Simultaneous-Multithreading"><a href="#11-2-4-同时多线程-Out-of-Order-Simultaneous-Multithreading" class="headerlink" title="11.2.4    同时多线程 Out-of-Order Simultaneous Multithreading"></a>11.2.4    同时多线程 Out-of-Order Simultaneous Multithreading</h3><ol>
<li><p>在细粒度的基础上进行改良</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228213316756.png" alt="image-20221228213316756" style="zoom:80%;" /></p>
</li>
<li><p>基础Out-of-order流水线</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228214452860.png" alt="image-20221228214452860" style="zoom:80%;" /></p>
</li>
<li><p>SMT流水线</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228214505388.png" alt="image-20221228214505388" style="zoom:80%;" /></p>
</li>
<li><p>SMT的设计挑战</p>
<ol>
<li>要在细粒度实现的表现与单线程的表现之间进行权衡<ol>
<li>首选线程：可能会牺牲吞吐量</li>
<li>不太可能混合来自多个线程的指令</li>
<li>最大限度地提高单线程性能，应尽可能提前提取，并在分支预测失误或预取缓冲区中发生未命中时释放提取单元</li>
</ol>
</li>
<li>一个较大的寄存器文件，用于保存多个上下文</li>
<li>不影响时钟周期，例如在指令发出时，在指令完成时</li>
<li>确保cache和TLB冲突不会导致性能下降</li>
</ol>
</li>
</ol>
<h3 id="11-2-5-投机、乱序、超标量的处理器"><a href="#11-2-5-投机、乱序、超标量的处理器" class="headerlink" title="11.2.5    投机、乱序、超标量的处理器"></a>11.2.5    投机、乱序、超标量的处理器</h3><p> <img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228215205370.png" alt="image-20221228215205370" style="zoom:80%;" /></p>
<h3 id="11-2-6-芯片多线程"><a href="#11-2-6-芯片多线程" class="headerlink" title="11.2.6    芯片多线程"></a>11.2.6    芯片多线程</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221228215601834.png" alt="image-20221228215601834" style="zoom:80%;" /></p>
<h1 id="Chapter-12：DLP—Vector-amp-SIMD-amp-GPU"><a href="#Chapter-12：DLP—Vector-amp-SIMD-amp-GPU" class="headerlink" title="Chapter 12：DLP—Vector &amp; SIMD &amp; GPU"></a>Chapter 12：DLP—Vector &amp; SIMD &amp; GPU</h1><p>数据级并行</p>
<ol>
<li>Vector Processor</li>
<li>GPU</li>
</ol>
<p>线程级并行</p>
<ol>
<li>SMP/DSM</li>
<li>Cache coherence</li>
<li>Synchronization</li>
</ol>
<h2 id="12-1-程序执行四种模式"><a href="#12-1-程序执行四种模式" class="headerlink" title="12.1    程序执行四种模式"></a>12.1    程序执行四种模式</h2><ol>
<li><p>SISD：单一指令、单一数据</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229123911394.png" alt="image-20221229123911394" style="zoom:80%;" /></p>
</li>
<li><p>SIMD：单一指令、多个数据</p>
<ol>
<li>SIMD必须在最小段里面执行，因为要保证指令是单一的</li>
<li>如果跳转的话，指令就不一样了</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229123901541.png" alt="image-20221229123901541" style="zoom:80%;" /></p>
</li>
<li><p>MIMD：多条指令、多个数据</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229123853310.png" alt="image-20221229123853310" style="zoom:80%;" /></p>
</li>
<li><p>MISD：多条指令、单一数据</p>
<ol>
<li>比较罕见</li>
</ol>
</li>
</ol>
<h2 id="12-2-SIMD"><a href="#12-2-SIMD" class="headerlink" title="12.2    SIMD"></a>12.2    SIMD</h2><ol>
<li>SIMD体系结构可以利用显著的数据级并行性：<ol>
<li>面向矩阵的科学计算</li>
<li>面向媒体的图像和声音处理器</li>
</ol>
</li>
<li>SIMD比MIMD更节能<ol>
<li>每个数据操作只需要获取一条指令</li>
<li>使SIMD对个人移动设备具有吸引力</li>
</ol>
</li>
<li>SIMD允许程序员继续按串行的思路思考</li>
</ol>
<h2 id="12-3-Vector-Processing-向量计算"><a href="#12-3-Vector-Processing-向量计算" class="headerlink" title="12.3    Vector Processing 向量计算"></a>12.3    Vector Processing 向量计算</h2><ol>
<li>在处理单元的个数不变的时候，相当于做了一次循环展开，节省了branch的开销</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229124703373.png" alt="image-20221229124703373" style="zoom: 67%;" /></p>
<h3 id="12-3-1-向量计算的特点"><a href="#12-3-1-向量计算的特点" class="headerlink" title="12.3.1    向量计算的特点"></a>12.3.1    向量计算的特点</h3><ol>
<li>单矢量指令意味着大量的重复工作（循环）<ol>
<li>可以减少IF的次数</li>
</ol>
</li>
<li>每个结果独立于以前的结果<ol>
<li>长管道，编译器确保无依赖性</li>
<li>提高时钟频率，因为基本上都是整数运算，可以很快完成</li>
<li>硬件不必检查数据危害</li>
</ol>
</li>
<li>访问存储器的向量指令具有已知的访问模式<ol>
<li>内存是高度交错的</li>
<li>内存的读取延迟会被分摊(amortize)到超过64个元素</li>
<li>不需要（数据）缓存</li>
</ol>
</li>
<li>减少管道中的分支和分支问题<ol>
<li>通常由回路分支引起的控制危险是不存在的</li>
</ol>
</li>
</ol>
<h3 id="12-3-2-Vector架构的类型"><a href="#12-3-2-Vector架构的类型" class="headerlink" title="12.3.2    Vector架构的类型"></a>12.3.2    Vector架构的类型</h3><ol>
<li><strong>memory-memory vector processors</strong>：<ol>
<li>所有的向量操作，都在<strong>内存</strong>之间进行，向量存储在内存中</li>
<li>可以给出两个内存地址作为source，一个内存地址作为target</li>
</ol>
</li>
<li><strong>vector-register processors</strong>：<ol>
<li>所有的向量操作，都在<strong>vector寄存器</strong>之间进行(处理load和store)</li>
<li>vector等价于load-store架构</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229180515728.png" alt="image-20221229180515728" style="zoom:80%;" /></p>
<h4 id="12-3-2-1-vector-register-architecture"><a href="#12-3-2-1-vector-register-architecture" class="headerlink" title="12.3.2.1    vector-register architecture"></a>12.3.2.1    vector-register architecture</h4><ol>
<li>基础想法<ol>
<li>把一组数据读到<code>vector register</code>中</li>
<li>在寄存器上进行操作</li>
<li>将结果写回memory</li>
</ol>
</li>
<li>寄存器由编译器控制<ol>
<li>用于隐藏memory latency</li>
<li>影响内存的带宽</li>
</ol>
</li>
</ol>
<h4 id="12-3-2-2-Vector-Memory-Memory-Achitecture"><a href="#12-3-2-2-Vector-Memory-Memory-Achitecture" class="headerlink" title="12.3.2.2    Vector Memory-Memory Achitecture"></a>12.3.2.2    Vector Memory-Memory Achitecture</h4><ol>
<li>矢量内存结构（VMMA）需要更大的主内存带宽，为什么？<ol>
<li>所有操作数都必须从内存中读取</li>
</ol>
</li>
<li>VMMA使多个向量操作的执行难以重叠，为什么？<ol>
<li>必须检查对内存地址的依赖关系</li>
</ol>
</li>
<li>VMMA导致更大的启动延迟<ol>
<li>在CDC Star-100上，当矢量&lt;100个元素时，标量代码更快</li>
<li>对于Cray-1，向量/标量盈亏平衡点约为2个元素</li>
</ol>
</li>
</ol>
<h4 id="12-3-2-3-Vector-Processor的组件"><a href="#12-3-2-3-Vector-Processor的组件" class="headerlink" title="12.3.2.3    Vector Processor的组件"></a>12.3.2.3    Vector Processor的组件</h4><ol>
<li>Vector Register：向量寄存器，固定长度的bank，存储一个vector<ol>
<li>至少2个读端口，1个写端口</li>
<li>通常有8~32个向量寄存器，每个存入64-128个64bit单元</li>
</ol>
</li>
<li>Vector Functional Units(FUs)：向量功能单元，完全流水，每个周期启动一个新的计算<ol>
<li>通常有4~8个FUs：FP add，FP mult，FP reciprocal，integer add，logical，shift</li>
<li>同一种功能单元可能有多个</li>
</ol>
</li>
<li>Vector Load-Store Units(LSUs)<ol>
<li>完全流水</li>
<li>每个周期可以读/写多个元素</li>
<li>可能有多个LSUs</li>
</ol>
</li>
<li>Scalar register：标量寄存器，用于浮点标量/地址计算</li>
<li>Cross-bar：矩阵，将所有部件连起来</li>
</ol>
<h4 id="12-3-2-4-基础向量指令"><a href="#12-3-2-4-基础向量指令" class="headerlink" title="12.3.2.4    基础向量指令"></a>12.3.2.4    基础向量指令</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229182638897.png" alt="image-20221229182638897" style="zoom:80%;" /></p>
<h4 id="12-3-2-5-向量指令的执行时间"><a href="#12-3-2-5-向量指令的执行时间" class="headerlink" title="12.3.2.5    向量指令的执行时间"></a>12.3.2.5    向量指令的执行时间</h4><ol>
<li>执行事件取决于三个因素<ol>
<li>向量的长度</li>
<li>是否有结构冲突</li>
<li>数据依赖</li>
</ol>
</li>
<li>RV64V功能单元每个时钟周期消耗一个element<ol>
<li>流水计算，而不是并行计算</li>
<li>执行时间大约为vector的长度</li>
</ol>
</li>
<li>Convey<ol>
<li>有可能可以同时执行的向量指令的集合</li>
</ol>
</li>
</ol>
<h4 id="12-3-2-6-Chimes-节拍"><a href="#12-3-2-6-Chimes-节拍" class="headerlink" title="12.3.2.6    Chimes 节拍"></a>12.3.2.6    Chimes 节拍</h4><ol>
<li><p>在同一个convey中的指令可能有RAW依赖</p>
</li>
<li><p>Chaining</p>
<ol>
<li>一旦向量操作的源向量均已可用，允许该向量操作尽早执行</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229183506548.png" alt="image-20221229183506548" style="zoom: 80%;" /></p>
</li>
<li><p>Chime</p>
<ol>
<li>执行一次传送的时间单元</li>
<li>m个convey在m个chimes中执行，向量长度为n</li>
<li>对于长度为n的向量，需要m*n个时钟周期</li>
</ol>
</li>
</ol>
<h4 id="12-3-2-7-Vector内存操作"><a href="#12-3-2-7-Vector内存操作" class="headerlink" title="12.3.2.7    Vector内存操作"></a>12.3.2.7    Vector内存操作</h4><ol>
<li>load/store操作在寄存器和内存之间移动数据</li>
<li>三种类型的寻址<ol>
<li>Unit stride：单位步幅<ol>
<li>给出每个单元的大小，然后一个单元一个单元的读取</li>
<li>最快的</li>
</ol>
</li>
<li>Non-unit(constant) stride：非单位（恒定）步幅</li>
<li>Indexed(gather-scatter)：索引（聚集-分散）<ol>
<li>寄存器间接的矢量等效</li>
<li>适用于稀疏数据阵列</li>
<li>增加矢量化程序的数量</li>
<li>压缩/扩展变量</li>
</ol>
</li>
</ol>
</li>
<li>支持内存中各种数据宽度的组合<ol>
<li>｛.L、.W、.H、.B｝x｛64b、32b、16b、8b｝</li>
</ol>
</li>
</ol>
<blockquote>
<p>  Vector 内存系统</p>
</blockquote>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229184004888.png" alt="image-20221229184004888" style="zoom:80%;" /></p>
<h4 id="12-3-2-8-DAXPY"><a href="#12-3-2-8-DAXPY" class="headerlink" title="12.3.2.8    DAXPY"></a>12.3.2.8    DAXPY</h4><ol>
<li>设X、Y为向量，a为标量，则DAXPY表示的操作为：Y = a * X + Y</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229184056542.png" alt="image-20221229184056542" style="zoom:80%;" /></p>
<h4 id="12-3-2-9-向量长度"><a href="#12-3-2-9-向量长度" class="headerlink" title="12.3.2.9    向量长度"></a>12.3.2.9    向量长度</h4><ol>
<li>一个向量的具体长度是不确定的，但是有一个最大长度(<strong>MVL，maximum vector length</strong>)</li>
<li><strong>vector-length register(VL)</strong>：控制任何矢量操作的长度，包括矢量加载或存储<ol>
<li>例如：VL=10时，vadd.vv为</li>
<li>for(I=0；I&lt;10；I++) V1[I]=V2[I]+V3[I]</li>
</ol>
</li>
<li>VL可以是从0到MVL的任何值</li>
</ol>
<h4 id="12-3-2-10-Strip-Mining"><a href="#12-3-2-10-Strip-Mining" class="headerlink" title="12.3.2.10    Strip Mining"></a>12.3.2.10    Strip Mining</h4><ol>
<li>当向量长度 &gt; MVL时，需要进行<strong>Strip Mining</strong><ol>
<li>生成一个循环计算，每个循环计算的向量长度为MVL</li>
<li>循环结束后，计算不足MVL的部分</li>
</ol>
</li>
</ol>
<h3 id="12-3-3-向量操作的优化"><a href="#12-3-3-向量操作的优化" class="headerlink" title="12.3.3    向量操作的优化"></a>12.3.3    向量操作的优化</h3><h4 id="12-3-3-1-Vector-Chaining"><a href="#12-3-3-1-Vector-Chaining" class="headerlink" title="12.3.3.1    Vector Chaining"></a>12.3.3.1    Vector Chaining</h4><ol>
<li>是forward在向量上的延展</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229184918604.png" alt="image-20221229184918604" style="zoom:80%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229184936670.png" alt="image-20221229184936670" style="zoom:80%;" /></p>
<h4 id="12-3-3-2-条件执行"><a href="#12-3-3-2-条件执行" class="headerlink" title="12.3.3.2    条件执行"></a>12.3.3.2    条件执行</h4><ol>
<li><p>假设源码如下：</p>
<ol>
<li>由于对每个单元的操作不一样，因此需要条件执行</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229185049389.png" alt="image-20221229185049389" style="zoom:80%;" /></p>
</li>
<li><p>解决方法：条件执行</p>
<ol>
<li>为向量的每个单元添加一个1-bit <strong>vector flag register</strong></li>
<li>使用<strong>vector compare</strong>，设置flag register</li>
<li>将flag register作为<strong>mask</strong>，控制向量减法</li>
</ol>
</li>
<li><p>示例：</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229185255149.png" alt="image-20221229185255149" style="zoom:80%;" /></p>
</li>
</ol>
<h4 id="12-3-3-3-压缩-扩展操作"><a href="#12-3-3-3-压缩-扩展操作" class="headerlink" title="12.3.3.3    压缩/扩展操作"></a>12.3.3.3    压缩/扩展操作</h4><ol>
<li>如果向量比较稀疏，可以通过mask做压缩</li>
<li>然后可以将另一次向量操作，填进当前操作的空余部分</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229185626244.png" alt="image-20221229185626244" style="zoom:80%;" /></p>
<h3 id="12-3-4-Vector的优点"><a href="#12-3-4-Vector的优点" class="headerlink" title="12.3.4    Vector的优点"></a>12.3.4    Vector的优点</h3><ol>
<li>易于获得高性能；N次操作：<ol>
<li>没有依赖关系</li>
<li>使用相同的功能单元</li>
<li>存取不相交寄存器</li>
<li>按照与前面指令相同的顺序访问寄存器</li>
<li>访问连续存储器字或已知模式</li>
<li>可以利用大内存带宽</li>
<li>隐藏内存延迟（以及任何其他延迟）</li>
</ol>
</li>
<li>可扩展：通过添加硬件资源获得更高的性能</li>
<li>紧凑型：用一条简短的指令描述N个操作</li>
<li>可预测：性能与统计性能（缓存）</li>
<li>多媒体就绪：N <em> 64b、2N </em> 32b、4N <em> 16b、8N </em> 8b</li>
<li>需要成熟的编译器技术</li>
</ol>
<h2 id="12-4-SIMD"><a href="#12-4-SIMD" class="headerlink" title="12.4    SIMD"></a>12.4    SIMD</h2><ol>
<li>多媒体应用需要的时比正常word更窄的数据类型<ol>
<li>如RGBA在做运算时，每个通道要分开计算，即一个计算单元为8-bit</li>
</ol>
</li>
<li>SIMD与向量计算相比，限制在于：<ol>
<li>数据的个数被编码进了op code中</li>
<li>无复杂的寻址模式（stride、scatter-gather）</li>
<li>无mask register</li>
</ol>
</li>
</ol>
<h3 id="12-4-1-SIMD实现"><a href="#12-4-1-SIMD实现" class="headerlink" title="12.4.1    SIMD实现"></a>12.4.1    SIMD实现</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229211750960.png" alt="image-20221229211750960" style="zoom:80%;" /></p>
<h3 id="12-4-2-SIMD代码示例"><a href="#12-4-2-SIMD代码示例" class="headerlink" title="12.4.2    SIMD代码示例"></a>12.4.2    SIMD代码示例</h3><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221229211810511.png" alt="image-20221229211810511" style="zoom:80%;" /></p>
<h2 id="12-5-GPU：Graphical-Processing-Units"><a href="#12-5-GPU：Graphical-Processing-Units" class="headerlink" title="12.5    GPU：Graphical Processing Units"></a>12.5    GPU：Graphical Processing Units</h2><ol>
<li>基础思路：<ol>
<li>异构的计算模型：Heterogeneous execution model<ol>
<li>CPU是主机，GPU是设备</li>
</ol>
</li>
<li>为GPU开发一种类似C语言的编程代码</li>
<li>编程模型为<strong>SIMT：Single Instruction Multiple Thread</strong></li>
</ol>
</li>
<li>GPU单个指令的计算能力不强，但是并行度非常高，路数很多</li>
<li>GPU是一个典型的SIMD</li>
</ol>
<h3 id="12-5-1-Threads-and-Blocks"><a href="#12-5-1-Threads-and-Blocks" class="headerlink" title="12.5.1    Threads and Blocks"></a>12.5.1    Threads and Blocks</h3><ol>
<li>一个thread与一个data element关联</li>
<li>thread组成block，block组成grid</li>
<li>GPU硬件进行thread的管理</li>
</ol>
<h3 id="12-5-2-NVIDIA-GPU-架构"><a href="#12-5-2-NVIDIA-GPU-架构" class="headerlink" title="12.5.2    NVIDIA GPU 架构"></a>12.5.2    NVIDIA GPU 架构</h3><ol>
<li>与vector machines类似：<ol>
<li>数据级并行</li>
<li>可以进行scatter-gather传输</li>
<li>有mask registers</li>
<li>有更大的寄存器组</li>
</ol>
</li>
<li>区别：<ol>
<li>没有标量的处理</li>
<li>使用多线程去隐藏memory latency</li>
<li>有很多的功能单元，不再流水，而是完全的并行<ol>
<li>4096个线程就是4096个加法器、4096个乘法器…</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="Chapter-13：Multiprocessors"><a href="#Chapter-13：Multiprocessors" class="headerlink" title="Chapter 13：Multiprocessors"></a>Chapter 13：Multiprocessors</h1><h2 id="13-1-为什么要使用多处理器"><a href="#13-1-为什么要使用多处理器" class="headerlink" title="13.1    为什么要使用多处理器"></a>13.1    为什么要使用多处理器</h2><ol>
<li>应用的需求<ol>
<li>单一处理器性能的提升，可以解决latency的问题，但不能解决单位时间内获取更多的产出的问题</li>
</ol>
</li>
<li>微处理器已经是最快的CPU了</li>
<li>摩尔定律的失效</li>
<li>能够使用并行的软件逐渐增多</li>
</ol>
<h3 id="13-1-1-多处理器的目标"><a href="#13-1-1-多处理器的目标" class="headerlink" title="13.1.1    多处理器的目标"></a>13.1.1    多处理器的目标</h3><ol>
<li>性能：<ol>
<li>突破单一处理器的限制</li>
<li>如ILP(branch预测，RAW冲突、内存)</li>
</ol>
</li>
<li>更低的成本：<ol>
<li>使用廉价的部分，构建一个大的系统</li>
</ol>
</li>
<li>可扩展性scalability：<ol>
<li>只要多加处理器，就能获得更好的性能</li>
</ol>
</li>
<li>错误容忍：<ol>
<li>如果有少量处理器失效，仍能继续进行运算</li>
</ol>
</li>
</ol>
<h3 id="13-1-2-并行计算机"><a href="#13-1-2-并行计算机" class="headerlink" title="13.1.2    并行计算机"></a>13.1.2    并行计算机</h3><ol>
<li>定义：并行计算机是一组处理单元，相互协作、通信处理大的问题</li>
<li>相关参数：<ol>
<li>多少个计算机</li>
<li>每一个计算单元有多强大</li>
<li>如何进行协作、通信</li>
<li>数据是怎么发送的</li>
<li>通信的类型是什么</li>
<li>对程序员来说，硬件和软件的基本单元是什么</li>
<li>如何形成性能的</li>
</ol>
</li>
</ol>
<h3 id="13-1-3-Catalogue-the-Parallel-MIMD-Processors"><a href="#13-1-3-Catalogue-the-Parallel-MIMD-Processors" class="headerlink" title="13.1.3    Catalogue the Parallel(MIMD) Processors"></a>13.1.3    Catalogue the Parallel(MIMD) Processors</h3><ol>
<li>main memory的组成方式<ol>
<li>Shared：所有核共享一个内存<strong>UMA</strong></li>
<li>Distributed：每个核都有一个内存<strong>NUMA</strong></li>
</ol>
</li>
<li>对硬件来说，memory的性能<ol>
<li>如memory access latency的表现？<ol>
<li>Shared：每个核访问的不同内存的时间是一致的</li>
<li>Distributed：每个核访问不同内存的时间是不同的</li>
</ol>
</li>
</ol>
</li>
<li>对软件来说，memory的性能<ol>
<li>处理器是否能够直接通过内存通信<ol>
<li>Shared(shared memory)：可以直接通过load/store进行通信</li>
<li>Distributed(message passing)：通过message进行通信</li>
</ol>
</li>
</ol>
</li>
<li>是否正交<ol>
<li><strong>DSM</strong>：物理上是分布的，逻辑上是共享的</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230143600300.png" alt="image-20221230143600300" style="zoom:80%;" /></p>
<h4 id="13-1-3-1-UMA"><a href="#13-1-3-1-UMA" class="headerlink" title="13.1.3.1    UMA"></a>13.1.3.1    UMA</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230143953225.png" alt="image-20221230143953225" style="zoom:67%;" /></p>
<ol>
<li>理想模型：<ol>
<li>优秀(single-cycle)的内存访问延迟</li>
<li>优秀(infinite)的内存访问带宽</li>
</ol>
</li>
<li>实际系统<ol>
<li>当处理器个数上升时，latency会变长</li>
<li>bandwidth是有限的</li>
<li>添加memory banks，latency也会变大</li>
</ol>
</li>
<li>也就是说，UMA做不大</li>
</ol>
<h4 id="13-1-3-2-UMA-vs-NUMA"><a href="#13-1-3-2-UMA-vs-NUMA" class="headerlink" title="13.1.3.2    UMA vs NUMA"></a>13.1.3.2    UMA vs NUMA</h4><p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230144111509.png" alt="image-20221230144111509" style="zoom:80%;" /></p>
<ol>
<li><strong>UMA：uniform memory access</strong><ol>
<li>p0访问m0~m3的延迟都是一样的</li>
<li>当系统变大时，延迟会增加</li>
<li>data放在哪一块是不重要的</li>
</ol>
</li>
<li><strong>NUMA：non-uniform memory access</strong><ol>
<li>p0访问m0会更快，m1~m3会更慢</li>
<li>p0发送请求给m0，如果m0发现数据不在当前内存，则向Interconnect发消息，获取其它内存单元的数据</li>
<li>data放在哪里很重要</li>
</ol>
</li>
</ol>
<h3 id="13-1-4-主要的MIMD类型"><a href="#13-1-4-主要的MIMD类型" class="headerlink" title="13.1.4    主要的MIMD类型"></a>13.1.4    主要的MIMD类型</h3><ol>
<li>中心化的共享内存</li>
<li>去中心化的内存：内存单元跟随CPU<ol>
<li>内存带宽变大，但是会有更高的通信延迟</li>
<li>软件模型更复杂</li>
</ol>
</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230144659638.png" alt="image-20221230144659638" style="zoom: 67%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230144739997.png" alt="image-20221230144739997" style="zoom:67%;" /></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230144820146.png" alt="image-20221230144820146" style="zoom: 67%;" /></p>
<h3 id="13-1-5-并行架构"><a href="#13-1-5-并行架构" class="headerlink" title="13.1.5    并行架构"></a>13.1.5    并行架构</h3><ol>
<li>并行架构拓展了传统的计算机架构，主要通过通信<ol>
<li>抽象：在硬件和软件上有不同的接口</li>
</ol>
</li>
<li>并行的编程模型<ol>
<li>multiprogramming：有很多任务，不考虑通信问题</li>
<li>shared address space：通过内存进行通信</li>
<li>message passing：发送/接收消息</li>
<li>data parallel：由代理(agents)同时操作数据集，然后全局地同时交换信息</li>
</ol>
</li>
<li>通信的抽象：<ol>
<li>共享地址空间：load、store、原子的swap</li>
<li>信号传递：send、receive调用库函数</li>
</ol>
</li>
</ol>
<h4 id="13-1-5-1-Shared-Address-Model"><a href="#13-1-5-1-Shared-Address-Model" class="headerlink" title="13.1.5.1    Shared Address Model"></a>13.1.5.1    Shared Address Model</h4><ol>
<li>每个处理器都可以访问机器上的任何一个物理地址</li>
<li>每个进程都可以访问和别的进程共享的数据</li>
<li>数据的传输：load、store</li>
<li>数据的大小：byte、word、cache blocks</li>
<li>使用虚拟内存，将虚拟空间映射到本地/远程物理空间</li>
<li>应用memory层级模型<ol>
<li>通信会将数据移动到本地的cache</li>
</ol>
</li>
<li>对于分布式内存架构，需要一个layer(硬件/软件)，做透明的地址映射</li>
<li>重点是：数据的一致性、数据保护</li>
<li>对于多机系统来说，地址的映射是由软件完成的，通常是OS的一部分 </li>
<li>scalability是有限的，因为通信方式与处理器的地址空间紧密的联系在一起</li>
</ol>
<h4 id="13-1-5-2-Message-Passing-Model"><a href="#13-1-5-2-Message-Passing-Model" class="headerlink" title="13.1.5.2    Message Passing Model"></a>13.1.5.2    Message Passing Model</h4><ol>
<li>整个计算机（CPU、内存、I/O设备）作为<strong>显式I/O操作</strong>进行通信<ol>
<li>本质上是NUMA，但集成在I/O设备与内存系统之间</li>
</ol>
</li>
<li>发送指定远程计算机上的本地缓冲区+接收进程</li>
<li>接收指定远程计算机上的发送进程+放置数据的本地缓冲区<ol>
<li>通常发送的信息包含process tag</li>
<li>接收在tag上有规则：match 1，match any</li>
<li>同步：当发送完成时，当缓冲区空闲时，当请求被接受时，接收等待发送</li>
</ol>
</li>
<li>发送+接收=&gt;memory-memory copy<ol>
<li>其中每个副本提供本地地址，并且执行成对同步</li>
</ol>
</li>
</ol>
<h2 id="13-2-Cache-coherence-一致性问题"><a href="#13-2-Cache-coherence-一致性问题" class="headerlink" title="13.2    Cache coherence 一致性问题"></a>13.2    Cache coherence 一致性问题</h2><p>SMP的特性：</p>
<ol>
<li>有限的处理器数量</li>
<li>足够大的cache：提供更大的memory bandwidth</li>
<li>UMA：uniform memory access time</li>
</ol>
<p><strong>Cache coherence</strong></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230151715739.png" alt="image-20221230151715739" style="zoom:80%;" /></p>
<p><strong>Synchronization</strong>：</p>
<ol>
<li>原子的读/写操作</li>
</ol>
<p>内存一致性模型：</p>
<ol>
<li>处理器必须以什么样的顺序观察别的处理器写的数据</li>
<li>读和写之间的关系是什么样的</li>
</ol>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230152443104.png" alt="image-20221230152443104" style="zoom:80%;" /></p>
<p>coherency的意义：</p>
<ol>
<li>严格定义：所有的read必须返回最新的write数据</li>
<li>更优的定义：所有的write必须最终被read看到，所有的write以一种正确的顺序被看到(串行)</li>
<li>两条规则去实现：<ol>
<li>如果P写了x，P1要读x，只有当read和write分开足够远时，P的write才能被P1的read看到</li>
<li>写到同一个地方的数据必须串行起来，以一种相同的顺序被看到<ol>
<li>只会看到最新的写</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><strong>cache coherence的定义：</strong></p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230153040285.png" alt="image-20221230153040285" style="zoom:80%;" /></p>
<h3 id="13-2-1-硬件Coherence协议"><a href="#13-2-1-硬件Coherence协议" class="headerlink" title="13.2.1    硬件Coherence协议"></a>13.2.1    硬件Coherence协议</h3><ol>
<li><strong>Snooping算法</strong>：Snoopy Bus<ol>
<li>所有对数据的请求都要发给所有处理器</li>
<li>处理器监听是否有对数据的请求与其相关，如果于其相关，则修改自己的cache中的数据</li>
<li>需要广播的机制</li>
<li>如果有bus，则work well</li>
<li>适用于小规模的机器</li>
</ol>
</li>
<li><strong>Directoy-Based Scheme</strong>：discuss later<ol>
<li>有一个中央的目录，知道哪一个处理器拥有哪一段地址</li>
<li>如果需要修改数据，则向中央目录发送点对点请求</li>
<li>中央目录将该请求发送到每个与其相关的处理器</li>
<li>只有当处理器不在一个bus上时，才更优</li>
</ol>
</li>
</ol>
<h3 id="13-2-2-Snoopy协议"><a href="#13-2-2-Snoopy协议" class="headerlink" title="13.2.2    Snoopy协议"></a>13.2.2    Snoopy协议</h3><ol>
<li><strong>Write Invalidate</strong>协议：<ol>
<li>多个reader，单一writer</li>
<li>写到shared data时，会发送一个invalidate的消息，给所有的cache</li>
<li>当cache读到invalidate的数据时，就会发生miss<ol>
<li>write-through：内存总是最新的</li>
<li>write-back：先看别的cache中，是否有当前数据的最新copy</li>
</ol>
</li>
</ol>
</li>
<li><strong>Write Broadcast</strong>协议：<ol>
<li>写的时候，会将数据发送到bus上，处理器用该数据更新自己的cache</li>
<li>不会导致新的miss</li>
</ol>
</li>
<li>写的串行化：通过bus访问实现</li>
<li>总结：<ol>
<li>所有的cache会看到所有的bus事件，并进行响应</li>
<li>协议依赖于bus事件的全局可见性</li>
<li>由于bus上只能有一个数据，因此可以强制串行write</li>
</ol>
</li>
</ol>
<blockquote>
<p>  示例：write-back cache、write invalidate</p>
<ol>
<li><p>最后一次读X时，让其它的cache中进行一次write-back，然后从memory中读取X</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230154822756.png" alt="image-20221230154822756" style="zoom:80%;" /></p>
<p>示例：write-back cache、broadcast</p>
</li>
<li><p>广播时，会将内存中的数据也修改了(事实上的through)</p>
<p><img src=" https://raw.githubusercontent.com/unicorn2022/Pictures/main/AssetMarkdown/image-20221230154953997.png" alt="image-20221230154953997" style="zoom:80%;" /></p>
</li>
</ol>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="unicorn2022.github.io">华丰夏</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://hzoi-unicorn.top/2022/09/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">https://hzoi-unicorn.top/2022/09/14/计算机体系结构/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://hzoi-unicorn.top" target="_blank">华风夏韵</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/">专业课</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/09/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/" title="计算机图形学"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">计算机图形学</div></div></a></div><div class="next-post pull-right"><a href="/2022/09/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="计算机网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">计算机网络</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/07/19/cmake%E6%8C%87%E4%BB%A4%E5%90%88%E9%9B%86/" title="cmake指令合集"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-19</div><div class="title">cmake指令合集</div></div></a></div><div><a href="/2023/07/15/cmake%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="cmake学习笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-15</div><div class="title">cmake学习笔记</div></div></a></div><div><a href="/2023/03/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="人工智能"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-01</div><div class="title">人工智能</div></div></a></div><div><a href="/2023/03/01/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/" title="多媒体技术"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-01</div><div class="title">多媒体技术</div></div></a></div><div><a href="/2023/02/28/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AF%BC%E8%AE%BA/" title="自然语言处理导论"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-28</div><div class="title">自然语言处理导论</div></div></a></div><div><a href="/2023/02/27/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" title="编译原理"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-27</div><div class="title">编译原理</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/avatar.png" onerror="this.onerror=null;this.src='https://raw.githubusercontent.com/unicorn2022/Pictures/main/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">华丰夏</div><div class="author-info__description">一切都是上天最好的安排</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/unicorn2022"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/unicorn2022" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:496300118@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">愿你前行的道路有群星闪耀。愿你留下的足迹有百花绽放。你即是上帝的馈赠，世界因你而瑰丽。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-1%EF%BC%9AIntroduction"><span class="toc-text">Chapter 1：Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-Current-computer"><span class="toc-text">1.1    Current computer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Dependability-%E9%9C%80%E8%A6%81%E8%AE%A1%E7%AE%97"><span class="toc-text">1.2    Dependability(需要计算)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E6%B5%8B%E9%87%8F-%E6%8A%A5%E5%91%8A-%E6%80%BB%E7%BB%93-%E6%80%A7%E8%83%BD-%E9%9C%80%E8%A6%81%E8%AE%A1%E7%AE%97"><span class="toc-text">1.3    测量&#x2F;报告&#x2F;总结 性能(需要计算)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-3%EF%BC%9AMemory-hierarchy"><span class="toc-text">Chapter 3：Memory hierarchy</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Introduction"><span class="toc-text">3.1    Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Cache"><span class="toc-text">3.2    Cache</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-%E7%BB%84%E7%9B%B8%E8%81%94%E8%AE%A1%E7%AE%97"><span class="toc-text">3.2.1    组相联计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-block%E7%9A%84%E6%9B%BF%E6%8D%A2%E7%AD%96%E7%95%A5"><span class="toc-text">3.2.2    block的替换策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E5%86%99%E7%AD%96%E7%95%A5"><span class="toc-text">3.2.3    写策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-4-%E6%95%B0%E6%8D%AE%E5%92%8C%E6%8C%87%E4%BB%A4%E7%9A%84cache%E6%98%AF%E5%90%A6%E5%88%86%E7%A6%BB"><span class="toc-text">3.2.4    数据和指令的cache是否分离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-5-Supervisor-cache-User-cache"><span class="toc-text">3.2.5    Supervisor cache &#x2F; User cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-6-Cache-Performance-%E8%AE%A1%E7%AE%97"><span class="toc-text">3.2.6    Cache Performance (计算)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-6-1-CPU-Time"><span class="toc-text">3.2.6.1    CPU Time</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-6-2-AMAT%EF%BC%9A%E5%B9%B3%E5%9D%87%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%97%B6%E9%97%B4"><span class="toc-text">3.2.6.2    AMAT：平均内存访问时间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-6-3-Cache%E6%80%A7%E8%83%BD%E7%9A%84%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87"><span class="toc-text">3.2.6.3    Cache性能的测试指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-6-4-%E7%A4%BA%E4%BE%8B"><span class="toc-text">3.2.6.4    示例</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-4%EF%BC%9AHow-to-improve-memory-performance"><span class="toc-text">Chapter 4：How to improve memory performance</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E9%99%8D%E4%BD%8Ehit-time"><span class="toc-text">4.1    降低hit time</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-%E5%B0%8F%E8%80%8C%E7%AE%80%E5%8D%95%E7%9A%84cache"><span class="toc-text">4.1.1    小而简单的cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-Way-Prediction"><span class="toc-text">4.1.2    Way Prediction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-3-%E5%9C%A8cache%E4%B8%8A%E5%81%9A%E7%B4%A2%E5%BC%95%E6%97%B6%E9%81%BF%E5%85%8DAddress-Translation"><span class="toc-text">4.1.3    在cache上做索引时避免Address Translation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-1-TLB%EF%BC%9ATranslation-Lookat-Buffer"><span class="toc-text">4.1.3.1    TLB：Translation Lookat Buffer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-2-Virtual-Cache"><span class="toc-text">4.1.3.2    Virtual Cache</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-4-Trace-Caches"><span class="toc-text">4.1.4    Trace Caches</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%A2%9E%E5%8A%A0bandwidth"><span class="toc-text">4.2    增加bandwidth</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-Pipelined-Cache"><span class="toc-text">4.2.1    Pipelined Cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-Nonblocking-Caches"><span class="toc-text">4.2.2    Nonblocking Caches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-3-Multibanked-Caches"><span class="toc-text">4.2.3    Multibanked Caches</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E9%99%8D%E4%BD%8Emiss-penalty"><span class="toc-text">4.3    降低miss penalty</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-1-Multilevel-Caches"><span class="toc-text">4.3.1    Multilevel Caches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-2-Critical-Word-First-amp-Early-Restart"><span class="toc-text">4.3.2    Critical Word First &amp; Early Restart</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-3-Giving-Priority-to-Read-Misses-over-Writes"><span class="toc-text">4.3.3    Giving Priority to Read Misses over Writes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-4-Merging-write-Buffer"><span class="toc-text">4.3.4    Merging write Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-5-Victim-Caches"><span class="toc-text">4.3.5    Victim Caches</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-%E9%99%8D%E4%BD%8Emiss-rate"><span class="toc-text">4.4    降低miss rate</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-1-%E6%9B%B4%E5%A4%A7%E7%9A%84Block-Size"><span class="toc-text">4.4.1    更大的Block Size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-2-%E6%9B%B4%E5%A4%A7%E7%9A%84cache"><span class="toc-text">4.4.2    更大的cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-3-%E6%9B%B4%E9%AB%98%E7%9A%84Associativity"><span class="toc-text">4.4.3    更高的Associativity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-4-%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96"><span class="toc-text">4.4.4    编译器优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-1-Merging-Arrays"><span class="toc-text">4.4.4.1    Merging Arrays</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-2-Loop-Interchange"><span class="toc-text">4.4.4.2    Loop Interchange</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-3-Loop-fusion"><span class="toc-text">4.4.4.3    Loop fusion</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-4-Blocking-optimized-Matrix-Multiplication"><span class="toc-text">4.4.4.4     Blocking optimized Matrix Multiplication</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-5-%E7%A4%BA%E4%BE%8B"><span class="toc-text">4.4.4.5    示例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-%E7%A1%AC%E4%BB%B6%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86"><span class="toc-text">4.5    硬件相关知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-1-DRAM-amp-SRAM"><span class="toc-text">4.5.1     DRAM &amp; SRAM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-2-SDRAM%EF%BC%9ASynchronous-DRAM"><span class="toc-text">4.5.2    SDRAM：Synchronous DRAM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-3-DDR%EF%BC%9ADouble-data-rate"><span class="toc-text">4.5.3    DDR：Double data rate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-4-flash"><span class="toc-text">4.5.4    flash</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%A0%E9%A2%98"><span class="toc-text">习题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-5%EF%BC%9AExtend-2-Supporting-M-Coperation"><span class="toc-text">Chapter 5：Extend 2 Supporting M Coperation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E4%B9%8B%E5%89%8D%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BFCPU"><span class="toc-text">5.1    之前的流水线CPU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E6%89%A9%E5%B1%95%E6%B5%81%E6%B0%B4%E7%BA%BFCPU%EF%BC%8C%E6%94%AF%E6%8C%81%E5%A4%9A%E5%91%A8%E6%9C%9F%E8%BF%90%E7%AE%97"><span class="toc-text">5.2    扩展流水线CPU，支持多周期运算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1-%E5%8C%85%E5%90%ABFP%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E7%9A%845%E9%98%B6%E6%AE%B5%E6%B5%81%E6%B0%B4%E7%BA%BF"><span class="toc-text">5.2.1    包含FP运算单元的5阶段流水线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-2-%E4%B8%A4%E4%B8%AA%E6%8C%87%E6%A0%87%EF%BC%9ALatency%E5%92%8CInitiation-interval"><span class="toc-text">5.2.2    两个指标：Latency和Initiation interval</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-3-%E6%8C%89%E5%BA%8F%E5%8F%91%E5%B0%84%EF%BC%8C%E4%B9%B1%E5%BA%8F%E5%AE%8C%E6%88%90"><span class="toc-text">5.2.3    按序发射，乱序完成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-4-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3write-port-conflict"><span class="toc-text">5.2.4    如何解决write port conflict</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-data-hazard%E7%9A%84%E7%A7%8D%E7%B1%BB"><span class="toc-text">5.3    data hazard的种类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-RAW%E4%BE%9D%E8%B5%96"><span class="toc-text">5.3.1    RAW依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-WAW%E4%BE%9D%E8%B5%96"><span class="toc-text">5.3.2    WAW依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-3-WAR%E4%BE%9D%E8%B5%96"><span class="toc-text">5.3.3    WAR依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-4-%E5%9C%A8ID%E9%98%B6%E6%AE%B5%E9%9C%80%E8%A6%81%E6%A3%80%E6%9F%A5%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-text">5.3.4    在ID阶段需要检查的内容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chpater-7%EF%BC%9ADynamic-Schedule%E2%80%94Scoreboard"><span class="toc-text">Chpater 7：Dynamic Schedule—Scoreboard</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8CILP"><span class="toc-text">7.1    指令级并行ILP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-1-%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8C%E7%9A%84%E7%9B%AE%E6%A0%87%EF%BC%9A%E6%9C%80%E5%B0%8F%E5%8C%96CPI"><span class="toc-text">7.1.1    指令级并行的目标：最小化CPI</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-2-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0ILP"><span class="toc-text">7.1.2    如何实现ILP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-3-%E9%99%8D%E4%BD%8Estall%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-text">7.1.3    降低stall的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-4-Instruction-Level-Parallelism-ILP"><span class="toc-text">7.1.4    Instruction-Level Parallelism ILP</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E6%95%B0%E6%8D%AE%E4%BE%9D%E8%B5%96"><span class="toc-text">7.2    数据依赖</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-1-%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E4%BE%9D%E8%B5%96%EF%BC%9ARAW-%E5%86%99%E5%90%8E%E8%AF%BB"><span class="toc-text">7.2.1    真实数据依赖：RAW 写后读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-2-%E5%91%BD%E5%90%8D%E4%BE%9D%E8%B5%96"><span class="toc-text">7.2.2    命名依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-3-%E6%8E%A7%E5%88%B6%E4%BE%9D%E8%B5%96"><span class="toc-text">7.2.3    控制依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-4-%E5%BC%82%E5%B8%B8"><span class="toc-text">7.2.4    异常</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-ILP%EF%BC%9A%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95%E2%80%94%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6"><span class="toc-text">7.3    ILP：软件方法—静态调度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-1-%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF"><span class="toc-text">7.3.1    相关技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-2-%E7%A4%BA%E4%BE%8B"><span class="toc-text">7.3.2    示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-3-%E8%B7%B3%E8%BD%AC%E6%8C%87%E4%BB%A4%E7%9A%84delay-slot"><span class="toc-text">7.3.3    跳转指令的delay slot</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-ILP%EF%BC%9A%E7%A1%AC%E4%BB%B6%E6%96%B9%E6%B3%95%E2%80%94%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6"><span class="toc-text">7.4    ILP：硬件方法—动态调度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6"><span class="toc-text">7.4.1    为什么需要动态调度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-2-%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="toc-text">7.4.2    基本思路</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-5-Scoreboard-%E8%AE%A1%E5%88%86%E6%9D%BF"><span class="toc-text">7.5    Scoreboard 计分板</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-1-%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-text">7.5.1    基本结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-2-%E8%AE%A1%E5%88%86%E6%9D%BF%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%A7"><span class="toc-text">7.5.2    计分板的流水级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-3-%E8%AE%A1%E5%88%86%E6%9D%BF%E7%AE%97%E6%B3%95"><span class="toc-text">7.5.3    计分板算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-4-%E8%AE%B0%E5%88%86%E7%89%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%85%B7%E4%BD%93%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F"><span class="toc-text">7.5.4    记分牌算法的具体运行方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-5-%E7%A4%BA%E4%BE%8B"><span class="toc-text">7.5.5    示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-6-Scoreboard%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-text">7.5.6    Scoreboard的局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-6-%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D"><span class="toc-text">7.6    寄存器重命名</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-7-Scoreboard-vs-Tomasulo"><span class="toc-text">7.7    Scoreboard vs. Tomasulo</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-8%EF%BC%9ADynamic-Schedule%E2%80%94Tomasulo"><span class="toc-text">Chapter 8：Dynamic Schedule—Tomasulo</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-Tomasulo%E7%AE%97%E6%B3%95"><span class="toc-text">8.1    Tomasulo算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-1-%E5%9F%BA%E7%A1%80%E6%80%9D%E6%83%B3"><span class="toc-text">8.1.1    基础思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-2-%E4%BF%9D%E7%95%99%E7%AB%99%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-text">8.1.2    保留站的内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-3-%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5"><span class="toc-text">8.1.3    三个阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-4-Data-Path"><span class="toc-text">8.1.4    Data Path</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-5-%E5%85%B7%E4%BD%93%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F"><span class="toc-text">8.1.5    具体运行方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-6-%E7%A4%BA%E4%BE%8B"><span class="toc-text">8.1.6    示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-7-%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-text">8.1.7    优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-8-Tomasolo%E7%AE%97%E6%B3%95%E7%9A%84%E6%8C%87%E4%BB%A4%E5%8F%AF%E4%BB%A5%E8%B7%A8%E8%B6%8A%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%89%8D%E5%90%8E%E8%BD%AE"><span class="toc-text">8.1.8    Tomasolo算法的指令可以跨越循环的前后轮</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-9-%E7%B2%BE%E7%A1%AE%E4%B8%AD%E6%96%AD"><span class="toc-text">8.1.9    精确中断</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-Scoreboard%E7%AE%97%E6%B3%95%EF%BC%9A%E9%80%9A%E8%BF%87%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D%E9%81%BF%E5%85%8DWAR%E3%80%81WAW%E7%AD%89%E5%BE%85"><span class="toc-text">8.2    Scoreboard算法：通过寄存器重命名避免WAR、WAW等待</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-1-Scoreboard%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%A7"><span class="toc-text">8.2.1    Scoreboard的流水级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-2-Scoreboard%E7%AE%97%E6%B3%95"><span class="toc-text">8.2.2    Scoreboard算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-3-Explicit-Renaming-%E6%98%BE%E5%BC%8F%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D"><span class="toc-text">8.2.3    Explicit Renaming 显式寄存器重命名</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-1-%E5%89%8D%E6%8F%90"><span class="toc-text">8.2.3.1    前提</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-2-%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF"><span class="toc-text">8.2.3.2    核心思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-3-%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6"><span class="toc-text">8.2.3.3    实现机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-4-%E4%BC%98%E7%82%B9"><span class="toc-text">8.2.3.4    优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-5-%E9%9C%80%E8%A6%81%E7%9A%84%E6%94%AF%E6%8C%81"><span class="toc-text">8.2.3.5    需要的支持</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-6-%E7%A4%BA%E4%BE%8B"><span class="toc-text">8.2.3.6    示例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-7-%E5%9C%A8Scoreboard%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%98%BE%E5%BC%8F%E9%87%8D%E5%91%BD%E5%90%8D"><span class="toc-text">8.2.3.7    在Scoreboard中使用显式重命名</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-3-8-%E6%98%BE%E5%BC%8F%E9%87%8D%E5%91%BD%E5%90%8DScoreboard%E7%9A%84%E5%9B%9B%E4%B8%AA%E9%98%B6%E6%AE%B5"><span class="toc-text">8.2.3.8    显式重命名Scoreboard的四个阶段</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-9-%EF%BC%9ABranch-Predictor-amp-Speculation"><span class="toc-text">Chapter 9 ：Branch Predictor &amp; Speculation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-Control-Hazard"><span class="toc-text">9.1    Control Hazard</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-2-%E5%8A%A8%E6%80%81%E7%A1%AC%E4%BB%B6%E9%A2%84%E6%B5%8B"><span class="toc-text">9.2    动态硬件预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-1-1-bit-Branch-Prediction-Buffer"><span class="toc-text">9.2.1    1-bit Branch-Prediction Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-2-2-bit-Branch-Prediction-Buffer"><span class="toc-text">9.2.2    2-bit Branch-Prediction Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-3-n-bit-Branch-Prediction-Buffer"><span class="toc-text">9.2.3    n-bit Branch-Prediction Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-4-Branch-Target-Buffer"><span class="toc-text">9.2.4    Branch Target Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-5-Integrated-Instruction-Fetch-Units-%E9%9B%86%E6%88%90%E6%8C%87%E4%BB%A4%E8%8E%B7%E5%8F%96%E5%8D%95%E5%85%83"><span class="toc-text">9.2.5    Integrated Instruction Fetch Units 集成指令获取单元</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-6-Return-Address-Predictor"><span class="toc-text">9.2.6    Return Address Predictor</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-3-Hardware-Based-Speculation-%E6%8A%95%E6%9C%BA"><span class="toc-text">9.3    Hardware Based Speculation 投机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-1-Tomasulo%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-text">9.3.1    Tomasulo的缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-2-Hardward-based-Speculation"><span class="toc-text">9.3.2    Hardward-based Speculation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-3-%E5%9F%BA%E4%BA%8ETomasulo%E7%AE%97%E6%B3%95%E7%9A%84%E6%8A%95%E6%9C%BA%E6%89%A7%E8%A1%8C-Speculative-execution"><span class="toc-text">9.3.3    基于Tomasulo算法的投机执行 Speculative execution</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-1-%E5%9F%BA%E7%A1%80%E6%80%9D%E6%83%B3"><span class="toc-text">9.3.3.1    基础思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-2-%E7%BB%93%E6%9E%84"><span class="toc-text">9.3.3.2    结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-3-%E5%92%8CTomasulo%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">9.3.3.3    和Tomasulo算法的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-4-Reorder-Buffer-%E7%9A%84%E6%AF%8F%E4%B8%AA%E5%AE%9E%E4%BE%8B%E5%8C%85%E5%90%AB"><span class="toc-text">9.3.3.4    Reorder Buffer 的每个实例包含</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-5-%E6%8A%95%E6%9C%BATomasulo%E7%AE%97%E6%B3%95%E7%9A%84%E5%9B%9B%E4%B8%AA%E6%AD%A5%E9%AA%A4"><span class="toc-text">9.3.3.5    投机Tomasulo算法的四个步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-6-commit%E6%97%B6%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-text">9.3.3.6    commit时的操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-7-%E7%A4%BA%E4%BE%8B"><span class="toc-text">9.3.3.7    示例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-8-%E6%96%B0%E9%97%AE%E9%A2%98%EF%BC%9Amemory-disambiguation"><span class="toc-text">9.3.3.8    新问题：memory disambiguation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-9-%E5%AF%B9%E7%B2%BE%E7%A1%AE%E4%B8%AD%E6%96%AD%E7%9A%84%E7%A1%AC%E4%BB%B6%E6%94%AF%E6%8C%81"><span class="toc-text">9.3.3.9    对精确中断的硬件支持</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-4-%E8%AE%B0%E5%88%86%E7%89%8C%E3%80%81Tomasulo%E3%80%81%E5%B8%A6%E6%8A%95%E6%9C%BA%E7%9A%84Tomasulo%E4%B8%89%E7%A7%8D%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94"><span class="toc-text">9.4    记分牌、Tomasulo、带投机的Tomasulo三种算法对比</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-10%EF%BC%9ASuperScalar-amp-VLIW"><span class="toc-text">Chapter 10：SuperScalar &amp; VLIW</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-%E8%8E%B7%E5%8F%96CPI-lt-1%EF%BC%9AMultiple-Issue-Processor-%E5%A4%9A%E5%8F%91%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-text">10.1    获取CPI&lt;1：Multiple Issue Processor 多发处理器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-SuperScalar"><span class="toc-text">10.2    SuperScalar</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-1-%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6SuperScalar"><span class="toc-text">10.2.1    静态调度SuperScalar</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-2-%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6SuperScalar"><span class="toc-text">10.2.2    动态调度SuperScalar</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-3-ILP%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95"><span class="toc-text">10.2.3    ILP软件方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-%E9%9D%99%E6%80%81%E5%A4%9A%E5%8F%91%EF%BC%9AVLIW"><span class="toc-text">10.3    静态多发：VLIW</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-11%EF%BC%9AMultithreading"><span class="toc-text">Chapter 11：Multithreading</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BD%AF%E4%BB%B6"><span class="toc-text">11.1    多线程软件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-1-%E8%BF%9B%E7%A8%8B-amp-%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.1.1    进程&amp;线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-2-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BA%94%E7%94%A8%EF%BC%9A%E8%BF%9B%E7%A8%8B%E8%A2%AB%E5%88%92%E5%88%86%E6%88%90%E4%BA%86%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.1.2    多线程应用：进程被划分成了线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-3-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E6%8C%87%E4%BB%A4%E6%B2%A1%E6%9C%89%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB"><span class="toc-text">11.1.3    如何保证流水线之间的指令没有依赖关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-4-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-text">11.1.4    多线程体系结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-5-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BC%80%E9%94%80"><span class="toc-text">11.1.5    多线程的开销</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-6-%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5"><span class="toc-text">11.1.6    线程调度策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-7-Coarse-Grain-Multithreading-%E7%B2%97%E7%B2%92%E5%BA%A6%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.1.7    Coarse-Grain Multithreading 粗粒度多线程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-2-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1"><span class="toc-text">11.2    多线程设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-1-Superscalar-Machine-Efficiency"><span class="toc-text">11.2.1    Superscalar Machine Efficiency</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-2-%E5%9E%82%E7%9B%B4%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.2.2    垂直多线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-3-%E8%8A%AF%E7%89%87%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.2.3    芯片多线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-4-%E5%90%8C%E6%97%B6%E5%A4%9A%E7%BA%BF%E7%A8%8B-Out-of-Order-Simultaneous-Multithreading"><span class="toc-text">11.2.4    同时多线程 Out-of-Order Simultaneous Multithreading</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-5-%E6%8A%95%E6%9C%BA%E3%80%81%E4%B9%B1%E5%BA%8F%E3%80%81%E8%B6%85%E6%A0%87%E9%87%8F%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-text">11.2.5    投机、乱序、超标量的处理器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-6-%E8%8A%AF%E7%89%87%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-text">11.2.6    芯片多线程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-12%EF%BC%9ADLP%E2%80%94Vector-amp-SIMD-amp-GPU"><span class="toc-text">Chapter 12：DLP—Vector &amp; SIMD &amp; GPU</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#12-1-%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E5%9B%9B%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-text">12.1    程序执行四种模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-2-SIMD"><span class="toc-text">12.2    SIMD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-3-Vector-Processing-%E5%90%91%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="toc-text">12.3    Vector Processing 向量计算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-3-1-%E5%90%91%E9%87%8F%E8%AE%A1%E7%AE%97%E7%9A%84%E7%89%B9%E7%82%B9"><span class="toc-text">12.3.1    向量计算的特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-3-2-Vector%E6%9E%B6%E6%9E%84%E7%9A%84%E7%B1%BB%E5%9E%8B"><span class="toc-text">12.3.2    Vector架构的类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-1-vector-register-architecture"><span class="toc-text">12.3.2.1    vector-register architecture</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-2-Vector-Memory-Memory-Achitecture"><span class="toc-text">12.3.2.2    Vector Memory-Memory Achitecture</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-3-Vector-Processor%E7%9A%84%E7%BB%84%E4%BB%B6"><span class="toc-text">12.3.2.3    Vector Processor的组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-4-%E5%9F%BA%E7%A1%80%E5%90%91%E9%87%8F%E6%8C%87%E4%BB%A4"><span class="toc-text">12.3.2.4    基础向量指令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-5-%E5%90%91%E9%87%8F%E6%8C%87%E4%BB%A4%E7%9A%84%E6%89%A7%E8%A1%8C%E6%97%B6%E9%97%B4"><span class="toc-text">12.3.2.5    向量指令的执行时间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-6-Chimes-%E8%8A%82%E6%8B%8D"><span class="toc-text">12.3.2.6    Chimes 节拍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-7-Vector%E5%86%85%E5%AD%98%E6%93%8D%E4%BD%9C"><span class="toc-text">12.3.2.7    Vector内存操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-8-DAXPY"><span class="toc-text">12.3.2.8    DAXPY</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-9-%E5%90%91%E9%87%8F%E9%95%BF%E5%BA%A6"><span class="toc-text">12.3.2.9    向量长度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-2-10-Strip-Mining"><span class="toc-text">12.3.2.10    Strip Mining</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-3-3-%E5%90%91%E9%87%8F%E6%93%8D%E4%BD%9C%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-text">12.3.3    向量操作的优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-3-1-Vector-Chaining"><span class="toc-text">12.3.3.1    Vector Chaining</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-3-2-%E6%9D%A1%E4%BB%B6%E6%89%A7%E8%A1%8C"><span class="toc-text">12.3.3.2    条件执行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-3-3-3-%E5%8E%8B%E7%BC%A9-%E6%89%A9%E5%B1%95%E6%93%8D%E4%BD%9C"><span class="toc-text">12.3.3.3    压缩&#x2F;扩展操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-3-4-Vector%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-text">12.3.4    Vector的优点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-4-SIMD"><span class="toc-text">12.4    SIMD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-4-1-SIMD%E5%AE%9E%E7%8E%B0"><span class="toc-text">12.4.1    SIMD实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-4-2-SIMD%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="toc-text">12.4.2    SIMD代码示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-5-GPU%EF%BC%9AGraphical-Processing-Units"><span class="toc-text">12.5    GPU：Graphical Processing Units</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-5-1-Threads-and-Blocks"><span class="toc-text">12.5.1    Threads and Blocks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-5-2-NVIDIA-GPU-%E6%9E%B6%E6%9E%84"><span class="toc-text">12.5.2    NVIDIA GPU 架构</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-13%EF%BC%9AMultiprocessors"><span class="toc-text">Chapter 13：Multiprocessors</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#13-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-text">13.1    为什么要使用多处理器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-1-%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87"><span class="toc-text">13.1.1    多处理器的目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-2-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA"><span class="toc-text">13.1.2    并行计算机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-3-Catalogue-the-Parallel-MIMD-Processors"><span class="toc-text">13.1.3    Catalogue the Parallel(MIMD) Processors</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-3-1-UMA"><span class="toc-text">13.1.3.1    UMA</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-3-2-UMA-vs-NUMA"><span class="toc-text">13.1.3.2    UMA vs NUMA</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-4-%E4%B8%BB%E8%A6%81%E7%9A%84MIMD%E7%B1%BB%E5%9E%8B"><span class="toc-text">13.1.4    主要的MIMD类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-1-5-%E5%B9%B6%E8%A1%8C%E6%9E%B6%E6%9E%84"><span class="toc-text">13.1.5    并行架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-5-1-Shared-Address-Model"><span class="toc-text">13.1.5.1    Shared Address Model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-5-2-Message-Passing-Model"><span class="toc-text">13.1.5.2    Message Passing Model</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-2-Cache-coherence-%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-text">13.2    Cache coherence 一致性问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-1-%E7%A1%AC%E4%BB%B6Coherence%E5%8D%8F%E8%AE%AE"><span class="toc-text">13.2.1    硬件Coherence协议</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-2-Snoopy%E5%8D%8F%E8%AE%AE"><span class="toc-text">13.2.2    Snoopy协议</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/19/cmake%E6%8C%87%E4%BB%A4%E5%90%88%E9%9B%86/" title="cmake指令合集">cmake指令合集</a><time datetime="2023-07-19T12:19:11.000Z" title="发表于 2023-07-19 20:19:11">2023-07-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/15/cmake%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="cmake学习笔记">cmake学习笔记</a><time datetime="2023-07-15T10:00:00.000Z" title="发表于 2023-07-15 18:00:00">2023-07-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/13/hexo%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/" title="hexo常用指令">hexo常用指令</a><time datetime="2023-07-13T13:11:11.000Z" title="发表于 2023-07-13 21:11:11">2023-07-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/04/01/GAMES104/" title="GAMES104">GAMES104</a><time datetime="2023-04-01T04:49:00.000Z" title="发表于 2023-04-01 12:49:00">2023-04-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="人工智能">人工智能</a><time datetime="2023-03-01T02:00:00.000Z" title="发表于 2023-03-01 10:00:00">2023-03-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 华丰夏</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>